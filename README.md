### Soroban Smart Contract Docs, LangChain & Supabase: Create a Coding AI to help you development with Soroban

Leverage the power of Soroban AI combined with LangChain, Supabase, TypeScript, OpenAI, and Next.js. LangChain is a cutting-edge framework designed for building scalable AI/LLM apps, and Supabase provides an open-source Postgres database with capabilities to store embeddings through a pg vector extension.

## Tutorial Video: Watch Now

Need Help? Connect on the [Stellar Developers Discord](NickThoroughman on Discord)

üñºÔ∏è Dive into the visual guide folder to visually comprehend this repository and the tutorial.

## üõ†Ô∏è Development

# Step 1: Get the Code

bash

Copy code

git clone [github https url]

# Step 2: Install Dependencies

bash

Copy code

```

pnpm install

```

# Step 3: Environment Setup

Duplicate the .env.local.example and rename it to .env

Your .env should look like:

env

```

OPENAI_API_KEY=
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

```

Head over to OpenAI's Documentation to fetch your API keys.

Set up your database at Supabase and get your keys via the user dashboard following their guide.

# Step 4: Configuration

Inside the config directory, replace the URLs with your website's. Ensure you have more than one URL for the script to function.

# Step 5: Soroban Web Loader Setup

Within utils/soroban_web_loader.ts, modify the values of title, date, and content to the CSS selectors representing the desired text content from your webpage. Dive deep into Cheerio's utility here.

Remember, while you can include custom metadata, the default loader expects at least:

typescript

Copy code

```

{
  pageContent: string;
  metadata: { source: string; };
}

```

This data will be saved in your Supabase database later.

# Step 6: Database Setup

Paste and execute the schema.sql in your Supabase SQL editor. Ensure the existence of the documents table and the match_documents function.

## üåç Update Web Scraping and Embedding

Initiate the scraping and embedding script located in scripts/scrape-embed.ts using:

bash

```
npm run scrape-embed

```

This will process URLs from the config directory, extract specified content, and then utilize OpenAI's Embeddings (gpt-3.5-turbo-16k) to transmute this data into vectors.

## üöÄ Launch the App

Post confirming the successful addition of embeddings and content to your Supabase table, kick start the app with npm run dev. You're all set to pose questions and get them answered!

## üìú Credits

Frontend Inspiration: langchain-chat-nextjs
https://github.com/mayooear/notion-chat-langchain

Documentation: Extensively utilizes documentation from Soroban's React Guide and Soroban's Stellar Docs
