[{"pageContent":"WelcomeStellar is a layer-1 open-source, decentralized, peer-to-peer blockchain network that provides a framework for developers to create applications, issue assets, and connect to existing financial rails. Stellar is designed to enable creators, innovators, and developers to build projects on the network that can interoperate with each other.There are three main use cases for building on Stellar: building applications, issuing assets, and building anchors. These docs aim first to teach you Stellar fundamentals to help you build, walk you through how to set up for each use case, and then how to run your own Horizon API instance and validator node.If you can’t find answers to your questions in the docs, search for your answer or ask questions in our Stellar Developer Discord or Stack Exchange.Contribute to the docs​These documents are also open-source and aim to help developers take their projects from conception to launch. Contributions to the docs are encouraged. You can file a pull request to add new content, suggest revisions to existing content using the edit icon at the top of each page, or submit suggestions, requests, and bug reports as issues in the Docs GitHub Repo.Developer community channels​Get involved with the Stellar developer community- interact with other Stellar devs, keep up with ecosystem standards and protocol upgrades, and learn about upcoming workshops and events.Stellar Developer Discord Ask questions and engage with other Stellar devs.Stellar Developers Google Group Discuss Core Advancement Proposals (CAPs) and Stellar Ecosystem Proposals (SEPs), talk about the development of Stellar Core and Horizon, and stay informed about important network upgrades.Stellar Stack Exchange A question and answer site for Stellar developers; if you can’t find what you’re looking for in the docs, try searching the Stack Exchange to see if your question has been addressed. If it hasn't, feel free to ask!Developer Blog Get the latest news and insights about building on Stellar.","metadata":{"source":"https://developers.stellar.org/docs/","title":"Welcome","contentLength":327}},{"pageContent":"Stellar Consensus Protocol (SCP)Consensus is hugely important in a decentralized payment system. It distributes the monitoring and approval of transactions across many individual nodes (computers) instead of relying on one closed, central system. Nodes are run by organizations or individuals, and the goal is for all nodes to update the ledger in the same way, ensuring each ledger reaches the same state. Consensus is vital for the security of the blockchain, allowing nodes to agree on something safely and preventing double-spend attacks.The Stellar network reaches consensus using the Stellar Consensus Protocol (SCP), which is a construction of the Federated Byzantine Agreement (FBA). FBA differs from other well-known consensus mechanisms like Proof of Work (which relies on a node’s computational power) and Proof of Stake (which relies on a node’s staking power) by instead relying on the agreement of trusted nodes.In SCP, each participating Stellar Core node (also called a validator or validator node) decides what set of other nodes they want to trust. The flexibility of user-defined trust allows for open network membership (meaning anyone can become a Core node) and decentralized control (meaning no central authority dictates whose vote is required for consensus).There are no monetary rewards for being a validator on the Stellar network. Instead, users are encouraged to become a validator because they are then contributing to the security and resiliency of the network, which benefits the products and services built on Stellar.There are three desired properties of consensus mechanisms: fault tolerance, safety, and liveness.Fault tolerance - the system can continue operating despite node failures or malfunctionsSafety - no two nodes ever agree on different values, guarantees nodes will produce the same blockLiveness - a node can output a value without the participation of any misbehaving nodesConsensus mechanisms can typically only prioritize two out of three of these properties. SCP prioritizes fault tolerance and safety over liveness. Because of prioritizing safety, blocks can sometimes get stuck while waiting for nodes to agree.SCP components​Quorum set​As mentioned above, each Core node decides on which other nodes it would like to trust to reach agreement. A node’s trusted set of nodes is called a quorum set.Thresholds and quorum slices​In addition to choosing a quorum set, Core nodes must also choose a threshold. A threshold is the minimum number of nodes in a quorum set that must agree to reach consensus. For example, let’s say node B has nodes [A, C, D] in its quorum set and sets the threshold to 2. This means that any combination of 2 nodes in the quorum set agreeing is valid: either [A,C], [C,D], or [A,D] must agree for the node to proceed. The combination of agreeing nodes within the quorum set are called quorum slices.Node blocking sets​Nodes can be blocked from reaching consensus by node blocking sets. Node blocking sets are any set of nodes in a quorum set that prevent a node from reaching agreement. For example, if a node requires 3 out of 4 of the nodes in its quorum set to agree, any combination of two nodes is considered a node blocking set.Quorum​A quorum is a set of nodes sufficient to reach an agreement wherein each node is part of a quorum slice.Statement​Valid statements on Stellar express the different opinions of nodes regarding transaction sets to agree on for a given ledger. For example: “I propose this transaction set for ledger number 800”.A node’s opinion on a statement depends on the opinions of its quorum set.Federated voting​In the SCP, agreement is achieved using federated voting. A node reasons about the state of the network based on what it learns from its quorum set- before a statement is 100% agreed upon by every honest node in the network, it goes through three steps of federated voting: (1) Vote, (2) Accept, and (3) Confirm.A node can have four opinions on a statement (let’s call the statement “A”)I don’t know anything about A and have no opinionI vote for A, it’s valid, but I don’t know if it’s safe to act on it yetI accept A, because enough nodes supported this statement, but I don’t know if it’s safe to act on it yetI confirm A, it is safe to act on it. Even if every node in my quorum has not confirmed A, they will not be able to confirm anything else but A.To transition between the states above, federated voting has the following rules:Vote for A if it is consistent with my previous votesAccept A if either:Every node in my quorum slice voted for or accepted AORMy blocking set accepted A (even if I voted for something that contradicts A in the past, I forget about that vote, and proceed with accepting A)Confirm A if every node in a quorum slice accepted AEach consensus round is separated into two stages:Nomination protocolIn the nomination protocol, candidate transaction sets are selected to be included in a ledger. Once a node confirms its first candidate, it stops voting to nominate any new transaction sets. It may still accept or confirm previously nominated statements. This guarantees that at some point, all nodes will converge on a candidate set. If every node on the network stops introducing new values but continues to confirm what other nodes confirmed, eventually, everyone will end up with the same list of candidates.A node may start the ballot protocol as soon as it confirms a candidate. After it confirms its first candidate and starts the ballot protocol, nomination continues running in the background.Ballot protocolThe ballot protocol ensures that the network can unanimously confirm and apply nominated transaction sets. It consists of two steps:Prepare - verifies that a node’s quorum slice has the right value and is willing to commit itCommit - ensures that a node’s quorum slice actually commits the value","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-consensus-protocol","title":"Stellar Consensus Protocol (SCP)","contentLength":1004}},{"pageContent":"Stellar StackThe Stellar stack is made up of four software components (Stellar Core, Horizon API, SDKs, and the testnet & pubnet), each of which plays a specific part in providing financial infrastructure that is resilient to failures, available to anyone, and fast and cheap enough to serve real-world use cases.Stellar Core​Stellar Core is the program used by the individual nodes (or computers) that make up the network. Stellar Core keeps a common distributed ledger and engages in consensus to validate and process transactions. Generally, nodes reach consensus, apply a transaction set, and update the ledger every 5-7 seconds.Nodes reach consensus using the Stellar Consensus Protocol, which can you can learn more about here: Stellar Consensus ProtocolAnyone can run a Stellar Core node, but you don’t have to in order to build on Stellar. We recommend you do so if you issue an asset and want to ensure the accuracy of the ledger and/or if you want to contribute to Stellar’s overall health and decentralization. Check out our tutorial on installing, configuring, and maintaining your own node here: Run a Core Node TutorialHorizon API​Horizon is the client-facing RESTful HTTP API server that allows programmatic access to submit transactions and query the network’s historical data. It acts as the interface for applications that want to access the Stellar network. You can communicate with Horizon using an SDK, a web browser, or with simple command tools like cURL.You do not need to run your own Horizon instance — when you're getting started, you can use the free SDF Horizon instance to access the network — but it is recommended that you do when you’re ready to launch a finished product. Check out how to do so here: Run an API Server TutorialLearn all there is to know about using Horizon in the Horizon API Reference documentation.SDKs​SDKs simplify some of the work of accessing Horizon by converting the data into friendlier formats and allowing you to program in the language of your choice. Stellar’s SDKs show you how to request data and create and submit transactions.Check out our SDK library to access our SDKs and their documentation.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-stack","title":"Stellar Stack","contentLength":368}},{"pageContent":"Testnet and PubnetStellar has two networks: the public network (Pubnet, also called Mainnet) and the test network (Testnet). The Pubnet is the main network used by applications in production. It connects to real rails and requires XLM to cover minimum balances and transaction fees. The Testnet is a smaller, free-to-use network maintained by SDF that functions like the Pubnet but doesn’t connect to real money. It has a built-in testnet XLM faucet, and it's the best place for developers to test their applications.Stats: Testnet versus Pubnet​Testnet​SDF runs three core validator nodesSDF offers a free Horizon instance you can use to interact with the TestnetFriendbot is a faucet you can use for free Testnet XLMTestnet is limited to 100 operations per ledgerPubnet​Validator nodes are run by the publicSDF offers a free Horizon instance to interact with the Pubnet, or you can run your ownYou need to fund your account with XLM from another accountPubnet is limited to 1,000 operations per ledgerFriendbot​Friendbot is a bot that funds accounts with fake XLM on Testnet. You can request XLM from friendbot using the Stellar Laboratory or with various SDKs. Requests to friendbot are rate limited, so use it wisely. Friendbot provides 10,000 fake XLM when funding a new Testnet account.If you are creating multiple Testnet accounts, fund your first account with friendbot and then use that first account to fund your subsequent accounts using the Create Account operation.Testnet data reset​The Testnet is reset periodically to the genesis ledger to declutter the network, remove spam, reduce the time needed to catch up on the latest ledger, and help maintain the system. Resets clear all ledger entries (accounts, trustlines, offers, etc.), transactions, and historical data from Stellar Core and Horizon- which is why developers should not rely on the persistence of accounts or the state of any balances when using Testnet.Testnet resets happen once per quarter at 0900 UTC and are announced at least two weeks in advance on the Stellar Dashboard and through several developer community channels. Here are the 2023 dates:March 15, 2023 June 14, 2023 September 13, 2023 December 13, 2023If you run a Testnet Horizon instance, you need to re-join and re-sync to the network after a reset. Check out how to do that here: Testnet Reset.Test data automation​It is recommended that you have testing infrastructure that can repopulate the Testnet with useful data after a reset. This will make testing more reliable and will help you scale your testing infrastructure to a private network if you choose to do so. For example, you may want to:Generate issuers of assets for testing the development of a walletGenerate orders on the order book (both current and historical) for testing the development of a trading clientRecreate liquidity poolsIf you maintain an application, you should think about creating a data set that is representative enough to test your primary use cases, and allow for robust testing even when Testnet is not available.A script can automate this entire process by creating an account with friendbot and submitting a set of transactions that are predefined as a part of your testing infrastructure.What Testnet should and should not be used for​Testnet is good for​Creating test accounts (with funding from friendbot)Developing applications and exploring tutorials on Stellar without the potential to lose any assetsTesting existing applications against new releases or release candidates of Stellar Core and HorizonPerforming data analysis on a smaller, non-trivial data set compared to the PubnetTestnet is bad for​Load and stress testingHigh availability test infrastructure- SDF does not guarantee Testnet availabilityLong-term storage of data on the network since the network resets periodicallyA testing infrastructure that requires more control over the test environment, such as:The ability to control the data reset frequencyThe need to secure private or sensitive data (before launching on the Pubnet) You can always run your own test network for use cases that don’t work well with SDF’s Testnet.Moving your project from Testnet to production​The Pubnet and Testnet each have their own unique passphrase, which is used to validate signatures on a given transaction.The current passphrases for the Stellar Pubnet and Testnet are:Pubnet: 'Public Global Stellar Network ; September 2015'Testnet: 'Test SDF Network ; September 2015'For applications that don’t rely on the state of the network (such as specific accounts needing to exist), you move to production by changing the network passphrase and ensuring your Horizon instance is connected to Pubnet.If you’ve been running a Stellar Core or Horizon instance against the Testnet and want to switch to production, changing the passphrase will require both respective databases to be completely reinitialized.To learn more about network passphrases, see our Network Passphrase Encyclopedia Entry","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/testnet-and-pubnet","title":"Testnet and Pubnet","contentLength":809}},{"pageContent":"List of OperationsOperations are objects that represent a desired change to the ledger and are submitted to the network grouped in a transaction. For each operation, there is a successful or failed result type. In the case of success, the user can gather information about the effect of the operation. In the case of failure, the user can learn more about the error.Learn more about transactions and operations in our Transaction and Operations section.There are currently 23 operations you can use on the Stellar network, these operations, their definitions, SDKs, thresholds, parameters, and errors are listed below.Create account​Creates and funds a new account with the specified starting balanceSDKs: JavaScript | Java | Go Threshold: Medium Result: CreateAccountResult Parameters:ParameterTypeDescriptionDestinationaccount IDAccount address that is created and funded.Starting BalanceintegerAmount of XLM to send to the newly created account. This XLM comes from the source account.Possible errors:ErrorCodeDescriptionCREATE_ACCOUNT_MALFORMED-1The destination is invalid.CREATE_ACCOUNT_UNDERFUNDED-2The source account performing the command does not have enough funds to give destination the starting balance amount of XLM and still maintain its minimum XLM reserve plus satisfy its XLM selling liabilities.CREATE_ACCOUNT_LOW_RESERVE-3This operation would create an account with fewer than the minimum number of XLM an account must hold.CREATE_ACCOUNT_ALREADY_EXIST-4The destination account already exists.Payment​Sends an amount in a specific asset to a destination accountSDKs: JavaScript | Java | Go Threshold: Medium Result: PaymentResult Parameters:ParametersTypeDescriptionDestinationaccount IDAccount address that receives the payment.AssetassetAsset to send to the destination account.AmountintegerAmount of the aforementioned asset to send.Possible errors:ErrorCodeDescriptionPAYMENT_MALFORMED-1The input to the payment is invalid.PAYMENT_UNDERFUNDED-2The source account (sender) does not have enough funds to send amount and still satisfy its selling liabilities. Note that if sending XLM then the sender must additionally maintain its minimum XLM reserve.PAYMENT_SRC_NO_TRUST-3The source account does not trust the issuer of the asset it is trying to send.PAYMENT_SRC_NOT_AUTHORIZED-4The source account is not authorized to send this payment.PAYMENT_NO_DESTINATION-5The receiving account does not exist. Note that this error will not be returned if the receiving account is the issuer of asset.PAYMENT_NO_TRUST-6The receiver does not trust the issuer of the asset being sent. For more information, see the Assets section.PAYMENT_NOT_AUTHORIZED-7The destination account is not authorized by the asset's issuer to hold the asset.PAYMENT_LINE_FULL-8The destination account (receiver) does not have sufficient limits to receive amount and still satisfy its buying liabilities.Path payment strict send​A payment where the asset sent can be different than the asset received; allows the user to specify the amount of the asset to sendLearn more about path payments: Path Payments Encyclopedia EntrySDKs: JavaScript | Java | Go Threshold: Medium Result: PathPaymentStrictSendResult Parameters:ParametersTypeDescriptionSend assetassetThe asset deducted from the sender's account.Send amountintegerThe amount of send asset to deduct (excluding fees).Destinationaccount IDAccount ID of the recipient.Destination assetassetThe asset the destination account receives.Destination minintegerThe minimum amount of destination asset the destination account can receive.Pathlist of assetsThe assets (other than send asset and destination asset) involved in the offers the path takes. For example, if you can only find a path from USD to EUR through XLM and BTC, the path would be USD -> XLM -> BTC -> EUR and the path field would contain XLM and BTC.Possible errors:ErrorCodeDescriptionPATH_PAYMENT_STRICT_SEND_MALFORMED-1The input to this path payment is invalid.PATH_PAYMENT_STRICT_SEND_UNDERFUNDED-2The source account (sender) does not have enough funds to send and still satisfy its selling liabilities. Note that if sending XLM then the sender must additionally maintain its minimum XLM reserve.PATH_PAYMENT_STRICT_SEND_SRC_NO_TRUST-3The source account does not trust the issuer of the asset it is trying to send.PATH_PAYMENT_STRICT_SEND_SRC_NOT_AUTHORIZED-4The source account is not authorized to send this payment.PATH_PAYMENT_STRICT_SEND_NO_DESTINATION-5The destination account does not exist.PATH_PAYMENT_STRICT_SEND_NO_TRUST-6The destination account does not trust the issuer of the asset being sent. For more, see the Assets section.PATH_PAYMENT_STRICT_SEND_NOT_AUTHORIZED-7The destination account is not authorized by the asset's issuer to hold the asset.PATH_PAYMENT_STRICT_SEND_LINE_FULL-8The destination account does not have sufficient limits to receive destination amount and still satisfy its buying liabilities.PATH_PAYMENT_STRICT_SEND_TOO_FEW_OFFERS-10There is no path of offers connecting the send asset and destination asset. Stellar only considers paths of length 5 or shorter.PATH_PAYMENT_STRICT_SEND_OFFER_CROSS_SELF-11The payment would cross one of its own offers.PATH_PAYMENT_STRICT_SEND_UNDER_DESTMIN-12The paths that could send destination amount of destination asset would fall short of destination min.Path payment strict receive​A payment where the asset received can be different from the asset sent; allows the user to specify the amount of the asset receivedLearn more about path payments: Path Payments Encyclopedia EntrySDKs: JavaScript | Java | Go Threshold: Medium Result: PathPaymentStrictReceiveResult Parameters:ParametersTypeDescriptionSend assetassetThe asset deducted from the sender's account.Send maxintegerThe maximum amount of send asset to deduct (excluding fees).Destinationaccount IDAccount ID of the recipient.Destination assetassetThe asset the destination account receives.Destination amountintegerThe amount of destination asset the destination account receives.Pathlist of assetsThe assets (other than send asset and destination asset) involved in the offers the path takes. For example, if you can only find a path from USD to EUR through XLM and BTC, the path would be USD -> XLM -> BTC -> EUR and the path field would contain XLM and BTC.Possible errors:ErrorCodeDescriptionPATH_PAYMENT_STRICT_RECEIVE_MALFORMED-1The input to this path payment is invalid.PATH_PAYMENT_STRICT_RECEIVE_UNDERFUNDED-2The source account (sender) does not have enough funds to send and still satisfy its selling liabilities. Note that if sending XLM then the sender must additionally maintain its minimum XLM reserve.PATH_PAYMENT_STRICT_RECEIVE_SRC_NO_TRUST-3The source account does not trust the issuer of the asset it is trying to send.PATH_PAYMENT_STRICT_RECEIVE_SRC_NOT_AUTHORIZED-4The source account is not authorized to send this payment.PATH_PAYMENT_STRICT_RECEIVE_NO_DESTINATION-5The destination account does not exist.PATH_PAYMENT_STRICT_RECEIVE_NO_TRUST-6The destination account does not trust the issuer of the asset being sent. For more, see the Assets section.PATH_PAYMENT_STRICT_RECEIVE_NOT_AUTHORIZED-7The destination account is not authorized by the asset's issuer to hold the asset.PATH_PAYMENT_STRICT_RECEIVE_LINE_FULL-8The destination account does not have sufficient limits to receive destination amount and still satisfy its buying liabilities.PATH_PAYMENT_STRICT_RECEIVE_TOO_FEW_OFFERS-10There is no path of offers connecting the send asset and destination asset. Stellar only considers paths of length 5 or shorter.PATH_PAYMENT_STRICT_RECEIVE_OFFER_CROSS_SELF-11The payment would cross one of its own offers.PATH_PAYMENT_STRICT_RECEIVE_OVER_SENDMAX-12The paths that could send destination amount of destination asset would exceed send max.Manage buy offer​Creates, updates, or deletes an offer to buy a specific amount of an asset for anotherLearn more about passive sell offers: Liquidity on Stellar: SDEX and Liquidity PoolsSDKs: JavaScript | Java | Go Threshold: Medium Result: ManageBuyOfferResult Parameters:ParametersTypeDescriptionSellingassetAsset the offer creator is selling.BuyingassetAsset the offer creator is buying.AmountintegerAmount of buying being bought. Set to 0 if you want to delete an existing offer.Price{numerator, denominator}Price of 1 unit of buying in terms of selling. For example, if you wanted to buy 30 XLM and sell 5 BTC, the price would be {5,30}.Offer IDunsigned integerThe ID of the offer. 0 for new offer. Set to existing offer ID to update or delete.Possible errors:ErrorCodeDescriptionMANAGE_BUY_OFFER_MALFORMED-1The input is incorrect and would result in an invalid offer.MANAGE_BUY_OFFER_SELL_NO_TRUST-2The account creating the offer does not have a trustline for the asset it is selling.MANAGE_BUY_OFFER_BUY_NO_TRUST-3The account creating the offer does not have a trustline for the asset it is buying.MANAGE_BUY_OFFER_BUY_NOT_AUTHORIZED-4The account creating the offer is not authorized to sell this asset.MANAGE_BUY_OFFER_SELL_NOT_AUTHORIZED-5The account creating the offer is not authorized to buy this asset.MANAGE_BUY_OFFER_LINE_FULL-6The account creating the offer does not have sufficient limits to receive buying and still satisfy its buying liabilities.MANAGE_BUY_OFFER_UNDERFUNDED-7The account creating the offer does not have sufficient limits to send selling and still satisfy its selling liabilities. Note that if selling XLM then the account must additionally maintain its minimum XLM reserve, which is calculated assuming this offer will not completely execute immediately.MANAGE_BUY_OFFER_CROSS_SELF-8The account has opposite offer of equal or lesser price active, so the account creating this offer would immediately cross itself.MANAGE_BUY_OFFER_NOT_FOUND-11An offer with that offerID cannot be found.MANAGE_BUY_OFFER_LOW_RESERVE-12The account creating this offer does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a subentry and still satisfy its XLM selling liabilities. For every offer an account creates, the minimum amount of XLM that account must hold will increase.Manage sell offer​Creates, updates, or deletes an offer to sell a specific amount of an asset for anotherLearn more about passive sell offers: Liquidity on Stellar: SDEX and Liquidity PoolsSDKs: JavaScript | Java | Go Threshold: Medium Result: ManageSellOfferResult Parameters:ParametersTypeDescriptionSellingassetAsset the offer creator is selling.BuyingassetAsset the offer creator is buying.AmountintegerAmount of selling being sold. Set to 0 if you want to delete an existing offer.Price{numerator, denominator}Price of 1 unit of selling in terms of buying. For example, if you wanted to sell 30 XLM and buy 5 BTC, the price would be {5,30}.Offer IDunsigned integerThe ID of the offer. 0 for new offer. Set to existing offer ID to update or delete.Possible errors:ErrorCodeDescriptionMANAGE_SELL_OFFER_MALFORMED-1The input is incorrect and would result in an invalid offer.MANAGE_SELL_OFFER_SELL_NO_TRUST-2The account creating the offer does not have a trustline for the asset it is selling.MANAGE_SELL_OFFER_BUY_NO_TRUST-3The account creating the offer does not have a trustline for the asset it is buying.MANAGE_SELL_OFFER_SELL_NOT_AUTHORIZED-4The account creating the offer is not authorized to sell this asset.MANAGE_SELL_OFFER_BUY_NOT_AUTHORIZED-5The account creating the offer is not authorized to buy this asset.MANAGE_SELL_OFFER_LINE_FULL-6The account creating the offer does not have sufficient limits to receive buying and still satisfy its buying liabilities.MANAGE_SELL_OFFER_UNDERFUNDED-7The account creating the offer does not have sufficient limits to send selling and still satisfy its selling liabilities. Note that if selling XLM then the account must additionally maintain its minimum XLM reserve, which is calculated assuming this offer will not completely execute immediately.MANAGE_SELL_OFFER_CROSS_SELF-8The account has opposite offer of equal or lesser price active, so the account creating this offer would immediately cross itself.MANAGE_SELL_OFFER_NOT_FOUND-11An offer with that offerID cannot be found.MANAGE_SELL_OFFER_LOW_RESERVE-12The account creating this offer does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a subentry and still satisfy its XLM selling liabilities. For every offer an account creates, the minimum amount of XLM that account must hold will increase.Create passive sell offer​Creates an offer to sell one asset for another without taking a reverse offer of equal priceLearn more about passive sell offers: Liquidity on Stellar: SDEX and Liquidity PoolsSDKs: JavaScript | Java | Go Threshold: Medium Result: ManageSellOfferResult Parameters:ParametersTypeDescriptionSellingassetAsset the offer creator is selling.BuyingassetAsset the offer creator is buying.AmountintegerAmount of selling being sold.Price{numerator, denominator}Price of 1 unit of selling in terms of buying. For example, if you wanted to sell 30 XLM and buy 5 BTC, the price would be {5,30}.Possible errors:ErrorCodeDescriptionMANAGE_SELL_OFFER_MALFORMED-1The input is incorrect and would result in an invalid offer.MANAGE_SELL_OFFER_SELL_NO_TRUST-2The account creating the offer does not have a trustline for the asset it is selling.MANAGE_SELL_OFFER_BUY_NO_TRUST-3The account creating the offer does not have a trustline for the asset it is buying.MANAGE_SELL_OFFER_SELL_NOT_AUTHORIZED-4The account creating the offer is not authorized to sell this asset.MANAGE_SELL_OFFER_BUY_NOT_AUTHORIZED-5The account creating the offer is not authorized to buy this asset.MANAGE_SELL_OFFER_LINE_FULL-6The account creating the offer does not have sufficient limits to receive buying and still satisfy its buying liabilities.MANAGE_SELL_OFFER_UNDERFUNDED-7The account creating the offer does not have sufficient limits to send selling and still satisfy its selling liabilities. Note that if selling XLM then the account must additionally maintain its minimum XLM reserve, which is calculated assuming this offer will not completely execute immediately.MANAGE_SELL_OFFER_CROSS_SELF-8The account has opposite offer of equal or lesser price active, so the account creating this offer would immediately cross itself.MANAGE_SELL_OFFER_NOT_FOUND-11An offer with that offerID cannot be found.MANAGE_SELL_OFFER_LOW_RESERVE-12The account creating this offer does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a subentry and still satisfy its XLM selling liabilities. For every offer an account creates, the minimum amount of XLM that account must hold will increase.Set options​Set options for an account such as flags, inflation destination, signers, home domain, and master key weightLearn more about flags: Flags Encyclopedia Entry Learn more about the home domain: Stellar Ecosystem Proposals SEP-0001 Learn more about signers operations and key weight: Signature and Multisignature Encyclopedia EntrySDKs: JavaScript | Java | Go Threshold: High (when updating signers or other thresholds) or Medium (when updating everything else) Result: SetOptionsResult Parameters:ParametersTypeDescriptionInflation Destinationaccount IDAccount of the inflation destination.Clear flagsintegerIndicates which flags to clear. For details about the flags, please refer to the Accounts section. The bit mask integer subtracts from the existing flags of the account. This allows for setting specific bits without knowledge of existing flags.Set flagsintegerIndicates which flags to set. For details about the flags, please refer to the Accounts section. The bit mask integer adds onto the existing flags of the account. This allows for setting specific bits without knowledge of existing flags.Master weightintegerA number from 0-255 (inclusive) representing the weight of the master key. If the weight of the master key is updated to 0, it is effectively disabled.Low thresholdintegerA number from 0-255 (inclusive) representing the threshold this account sets on all operations it performs that have a low threshold.Medium thresholdintegerA number from 0-255 (inclusive) representing the threshold this account sets on all operations it performs that have a medium threshold.High thresholdintegerA number from 0-255 (inclusive) representing the threshold this account sets on all operations it performs that have a high threshold.Home domainstringSets the home domain of an account. See Federation.Signer{Public Key, weight}Add, update, or remove a signer from an account. Signer weight is a number from 0-255 (inclusive). The signer is deleted if the weight is 0.Possible errors:ErrorCodeDescriptionSET_OPTIONS_LOW_RESERVE-1This account does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a subentry and still satisfy its XLM selling liabilities. For every new signer added to an account, the minimum reserve of XLM that account must hold increases.SET_OPTIONS_TOO_MANY_SIGNERS-220 is the maximum number of signers an account can have, and adding another signer would exceed that.SET_OPTIONS_BAD_FLAGS-3The flags set and/or cleared are invalid by themselves or in combination.SET_OPTIONS_INVALID_INFLATION-4The destination account set in the inflation field does not exist.SET_OPTIONS_CANT_CHANGE-5This account can no longer change the option it wants to change.SET_OPTIONS_UNKNOWN_FLAG-6The account is trying to set a flag that is unknown.SET_OPTIONS_THRESHOLD_OUT_OF_RANGE-7The value for a key weight or threshold is invalid.SET_OPTIONS_BAD_SIGNER-8Any additional signers added to the account cannot be the master key.SET_OPTIONS_INVALID_HOME_DOMAIN-9Home domain is malformed.Change trust​Creates, updates, or deletes a trustlineLearn more about trustlines: Trustlines sectionSDKs: JavaScript | Java | Go Threshold: Medium Result: ChangeTrustResult Parameters:ParametersTypeDescriptionLineChangeTrustAssetThe asset of the trustline. For example, if a user extends a trustline of up to 200 USD to an anchor, the line is USD:anchor.LimitintegerThe limit of the trustline. In the previous example, the limit would be 200.Possible errors:ErrorCodeDescriptionCHANGE_TRUST_MALFORMED-1The input to this operation is invalid.CHANGE_TRUST_NO_ISSUER-2The issuer of the asset cannot be found.CHANGE_TRUST_INVALID_LIMIT-3The limit is not sufficient to hold the current balance of the trustline and still satisfy its buying liabilities. This error occurs when attempting to remove a trustline with a non-zero asset balance.CHANGE_TRUST_LOW_RESERVE-4This account does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a subentry and still satisfy its XLM selling liabilities. For every new trustline added to an account, the minimum reserve of XLM that account must hold increases.CHANGE_TRUST_SELF_NOT_ALLOWED-5The source account attempted to create a trustline for itself, which is not allowed.CHANGE_TRUST_TRUST_LINE_MISSING-6The asset trustline is missing for the liquidity pool.CHANGE_TRUST_CANNOT_DELETE-7The asset trustline is still referenced by a liquidity pool.CHANGE_TRUST_NOT_AUTH_MAINTAIN_LIABILITIES-8The asset trustline is deauthorized.Allow trust​Updates the authorized flag of an existing trustlineThis operation is deprecated as of Protocol 17- prefer SetTrustlineFlags insteadSDKs: JavaScript | Java | Go Threshold: Low Result: AllowTrustResult Parameters:ParametersTypeDescriptionTrustoraccount IDThe account of the recipient of the trustline.Typeasset codeThe 4 or 12 character-maximum asset code of the trustline the source account is authorizing. For example, if an issuing account wants to allow another account to hold its USD credit, the type is USD.AuthorizeintegerFlag indicating whether the trustline is authorized. 1 if the account is authorized to transact with the asset. 2 if the account is authorized to maintain offers, but not to perform other transactionsPossible errors:ErrorCodeDescriptionALLOW_TRUST_MALFORMED-1The asset specified in type is invalid. In addition, this error happens when the native asset is specified.ALLOW_TRUST_NO_TRUST_LINE-2The trustor does not have a trustline with the issuer performing this operation.ALLOW_TRUST_TRUST_NOT_REQUIRED-3The source account (issuer performing this operation) does not require trust. In other words, it does not have the flag AUTH_REQUIRED_FLAG set.ALLOW_TRUST_CANT_REVOKE-4The source account is trying to revoke the trustline of the trustor, but it cannot do so.ALLOW_TRUST_SELF_NOT_ALLOWED-5The source account attempted to allow a trustline for itself, which is not allowed because an account cannot create a trustline with itself.ALLOW_TRUST_LOW_RESERVE-6Claimable balances can't be created on revocation of asset (or pool share) trustlines associated with a liquidity pool due to low reserves.Account merge​Transfers the XLM balance of an account to another account and removes the source account from the ledgerSDKs: JavaScript | Java | Go Threshold: High Result: AccountMergeResult Parameters:ParametersTypeDescriptionDestinationaccount IDThe account that receives the remaining XLM balance of the source account.Possible errors:ErrorCodeDescriptionACCOUNT_MERGE_MALFORMED-1The operation is malformed because the source account cannot merge with itself. The destination must be a different account.ACCOUNT_MERGE_NO_ACCOUNT-2The destination account does not exist.ACCOUNT_MERGE_IMMUTABLE_SET-3The source account has AUTH_IMMUTABLE flag set.ACCOUNT_MERGE_HAS_SUB_ENTRIES-4The source account has trustlines/offers.ACCOUNT_MERGE_SEQNUM_TOO_FAR-5Source's account sequence number is too high. It must be less than (ledgerSeq << 32) = (ledgerSeq * 0x100000000).ACCOUNT_MERGE_DEST_FULL-6The destination account cannot receive the balance of the source account and still satisfy its lumen buying liabilities.ACCOUNT_MERGE_IS_SPONSOR-7The source account is a sponsor.Manage data​Sets, modifies, or deletes a data entry (name/value pair) that is attached to an accountLearn more about entries and subentries: Accounts sectionSDKs: JavaScript | Java | Go Threshold: Medium Result: ManageDataResult Parameters:ParametersTypeDescriptionNamestringString up to 64 bytes long. If this is a new Name it will add the given name/value pair to the account. If this Name is already present then the associated value will be modified.Valuebinary data(optional) If not present then the existing Name will be deleted. If present then this value will be set in the DataEntry. Up to 64 bytes long.Possible errors:ErrorCodeDescriptionMANAGE_DATA_NOT_SUPPORTED_YET-1The network hasn't moved to this protocol change yet. This failure means the network doesn't support this feature yet.MANAGE_DATA_NAME_NOT_FOUND-2Trying to remove a Data Entry that isn't there. This will happen if Name is set (and Value isn't) but the Account doesn't have a DataEntry with that Name.MANAGE_DATA_LOW_RESERVE-3This account does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a subentry and still satisfy its XLM selling liabilities. For every new DataEntry added to an account, the minimum reserve of XLM that account must hold increases.MANAGE_DATA_INVALID_NAME-4Name not a valid string.Bump sequence​Bumps forward the sequence number of the source account to the given sequence number, invalidating any transaction with a smaller sequence numberSDKs: JavaScript | Java | Go Threshold: Low Result: BumpSequenceResult Parameters:ParametersTypeDescriptionbumpToSequenceNumberdesired value for the operation's source account sequence number.Possible errors:ErrorCodeDescriptionBUMP_SEQUENCE_BAD_SEQ-1The specified bumpTo sequence number is not a valid sequence number. It must be between 0 and INT64_MAX (9223372036854775807 or 0x7fffffffffffffff).Create claimable balance​Moves an amount of asset from the operation source account into a new ClaimableBalanceEntryLearn more about claimable balances: Claimable Balances Encyclopedia EntryThreshold: Medium Result: CreateClaimableBalanceResult Parameters:ParametersTypeDescriptionAssetassetAsset that will be held in the ClaimableBalanceEntry in the form asset_code:issuing_address or native (XLM).AmountintegerAmount of asset stored in the ClaimableBalanceEntry.Claimantslist of claimantsList of Claimants (account address and ClaimPredicate pair) that can claim this ClaimableBalanceEntry.Possible errors:ErrorCodeDescriptionCREATE_CLAIMABLE_BALANCE_MALFORMED-1The input to this operation is invalid.CREATE_CLAIMABLE_BALANCE_LOW_RESERVE-2The account creating this entry does not have enough XLM to satisfy the minimum XLM reserve increase caused by adding a ClaimableBalanceEntry. For every claimant in the list, the minimum amount of XLM this account must hold will increase by baseReserve.CREATE_CLAIMABLE_BALANCE_NO_TRUST-3The source account does not trust the issuer of the asset it is trying to include in the ClaimableBalanceEntry.CREATE_CLAIMABLE_BALANCE_NOT_AUTHORIZED-4The source account is not authorized to transfer this asset.CREATE_CLAIMABLE_BALANCE_UNDERFUNDED-5The source account does not have enough funds to transfer amount of this asset to the ClaimableBalanceEntry.Claim claimable balance​Claims a ClaimableBalanceEntry that corresponds to the BalanceID and adds the amount of an asset on the entry to the source accountLearn more about claimable balances and view more parameters: Claimable Balances Encyclopedia EntryThreshold: Low Result: ClaimClaimableBalanceResult Parameters:ParametersTypeDescriptionBalanceIDclaimableBalanceIDBalanceID on the ClaimableBalanceEntry that the source account is claiming. The balanceID can be retrieved from a successful CreateClaimableBalanceResult. See Claimable Balance Encyclopedia Entry for more information.Possible errors:ErrorCodeDescriptionCLAIM_CLAIMABLE_BALANCE_DOES_NOT_EXIST-1There is no existing ClaimableBalanceEntry that matches the input BalanceID.CLAIM_CLAIMABLE_BALANCE_CANNOT_CLAIM-2There is no claimant that matches the source account, or the claimants predicate is not satisfied.CLAIM_CLAIMABLE_BALANCE_LINE_FULL-3The account claiming the ClaimableBalanceEntry does not have sufficient limits to receive amount of the asset and still satisfy its buying liabilities.CLAIM_CLAIMABLE_BALANCE_NO_TRUST-4The source account does not trust the issuer of the asset it is trying to claim in the ClaimableBalanceEntry.CLAIM_CLAIMABLE_BALANCE_NOT_AUTHORIZED-5The source account is not authorized to claim the asset in the ClaimableBalanceEntry.Begin sponsoring future reserves​Allows an account to pay the base reserves for another account; sponsoring account establishes the is-sponsoring-future-reserves relationshipThere must also be an end sponsoring future reserves operation in the same transactionLearn more about sponsored reserves: Sponsored Reserves Encyclopedia EntryThreshold: Medium Result: BeginSponsoringFutureReservesResult Parameters:ParametersTypeDescriptionSponsoredIDaccount IDAccount that will have its reserves sponsored.Possible errors:ErrorCodeDescriptionBEGIN_SPONSORING_FUTURE_RESERVES_MALFORMED-1Source account is equal to sponsoredID.BEGIN_SPONSORING_FUTURE_RESERVES_ALREADY_SPONSORED-2Source account is already sponsoring sponsoredID.BEGIN_SPONSORING_FUTURE_RESERVES_RECURSIVE-3Either source account is currently being sponsored, or sponsoredID is sponsoring another account.End sponsoring future reserves​Terminates the current is-sponsoring-future-reserves relationship in which the source account is sponsoredLearn more about sponsored reserves: Sponsored Reserves Encyclopedia EntryThreshold: Medium Result: EndSponsoringFutureReservesResult Parameters:ParametersTypeDescriptionbegin_sponsoraccount IDThe id of the account which initiated the sponsorship.Possible errors:ErrorCodeDescriptionEND_SPONSORING_FUTURE_RESERVES_NOT_SPONSORED-1Source account is not sponsored.Revoke sponsorship​Sponsoring account can remove or transfer sponsorships of existing ledgerEntries and signers; the logic of this operation depends on the state of the source accountLearn more about sponsored reserves: Sponsored Reserves Encyclopedia EntryThreshold: Medium Result: RevokeSponsorshipResultThis operation is a union with two possible types:Union TypeParametersTypeDescriptionREVOKE_SPONSORSHIP_LEDGER_ENTRYLedgerKeyledgerKeyLedger key that holds information to identify a specific ledgerEntry that may have its sponsorship modified. See LedgerKey for more information.OrUnion TypeParametersTypeDescriptionREVOKE_SPONSORSHIP_SIGNERSigner{account ID, Signer Key}Signer that may have its sponsorship modified.Possible errors:ErrorCodeDescriptionREVOKE_SPONSORSHIP_DOES_NOT_EXIST-1The ledgerEntry for LedgerKey doesn’t exist, the account ID on signer doesn’t exist, or the Signer Key doesn’t exist on account ID’s account.REVOKE_SPONSORSHIP_NOT_SPONSOR-2If the ledgerEntry/signer is sponsored, then the source account must be the sponsor. If the ledgerEntry/signer is not sponsored, the source account must be the owner. This error will be thrown otherwise.REVOKE_SPONSORSHIP_LOW_RESERVE-3The sponsored account does not have enough XLM to satisfy the minimum balance increase caused by revoking sponsorship on a ledgerEntry/signer it owns, or the sponsor of the source account doesn’t have enough XLM to satisfy the minimum balance increase caused by sponsoring a transferred ledgerEntry/signer.REVOKE_SPONSORSHIP_ONLY_TRANSFERABLE-4Sponsorship cannot be removed from this ledgerEntry. This error will happen if the user tries to remove the sponsorship from a ClaimableBalanceEntry.REVOKE_SPONSORSHIP_MALFORMED-5One or more of the inputs to the operation was malformed.Clawback​Burns an amount in a specific asset from a receiving accountLearn more about clawbacks: Clawback Encyclopedia EntrySDKs: JavaScript | Java | Go Threshold: Medium Result: ClawbackResult Parameters:ParametersTypeDescriptionFromaccount IDAccount address that receives the clawback.AssetassetAsset held by the destination account.AmountintegerAmount of the aforementioned asset to burn.Possible errors:ErrorCodeDescriptionCLAWBACK_MALFORMED-1The input to the clawback is invalid.CLAWBACK_NOT_CLAWBACK_ENABLED-2The trustline between From and the issuer account for this Asset does not have clawback enabled.CLAWBACK_NO_TRUST-3The From account does not trust the issuer of the asset.CLAWBACK_UNDERFUNDED-4The From account does not have a sufficient available balance of the asset (after accounting for selling liabilities).Clawback claimable balance​Claws back an unclaimed ClaimableBalanceEntry, burning the pending amount of the assetLearn more about clawbacks: Clawback Encyclopedia EntryLearn more about claimable balances: Claimable Balances Encyclopedia EntryThreshold: Medium Result: ClaimClaimableBalanceResult Parameters:ParametersTypeDescriptionBalanceIDclaimableBalanceIDThe BalanceID on the ClaimableBalanceEntry that the source account is claiming, which can be retrieved from a succesful CreateClaimableBalanceResultPossible errors:ErrorCodeDescriptionCLAWBACK_CLAIMABLE_BALANCE_DOES_NOT_EXIST-1There is no existing ClaimableBalanceEntry that matches the input BalanceID.CLAWBACK_CLAIMABLE_BALANCE_NOT_ISSUER-2The source account is not the issuer of the asset in the claimable balance.CLAWBACK_CLAIMABLE_BALANCE_NOT_CLAWBACK_ENABLED-3The CLAIMABLE_BALANCE_CLAWBACK_ENABLED_FLAG is not set for this trustline.Set trustline flags​Allows issuing account to configure authorization and trustline flags to an assetThe Asset parameter is of the TrustLineAsset type. If you are modifying a trustline to a regular asset (i.e. one in a Code:Issuer format), this is equivalent to the Asset type. If you are modifying a trustline to a pool share, however, this is composed of the liquidity pool's unique ID.Learn more about flags: Flags Glossary EntryThreshold: Low Result: SetTrustLineFlagsResult Parameters:ParametersTypeDescriptionTrustoraccount IDThe account that established this trustline.AssetTrustLineAssetThe asset trustline whose flags are being modified.SetFlagsintegerOne or more flags (combined via bitwise-OR) indicating which flags to set. Possible flags are: 1 if the trustor is authorized to transact with the asset or 2 if the trustor is authorized to maintain offers but not to perform other transactions.ClearFlagsintegerOne or more flags (combined via bitwise OR) indicating which flags to clear. Possibilities include those for SetFlags as well as 4, which prevents the issuer from clawing back its asset (both from accounts and claimable balances).Possible errors:ErrorCodeDescriptionSET_TRUST_LINE_FLAGS_MALFORMED-1This can happen for a number of reasons: the asset specified by AssetCode and AssetIssuer is invalid; the asset issuer isn't the source account; the Trustor is the source account; the native asset is specified; or the flags being set/cleared conflict or are otherwise invalid.SET_TRUST_LINE_FLAGS_NO_TRUST_LINE-2The Trustor does not have a trustline with the issuer performing this operation.SET_TRUST_LINE_FLAGS_CANT_REVOKE-3The issuer is trying to revoke the trustline authorization of Trustor, but it cannot do so because AUTH_REVOCABLE_FLAG is not set on the account.SET_TRUST_LINE_FLAGS_INVALID_STATE-4If the final state of the trustline has both AUTHORIZED_FLAG (1) and AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG (2) set, which are mutually exclusive.SET_TRUST_LINE_FLAGS_LOW_RESERVE-5Claimable balances can't be created on revocation of asset (or pool share) trustlines associated with a liquidity pool due to low reserves.Liquidity pool deposit​Deposits assets into a liquidity pool, increasing the reserves of a liquidity pool in exchange for pool sharesParameters to this operation depend on the ordering of assets in the liquidity pool: “A” refers to the first asset in the liquidity pool, and “B” refers to the second asset in the liquidity pool.If the pool is empty, then this operation deposits maxAmountA of A and maxAmountB of B into the pool. If the pool is not empty, then this operation deposits at most maxAmountA of A and maxAmountB of B into the pool. The actual amounts deposited are determined using the current reserves of the pool. You can use these parameters to control a percentage of slippage.Learn more about liquidity pools: Liquidity Pools Encyclopedia EntryThreshold: Medium Result: LiquidityPoolDepositResult Parameters:ParametersTypeDescriptionLiquidity Pool IDliquidityPoolIDThe PoolID for the Liquidity Pool to deposit into.Max Amount AintegerMaximum amount of first asset to deposit.Max Amount BintegerMaximum amount of second asset to deposit.Min Price{numerator, denominator}Minimum depositA/depositB.Max Price{numerator, denominator}Maximum depositA/depositB.Possible errors:ErrorCodeDescriptionLIQUIDITY_POOL_DEPOSIT_MALFORMED-1One or more of the inputs to the operation was malformed.LIQUIDITY_POOL_DEPOSIT_NO_TRUST-2No trustline exists for one of the assets being deposited.LIQUIDITY_POOL_DEPOSIT_NOT_AUTHORIZED-3The account does not have authorization for one of the assets.LIQUIDITY_POOL_DEPOSIT_UNDERFUNDED-4There is not enough balance of one of the assets to perform the deposit.LIQUIDITY_POOL_DEPOSIT_LINE_FULL-5The pool share trustline does not have a sufficient limit.LIQUIDITY_POOL_DEPOSIT_BAD_PRICE-6The deposit price is outside of the given bounds.LIQUIDITY_POOL_DEPOSIT_POOL_FULL-7The liquidity pool reserves are full.Liquidity pool withdraw​Withdraw assets from a liquidity pool, reducing the number of pool shares in exchange for reserves of a liquidity poolThe minAmountA and minAmountB parameters can be used to control a percentage of slippage from the \"spot price\" on the pool.Learn more about liquidity pools: Liquidity Pools Encyclopedia EntryThreshold: Medium Result: LiquidityPoolWithdrawResult Parameters:ParametersTypeDescriptionLiquidity Pool IDliquidityPoolIDThe PoolID for the Liquidity Pool to withdraw from.AmountintegerAmount of pool shares to withdraw.Min Amount AintegerMinimum amount of the first asset to withdraw.Min Amount BintegerMinimum amount of the second asset to withdraw.Possible errors:ErrorCodeDescriptionLIQUIDITY_POOL_WITHDRAW_MALFORMED-1One or more of the inputs to the operation was malformed.LIQUIDITY_POOL_WITHDRAW_NO_TRUST-2There is no trustline for one of the assets.LIQUIDITY_POOL_WITHDRAW_UNDERFUNDED-3Insufficient balance for the pool shares.LIQUIDITY_POOL_WITHDRAW_LINE_FULL-4The withdrawal would exceed the trustline limit for one of the assets.LIQUIDITY_POOL_WITHDRAW_UNDER_MINIMUM-5Unable to withdraw enough to satisfy the minimum price.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/list-of-operations","title":"List of Operations","contentLength":4898}},{"pageContent":"LedgersA ledger represents the state of the Stellar network at a point in time. It is shared across all Core nodes in the network and contains the list of accounts and balances, orders on the distributed exchange, and any other persisting data.In every Stellar Consensus Protocol round, the network reaches consensus on which transaction set to apply to the last closed ledger, and when the new set is applied, a new “last closed ledger” is defined. Each ledger is cryptographically linked to the unique previous ledger, creating a historical chain that goes back to the genesis ledger.Data is stored on the ledger as ledger entries. Possible ledger entries include:AccountsClaimable balancesLiquidity poolsEvery ledger has a ledger header, to read about what is contained in the ledger header, see our Ledger Header Encyclopedia Entry.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-data-structures/ledgers","title":"Ledgers","contentLength":135}},{"pageContent":"AccountsAccounts​Accounts are the central data structure in Stellar- they hold balances, sign transactions, and issue assets. Accounts can only exist with a valid keypair and the required minimum balance of XLM.To learn about minimum balance requirements, see our section on Lumens.Accounts are made up of the below fields. Click on the field to learn more about it.Account IDBalancesFlagsHome Domain (up to 32 characters)LiabilitiesNumber of entries sponsored by this accountNumber of sponsored reservesNumber of subentriesSequence numberSignersThresholdsBase reserves and subentries​Accounts store data in subentries, and each subentry increases the account’s required minimum balance.Base reserves​A base reserve is a unit of measurement used to calculate an account’s minimum balance. One base reserve is currently 0.5 XLM.Subentries​Account data is stored in subentries, each of which increases an account’s minimum balance by one base reserve (0.5 XLM). An account cannot have more than 1,000 subentries. Possible subentries are:Trustlines (includes traditional assets and pool shares)OffersAdditional signersData entriesTrustlines​Trustlines are an explicit opt-in for an account to hold and trade a particular asset. To hold a specific asset, an account must establish a trustline with the issuing account using the change_trust operation. Trustlines track the balance of an asset and can also limit the amount of an asset that an account can hold.A trustline must be established for an account to receive any asset except lumens (XLM). You can create a claimable balance to send assets to an account without a trustline, but the recipient has to create a trustline to claim that balance. Learn more here: Claimable Balances Encyclopedia EntryA trustline also tracks liabilities. Buying liabilities equal the total amount of the asset offered to buy aggregated over all offers owned by an account, and selling liabilities equal the total amount of the asset offered to sell aggregated over all offers owned by an account. A trustline must always have a balance sufficiently large to satisfy its selling liabilities and a balance sufficiently below its limit to accommodate its buying liabilities.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-data-structures/accounts","title":"Accounts","contentLength":345}},{"pageContent":"AssetsAccounts on the Stellar network can be used to track, hold, and transfer any type of asset. Assets can represent many things: cryptocurrencies (such as bitcoin or ether), fiat currencies (such as dollars or pesos), other tokens of value (such as NFTs), pool shares, or even bonds and equity.Assets on Stellar have two identifying characteristics: the asset code and the issuer. Since more than one organization can issue a credit representing the same asset, asset codes often overlap (for example, multiple companies offer a USD token on Stellar). Assets are uniquely identified by the combination of their asset code and issuer.Asset components​Asset code​An asset’s identifying code. There are three different formats: Alphanumeric 4, Alphanumeric 12, and liquidity pool shares.Learn about liquidity pool shares in the Liquidity Pool Encyclopedia Entry.Learn more about asset codes in the Naming an Asset sectionIssuer​There is no dedicated operation to create an asset on Stellar. Instead, assets are created with a payment operation: an issuing account makes a payment using the asset it’s issuing, and that payment creates the asset on the network.The public key of the issuing account is linked on the ledger to the asset. Responsibility for and control over an asset resides with the issuing account. Since settings are stored at the account level on the ledger, the issuing account is where you use set_options operations to link to meta-information about an asset and set authorization flags.Representation​In Horizon, assets are represented in a JSON object:In the Stellar SDKs, they’re represented with the asset class:Amount precision​Each asset amount is encoded as a signed 64-bit integer in the XDR structures that Stellar uses to encode transactions. The asset amount unit seen by end-users is scaled down by a factor of ten million (10,000,000) to arrive at the native 64-bit integer representation.For example, the integer amount value 25,123,456 equals 2.5123456 units of the asset. This scaling allows for seven decimal places of precision in human-friendly amount units.The smallest non-zero amount unit, also known as a stroop, is 0.0000001 (one ten-millionth) represented as an integer value of one. The largest amount unit possible is 263−1107\\frac{2^{63}-1}{10^7}107263−1​ (derived from the maximum 64-bit integer, scaled down) which is 922,337,203,685.4775807.The numbers are represented as int64s. Amount values are stored as only signed integers to avoid bugs that arise from mixing signed and unsigned integers.Relevance in Horizon and Stellar Client Libraries​In Horizon and client-side libraries such as js-stellar-sdk, the integer encoded value is abstracted away. Many APIs expect an amount in unit value (the scaled-up amount displayed to end-users). Some programming languages (such as JavaScript) have problems maintaining precision on a number amount. It is recommended to use “big number” libraries that can record arbitrary-precision decimal numbers without a loss of precision.Deleting or burning assets​To delete, or \"burn\", an asset, you must send it back to the account that issued it.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-data-structures/assets","title":"Assets","contentLength":525}},{"pageContent":"Operations and TransactionsOperations and transactions: how they work​To perform actions with an account on the Stellar network, you compose operations, bundle them into a transaction, and then sign and submit the transaction to the network.Operations​Operations are individual commands that modify the ledger. Operations are used to send payments, enter orders into the decentralized exchange, change settings on accounts, and authorize accounts to hold assets.All operations fall into one of three threshold categories: low, medium, or high, and each threshold category has a weight between 0 and 255 (which can be determined using set_options). Thresholds determine what signature weight is required for the operation to be accepted. For example, let’s say an account sets the medium threshold weight to 5. If the account wants to successfully establish a trustline with the changeTrust operation, the weight of the signature(s) must be greater than or equal to 5.To learn more about signature weight, see the Signature and Multisignature Encyclopedia EntryView a comprehensive list of Stellar operations and their threshold levels in the List of Operations sectionTransactions​The Stellar network encodes transactions using a standardized protocol called External Data Representation (XDR). You can read more about this in our XDR Encyclopedia Entry.Accounts can only perform one transaction at a time.Transactions comprise a bundle of between 1-100 operations and are signed and submitted to the ledger by accounts. Transactions always need to be authorized by the source account’s public key to be valid, which involves signing the transaction object with the public key’s associated secret key. A transaction plus its signature(s) is called a transaction envelope.A transaction may need more than one signature- this happens if it has operations that affect more than one account or if it has a high threshold weight. Check out the Signature and Multisignature Encyclopedia Entry for more information.Transactions are atomic. Meaning if one operation in a transaction fails, all operations fail, and the entire transaction is not applied to the ledger.Operations are executed for the source account of the transaction unless an operation override is defined.Transaction attributes​FeeList of operationsList of signaturesMemo or muxed accountSequence numberSource accountPreconditions (optional)Transaction and operation validity​Before being successfully submitted to the Stellar network, transactions go through several validity checks. These checks are grouped into three categories:Preconditions (optional)​Preconditions are checked first.All preconditions are optional. Time bounds are encouraged, but the other preconditions are used in more specialized circumstances. You can set multiple preconditions as long as the combination is logically sound.Time bounds​Valid if within set time bounds of the transactionTime bounds are an optional UNIX timestamp (in seconds), determined by ledger time, of a lower and upper bound of when a transaction will be valid. If a transaction is submitted too early or too late, it will fail to make it into the transaction set.Setting time bounds on transactions is highly encouraged, and many SDKs enforce them.If maxTime is 0, upper time bounds are not set. In this case, if a transaction does not make it to the transaction set, it is kept in memory and continuously tries to make it to the next transaction set. Because of this, we advise that all transactions are created with time bounds to invalidate transactions after a certain amount of time, especially if you plan to resubmit your transaction at a later time.Ledger bounds​Valid if within the set ledger bounds of the transactionLedger bounds apply to ledger numbers. With these defined, a transaction will only be valid for ledger numbers that fall within the determined range.The lower bound is inclusive (less than or equal to) while the upper bound is not (just greater than).If the upper bound is set to 0, this indicates there is no upper bound.Minimum sequence number​If a minimum sequence number is set, the transaction will only be valid when its source account’s sequence number (call it S) is large enough. Specifically, it’s valid when S satisfies minSeqNum <= S < tx.seqNum.If this precondition is omitted, the default behavior applies: the transaction’s sequence number must be exactly one greater than the account’s sequence number.Note that after a transaction is executed, the account will always set its sequence number to the transaction’s sequence number.Minimum sequence age​Transaction is valid after a particular duration (expressed in seconds) elapses since the account’s sequence number age.Minimum sequence age is a precondition relating to time, but unlike time bounds, which express absolute times, minimum sequence age is relative to when the transaction source account’s sequence number was touched.Minimum sequence ledger gap​Valid if submitted in a ledger meeting or exceeding the source account’s sequence number ageThis is similar to the minimum sequence age, except it is expressed as a number of ledgers rather than a duration of time.Extra signers​Valid if submitted with signatures that fulfill each of the extra signersA transaction can specify up to two extra signers as a precondition, meaning it must have signatures that correspond to those extra signers, even if those signatures would not otherwise be required to authorize the transaction (i.e., for its sources account or operations).The additional signers can be of any type besides the pre-authorized transaction signer since to pre-authorize a transaction, you need to know its hash, but be hash must include the extra signers. This Catch-22 relationship means including this type of extra signer will return an error.Operation validity​When a transaction is submitted to a node, the node checks the validity of each operation in the transaction before attempting to include it in a candidate transaction set. These initial operation validity checks are intended to be fast and simple, with more intensive checks coming after the fees have been consumed. For an operation to pass this validity check, it has to meet the following conditions:The signatures on the transaction must be valid for the operation​The signatures are from valid signers for the source account of the operation. The combined weight of all signatures for the source account of the operation meets the threshold for the operation.The operation must be well-formed​Typically this means checking the parameters for the operation to see if they’re in a valid format. For example, only positive values can be set for the amount of a payment operation.The operation must be valid in the current protocol version of the network​Deprecated operations, such as inflation, are invalid by design.Transaction validity​Finally, the following transaction checks take place:Source account​The source account must exist on the ledger.Fee​The fee must be greater than or equal to the network minimum fee for the number of operations submitted as part of the transaction. This does not guarantee that the transaction will be applied, only that it is valid. In addition, the source account must be able to pay the fee specified. If multiple transactions are submitted but only a subset of them can be paid for, they are checked for validity in order of sequence number.Fee-bump (if applicable)​See Validity of a Fee-Bump Transaction sectionSequence number​The sequence number must be one greater than the sequence number stored in the source account entry when the transaction is applied unless sequence number preconditions are set. When checking the validity of multiple transactions with the same source account in a candidate transaction set, they must all be valid transactions and their sequence numbers must be offset by one. Then they are ordered and applied according to their sequence number.List of operations​Each operation must pass all the validity checks for an operation, described in the Operation Validity section above.List of signatures​Meet signature requirements for each operation in the transactionAppropriate network passphrase is part of the transaction hash signed by each signerCombined weight of the signatures for the source account of the transaction meets the low threshold for the source account.Memo (if applicable)​The memo type must be a valid type, and the memo itself must adhere to the formatting of the memo type.Transaction lifecycle​1. Creation (Transaction Creator)​A user creates a transaction by setting the source account, sequence number, list of operations and their respective parameters, fee or fee-bump, and optionally a memo and/or preconditions.2. Signing (Transaction Signers)​Once the transaction is complete, it becomes a transaction envelope containing the transaction itself and a list of signers. All the required signatures must be collected and added to the transaction envelope’s list of signers. Commonly, it’s just the signature of the account doing the transaction, but more complicated setups can require collecting signatures from multiple parties.3. Submitting (Transaction Submitter)​After signing, the transaction can now be submitted to the Stellar network. If the transaction is invalid, it will be rejected immediately by Stellar Core, the account’s sequence number will not be incremented, and no fee will be consumed from the source account. Multiple transactions for the same account can be submitted, provided each sequence number is off by one (unless minimum sequence number preconditions are set). If they are all valid, Stellar Core will craft a transaction set with each of those transactions applied in sequence number order. Transactions are typically submitted using Horizon, but you can also submit the transaction directly to an instance of Stellar Core.4. Propagating (Validator)​Once Stellar Core has determined that a transaction is valid, it will propagate the transaction to all other servers to which it’s connected. This way, a valid transaction is flooded to the entire Stellar network.5. Crafting a candidate transaction set (Validator)​When it’s time to close the ledger, each Stellar Core validator takes all valid transactions it is aware of since the last ledger close and collects them into a candidate transaction set. If it hears about any incoming transactions now, it puts them aside for the next ledger close. If the number of operations in the candidate transaction set is greater than the maximum number of operations per ledger, transactions will be prioritized by their fee for inclusion in the set.6. Nominating a transaction set (Validator)​Once each validator has crafted a candidate transaction set, the set is nominated to the network.7. Stellar Consensus Protocol (SCP) determines the final transaction set (Validator Network)​SCP resolves any differences between candidate transaction sets and ultimately determines a single transaction set to apply, the close time of the ledger, and any upgrades to the protocol that need to be applied network-wide at the apply time.If a transaction doesn’t make it into the transaction set, it is kept around in memory to be added to the next transaction set on a best-effort basis.If a transaction is kept in memory after a certain number of ledger closes, it will be banned for several additional ledgers. This means no attempt will be made to include it in a candidate transaction set additional ledgers during this time.8. Transaction apply order is determined (Validator Network)​Once SCP agrees on a particular transaction set, the apply order is computed for the transaction set. This shuffles the set's order to create uncertainty for competing transactions and maintains the order of sequence numbers for multiple transactions per account.9. Fees are collected (Validator)​Fees are collected for all transactions simultaneously.10. Application (Validator)​Each transaction is applied in the previously-determined order. For each transaction, the account’s sequence number is consumed (increased by 1), the transaction’s validity is rechecked, and each operation is applied in the order they occur in the transaction. Operations may fail at this stage due to errors that can occur outside of the transaction and operation validity checks. For example, an insufficient balance for a payment is not checked at submission and would fail at this time. The entire transaction will fail if any operation fails, and all previous operations will be rolled back.11. Protocol Upgrades (Validator)​Finally, upgrades are run if an upgrade took place. This can include arbitrary logic to upgrade the ledger state for protocol upgrades, along with ledger header modifications, including the protocol version, base fee, maximum number of operations per ledger, etc. Once this has been completed, the life cycle begins anew.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-data-structures/operations-and-transactions","title":"Operations and Transactions","contentLength":2072}},{"pageContent":"Lumens (XLM)Lumens (XLM) are the native currency of the Stellar network. The lumen is the only token that doesn’t require an issuer or trustline, and it pays all transaction fees and covers minimum balances on the network.To read up on the basics of lumens, head over to our Stellar Learn site: Stellar Learn: LumensTransaction fees​Stellar requires a small fee for all transactions to prevent ledger spam and prioritize transactions during surge pricing. Transaction fees are paid in lumens.To learn about fees on Stellar, see our Fees, Surge Pricing, and Fee Strategies Encyclopedia EntryBase reserves​A unit of measurement used to calculate an account’s minimum balance. One base reserve is currently 0.5 XLM.Validators can vote to change the base reserve, but that’s uncommon and should only happen every few years.Minimum balance​Stellar accounts must maintain a minimum balance to exist, which is calculated using the base reserve. An account must always maintain a minimum balance of two base reserves (currently 1 XLM). Every subentry after that requires an additional base reserve (currently 0.5 XLM) and increases the account’s minimum balance. Subentries include trustlines (for both traditional assets and pool shares), offers, signers, and data entries. An account cannot have more than 1,000 subentries.Data also lives on the ledger as ledger entries. Ledger entries include claimable balances (which require a base reserve per claimant) and liquidity pool deposits and withdrawals.For example, an account with one trustline, two offers, and a claimable balance with one claimant has a minimum balance of:2 base reserves (1 XLM) + 3 subentries/base reserves (1.5 XLM) + 1 ledger entry/base reserve (1 XLM) = 3.5 XLMWhen you close a subentry, the associated base reserve will be added to your available balance. An account must always pay its own minimum balance unless a subentry is being sponsored by another account. For information about this, see our Sponsored Reserves Encyclopedia Entry.","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/lumens","title":"Lumens (XLM)","contentLength":328}},{"pageContent":"Stellar Ecosystem Proposals (SEPs)Each SEP is a distinct blueprint meant to help users build a product or service that interoperates with other products and services on the Stellar network.When you build on Stellar, you generally use the Horizon API to interact with the network. However, anytime you want your product or service to interoperate with other products or services in the ecosystem, you must create additional infrastructure to handle those components of an interaction.SEPs define standards for building that infrastructure on top of the Stellar network. They are designed to help different entities, such as asset issuers, wallets, exchanges, and other service providers interoperate using a single common integration. Generally, they define two sides of an interaction — often a server-side and a client-side — and using them as a blueprint allows you to connect to multiple counterparties without starting from scratch every time.SEPs are publicly created, open-source documents that live in the GitHub repository and have a lightweight approval process. New SEPs and upgrades are discussed constantly. We encourage participation in these discussions to help build new standards and make Stellar services more accessible.Notable SEPs​There are many SEPs, and they cover a wide variety of standards for interoperation. Whatever you're building, you may want to take a look at the complete list to see if there's a standard for your use case.Here, we'll cover a few notable SEPs that define the standards for the most common Stellar use cases.SEP-0001 - Stellar Info File​Defines how to create and host a stellar.toml file: a common place where the Internet can find information about your Stellar integration. You can store a lot of information in your stellar.toml file including organization information, currency information, and contact information. TOML is a simple and commonly used configuration file format designed to be readable by both humans and machines.Using the set_options operation, you can link your Stellar account to the domain that hosts your stellar.toml, creating an on-chain connection between this information and that account.Used by anchors, issuers, and validators.Link to GitHubSEP-0005 - Key Derivation Methods for Stellar Accounts​Describes methods for key derivation for Stellar, improving key storage and moving keys between wallets and applications. Guidance in this SEP improves the Stellar ecosystem by:Making key derivation the same across wallets and applicationsAllowing users to hold keys in hardware walletsAllowing users to hold keys in cold storage more reliably (using mnemonic codes)Allowing users to generate multiple keys from a single seed (for example, first for storing funds and second as a signer for a shared account)Used by wallets and other applications.Link to GitHubSEP-0006 - Deposit and Withdrawal API​Defines the standard way for anchors and wallets to interact on behalf of users. With this SEP’s guidance, wallets and other clients can interact with anchors directly without the user needing to leave the wallet to go to the anchor’s site.This SEP defines a standard protocol enabling the following features within a wallet or other Stellar client:Deposit external assets with an anchorWithdraw assets from an anchorExecute deposit/withdrawal between non-equivalent assetsCommunicate deposit & withdrawal fee structure for an anchor to the userHandle anchor KYC needs, including transmitting KYC information about the user to the anchor via SEP-12Check the status of ongoing deposits or withdrawals involving the userView history of deposits and withdrawals involving the userSEP-0024 is the alternative to SEP-0006 which supports hosted deposits and withdrawals.Used by anchors, wallets, and other applications.Link to GitHubSEP-0007 - URI Scheme to Facilitate Delegated Signing​Defines the standard URI scheme that can be used to generate a URI that will serve as a request to sign a transaction. With this SEP’s guidance, non-wallet applications can have their their users sign a transaction without seeing the wallet user's secret key in any form since the URI (request) will typically be signed by the user’s trusted wallet where the secret keys are stored.This SEP defines a standard protocol enabling the following features within a wallet or other Stellar client:Deeplinks payments (online)QR code payments (online and offline)Point of sale transactions (offline)Peer to peer payments (online and offline)Used by wallets and other applications.Link to GitHubSEP-0010 - Stellar Authentication​Defines a standard way for clients (such as wallets or exchanges) to create authenticated web sessions for users holding a Stellar account. This SEP also supports authenticating users of shared or pooled Stellar accounts. Clients can use muxed accounts to distinguish users or sub-accounts of shared accounts.Proves that the user has a Stellar account and that they control the account with a single master key or sufficient signers needed.Used by wallets and exchanges.Link to GitHubSEP-0012 - KYC API​Allows for sharing of KYC data and defines a standard way for Stellar clients to upload KYC and other information to anchors and other services. This SEP was made with these goals in mind:Allow a customer to enter their KYC information into their wallet once and use it across many services without re-entering information manuallyHandle image and binary dataSupport the set of fields defined in SEP-9Support authentication via SEP-10Support the provision of data for SEP-6, SEP-24, SEP-31, and othersGive customers control over their data by supporting complete data erasureUsed by anchors, wallets, and other applications.Link to GitHubSEP-0020 - Self-Verification of Validator Nodes​Defines how validators self-verify by setting the home domain of their Stellar account to their website, where they publish information on-chain about their node and organization in a stellar.toml file. This allows other participants to discover other nodes and add them to their quorum sets without needing a centralized database.Used by validators.Link to GitHubSEP-0024 - Hosted Deposit and Withdrawal​Defines the standard way for anchors and wallets to interact on behalf of users interactively. This means that the user’s application must open a webview hosted by a third-party anchor for the user to provide the information necessary to complete the transaction.Users use applications that implement SEP-0024 to connect to businesses that will accept off-chain value (such as USD) in exchange for on-chain value (such as USDC) and vice-versa.SEP-0006 is the alternative to SEP-0024 that supports an API-style solution for the same use case.Used by anchors, wallets, and other applications.Link to GitHubSEP-0030 - Account Recovery: Multi-Party Recovery of Stellar Accounts​Defines the standard API that enables an individual (e.g., a user or wallet) to regain access to a Stellar account that it owns after the individual has lost its private key without providing any third-party control of the account. Using this protocol, the user or wallet will preregister the account and a phone number, email, or other form of authentication with one or more servers implementing the protocol and add those servers as signers of the account. If two or more servers are used with appropriate signer configuration no individual server will have control of the account, but collectively, they may help the individual recover access to the account.The protocol also enables individuals to pass control of a Stellar account to another individual.This SEP enables the following use cases for a user:Recover: Recover access to Stellar accounts for which they may have lost keys.Share: Gain access to Stellar accounts that another user intends to share with them.Used by wallets and other applications.Link to GitHubSEP-0031 - Cross-Border Payment API​Defines the protocol for two financial accounts that exist outside the Stellar network (anchors) to interact with each other.Used by anchors.Link to GitHub","metadata":{"source":"https://developers.stellar.org/docs/fundamentals-and-concepts/stellar-ecosystem-proposals","title":"Stellar Ecosystem Proposals (SEPs)","contentLength":1299}},{"pageContent":"Create an AccountBefore we get started with working with Stellar in code, consider going through the following examples using the Stellar Laboratory. The lab allows you create accounts, fund accounts on the Stellar test network, build transactions, run any operation, and inspect responses from Horizon via the Endpoint Explorer.Accounts are a fundamental building block of Stellar: they hold all your balances, allow you to send and receive payments, and let you place offers to buy and sell assets. Since pretty much everything on Stellar is in some way tied to an account, the first thing you generally need to do when you start developing is create one. This beginner-level tutorial will show you how to do that.Create a Keypair​Stellar uses public key cryptography to ensure that every transaction is secure: every Stellar account has a keypair consisting of a public key and a secret key. The public key is always safe to share — other people need it to identify your account and verify that you authorized a transaction. It's like an email address. The secret key, however, is private information that proves you own — and gives you access to — your account. It's like a password, and you should never share it with anyone.Before creating an account, you need to generate your own keypair:Create Account​A valid keypair, however, does not make an account: in order to prevent unused accounts from bloating the ledger, Stellar requires accounts to hold a minimum balance of 1 XLM before they actually exist. Until it gets a bit of funding, your keypair doesn't warrant space on the ledger.On the public network, where live users make live transactions, your next step would be to acquire XLM, which you can do by consulting our lumen buying guide. Because this tutorial runs on the test network, you can get 10,000 test XLM from Friendbot, which is a friendly account funding tool.To do that, send Friendbot the public key you created. It’ll create and fund a new account using that public key as the account ID.Now for the last step: getting the account’s details and checking its balance. Accounts can carry multiple balances — one for each type of currency they hold.Now that you’ve got an account, you can start sending and receiving payments, or, if you're ready to hunker down, you can skip ahead and build a wallet or issue a Stellar-network asset.","metadata":{"source":"https://developers.stellar.org/docs/tutorials/create-account","title":"Create an Account","contentLength":413}},{"pageContent":"Send and Receive PaymentsMost of the time, you’ll be sending money to someone else who has their own account. For this tutorial, however, you'll need a second account to transact with. So before proceeding, follow the steps outlined in Create an Account to make two accounts: one for sending and one for receiving.About Operations and Transactions​Actions that do things on Stellar — like sending payments or making buy or sell offers — are called operations. To submit an operation to the network, you bundle it into a transaction, which is a group of anywhere from 1 to 100 operations accompanied by some extra information, like which account is making the transaction and a cryptographic signature to verify that the transaction is authentic.Transactions are atomic, meaning that if any operation in a transaction fails, they all fail. Let’s say you have 100 lumens and you make two payment operations of 60 lumens each. If you make two transactions (each with one operation), the first will succeed and the second will fail because you don’t have enough lumens. You’ll be left with 40 lumens. However, if you group the two payments into a single transaction, they will both fail and you’ll be left with the full 100 lumens still in your account.Every transaction also incurs a small fee. Like the minimum balance on accounts, this fee deters spam and prevents people from overloading the system. This base fee is very small — 100 stroops per operation where a stroop equals 1 * 10 ^-7 XLM — and it's charged for each operation in a transaction. A transaction with two operations, for instance, would cost 200 stroops.Send a Payment​Stellar stores and communicates transaction data in a binary format called XDR, which is optimized for network performance but unreadable to the human eye. Luckily, Horizon, the Stellar API, and the Stellar SDKs convert XDRs into friendlier formats. Here’s how you might send 10 lumens to an account:What exactly happened there? Let’s break it down.Confirm that the account ID (aka the public key) you are sending to actually exists by loading the associated account data from the Stellar network. It's okay to skip this step, but it gives you an opportunity to avoid making a transaction that will inevitably fail.Load data for the account you are sending from. An account can only perform one transaction at a time and has something called a sequence number, which helps Stellar verify the order of transactions. A transaction’s sequence number needs to match the account’s sequence number, so you need to get the account’s current sequence number from the network.The SDK will automatically increment the account’s sequence number when you build a transaction, so you won’t need to retrieve this information again if you want to perform a second transaction.Start building a transaction. This requires an account object, not just an account ID, because it will increment the account’s sequence number.Add the payment operation to the account. Note that you need to specify the type of asset you are sending: Stellar’s network currency is the lumen, but you can send any asset issued on the network. We'll cover sending non-lumen assets below. For now, though, we’ll stick to lumens, which are called “native” assets in the SDK:You should also note that the amount is a string rather than a number. When working with extremely small fractions or large values, floating point math can introduce small inaccuracies. Since not all systems have a native way to accurately represent extremely small or large decimals, Stellar uses strings as a reliable way to represent the exact amount across any system.Optionally, you can add your own metadata, called a memo, to a transaction. Stellar doesn’t do anything with this data, but you can use it for any purpose you’d like. Many exchanges require memos for incoming transactions because they use a single Stellar account for all their users and rely on the memo to differentiate between internal user accounts.Now that the transaction has all the data it needs, you have to cryptographically sign it using your secret key. This proves that the data actually came from you and not someone impersonating you.And finally, submit it to the Stellar network!In this example, we're submitting the transaction to the SDF-maintained public testnet instance of Horizon, the Stellar API. When submitting transactions to a Horizon server — which is what most people do — it's possible that you will not receive a response from the server due to a bug, network conditions, etc. In such a situation it's impossible to determine the status of your transaction. That's why you should always save a built transaction (or transaction encoded in XDR format) in a variable or a database and resubmit it if you don't know its status. If the transaction has already been successfully applied to the ledger, Horizon will simply return the saved result and not attempt to submit the transaction again. Only in cases where a transaction’s status is unknown (and thus will have a chance of being included into a ledger) will a resubmission to the network occur.Receive a Payment​You don’t actually need to do anything to receive payments into a Stellar account: if a payer makes a successful transaction to send assets to you, those assets will automatically be added to your account.However, you may want to keep an eye out for incoming payments. A simple program that watches the network for payments and prints each one might look like:There are two main parts to this program. First, you create a query for payments involving a given account. Like most queries in Stellar, this could return a huge number of items, so the API returns paging tokens, which you can use later to start your query from the same point where you previously left off. In the example above, the functions to save and load paging tokens are left blank, but in a real application, you’d want to save the paging tokens to a file or database so you can pick up where you left off in case the program crashes or the user closes it.Second, the results of the query are streamed. This is the easiest way to watch for payments or other transactions. Each existing payment is sent through the stream, one by one. Once all existing payments have been sent, the stream stays open and new payments are sent as they are made.Try it out: Run this program, and then, in another window, create and submit a payment. You should see this program log the payment.You can also request payments in groups or pages. Once you’ve processed each page of payments, you’ll need to request the next one until there are none left.Transacting in Other Currencies​One of the amazing things about the Stellar network is that you can create, hold, send, receive, and trade any type of asset. Many organizations issue assets on Stellar that represent real-world currencies such as US dollars or Nigerian naira or other cryptocurrencies such as bitcoin or ether.Each of these redeemable assets — anchored in the Stellar vernacular — is essentially a credit issued by a particular account that represents reserves those accounts hold outside the network. That's why the assets in the example above had both a code and an issuer: the issuer is the public key of the account that created the asset, an account owned by the organization that ultimately honors the credit that asset represents.","metadata":{"source":"https://developers.stellar.org/docs/tutorials/send-and-receive-payments","title":"Send and Receive Payments","contentLength":1288}},{"pageContent":"Follow Received PaymentsThis tutorial shows how easy it is to use Horizon to watch for incoming payments on an account using JavaScript and EventSource. We will eschew using js-stellar-sdk, the high-level helper library, to show that it is possible for you to perform this task on your own with whatever programming language you would like to use.This tutorial assumes that you:Have node.js installed locally on your machine.Have curl installed locally on your machine.Are running on Linux, macOS, or any other system that has access to a bash-like shell.Are familiar with launching and running commands in a terminal.In this tutorial we will learn:How to create a new account.How to fund your account using friendbot.How to follow payments to your account using curl and EventSource.Project Skeleton​Let's get started by building our project skeleton:This should have created a package.json in the follow_tutorial directory. You can check that everything went well by running the following command:Everything was successful if no output was generated from the above command. Now let's write a script to create a new account.Creating an account​Create a new file named make_account.js and paste the following text into it:Save the file and run it:Before our account can do anything it must be funded. Indeed, before an account is funded it does not truly exist!Funding your account​The Stellar test network provides the Friendbot, a tool that developers can use to get testnet lumens for testing purposes. To fund your account, simply execute the following curl command:Don't forget to replace the account id above with your own. If the request succeeds, you should see a response like:After a few seconds, the Stellar network will perform consensus, close the ledger, and your account will have been created. Next up we will write a command that watches for new payments to your account and outputs a message to the terminal.Following payments using curl​To follow new payments connected to your account you simply need to send the Accept: text/event-stream header to the /payments endpoint.As a result you will see something like:Every time you receive a new payment you will get a new row of data. Payments is not the only endpoint that supports streaming. You can also stream transactions /transactions and operations /operations.Following payments using EventStream​Warning! EventSource object does not reconnect for certain error types so it can stop working. If you need a reliable streaming connection please use our SDK.Another way to follow payments is writing a simple JS script that will stream payments and print them to console. Create stream_payments.js file and paste the following code into it:Now, run our script: node stream_payments.js. You should see following output:Testing it out​We now know how to get a stream of transactions to an account. Let's check if our solution actually works and if new payments appear. Let's watch as we send a payment (create_account operation) from our account to another account.We use the create_account operation because we are sending payment to a new, unfunded account. If we were sending payment to an account that is already funded, we would use the payment operation.First, let's check our account sequence number so we can create a payment transaction. To do this we send a request to horizon:Sequence number can be found under the sequence field. For our example, the current sequence number is 713226564141056. Save your value somewhere.Now, create make_payment.js file and paste the following code into it, replacing the sequence number accordingly:After running this script you should see a signed transaction blob. To submit this transaction we send it to Horizon or Stellar-Core. But before we do, let's open a new console and start our previous script by node stream_payments.js.Now to send a transaction just use Horizon:You should see a new payment in a window running stream_payments.js script.","metadata":{"source":"https://developers.stellar.org/docs/tutorials/follow-received-payments","title":"Follow Received Payments","contentLength":680}},{"pageContent":"Integrate with MoneyGram AccessThis document guides the reader through the technical requirements for integrating MoneyGram Access into an existing application. MoneyGram Access is a MoneyGram product that enables users of third-party applications, such as crypto wallets and exchanges, to cash-in (deposit) and cash-out (withdrawal) of Stellar USDC.MoneyGram requires businesses to go through an onboarding process in order to get access to their testing and production environments. To get started with this process, reach out to [email protected].Resources​MoneyGram Access Wallet MVP ImplementationUse this MVP implementation as a reference for building your own integration. Many of the code snippets shared in this document are pulled from this project.Stellar Test AnchorBefore getting access to MoneyGram's test environment, you can use the SDF's test anchor while developing your integrationStellar Demo WalletThis application visualizes the API calls necessary to connect to a Stellar AnchorStellar Ecosystem Proposal 24 (SEP-24)The standardized API protocol for Stellar on & off ramps, implemented by MoneyGramStellar Ecosystem Proposal 10 (SEP-10)The standardized API protocol for Stellar authentication, implemented by MoneyGramAsset Information​Before you get access to MoneyGram's test environment, you should test your implementation with the SDF's Stellar Test Anchor. It implements the same APIs as MoneyGram's service but uses a different asset. The information for each asset is below.Stellar Reference Token​This token is only on testnet.Issuing Account: GCDNJUBQSX7AJWLJACMJ7I4BC3Z47BQUTMHEICZLE6MU4KQBRYG5JY6BAsset Code: SRTUSD Coin​Testnet:Issuing Account: GBBD47IF6LWK7P7MDEVSCWR7DPUWV3NY3DTQEVFL4NAT4AQH3ZLLFLA5Asset Code: USDCPubnet:Issuing Account: GA5ZSEJYB37JRC5AVCIA5MOP4RHTM335X2KGX3IHOJAPP5RE34K4KZVNAsset Code: USDCIntroduction​Applications seeking to integrate MoneyGram Access must implement the client side of Stellar Ecosystem Proposal 24 (SEP-24), a standardized protocol defined for applications to connect to businesses such as MoneyGram, more generally called anchors, that offer Stellar deposit & withdrawal services utilizing local payment rails.This document will walk you through the necessary steps to develop a functional implementation of this standard.The guide will assume your application is first being developed on Stellar’s test network and using MoneyGram’s testing deployment of Access, but there are no functional differences deploying the application to Stellar’s public network and using MoneyGram’s production deployment.Custodial vs. Non-Custodial Applications​Some applications, such as centralized exchanges, are custodial, meaning the application has access to the private keys of the acccounts holding its users’ funds on Stellar. Typically, custodial applications pool user funds into a smaller set of managed Stellar accounts, called pooled, shared, or omnibus accounts.Other applications are non-custodial, meaning the application does not have access to the private keys of the accounts holding its users' funds on Stellar. Typically, non-custodial applications create or import a pre-existing Stellar account for each user.These two approaches require minor but concrete differences in how applications integrate with MoneyGram Access. The sub-sections below will describe these differences, but the rest of this tutorial will assume the application is custodial.Authentication​MoneyGram needs to authenticate both the user and the application being used via Stellar's SEP-10 protocol.Custodial applications are identified by the Stellar account public key they register with MoneyGram during the onboarding process. When authenticating, the application must pass this public key as the account query parameter, and to identify the user, the application must pass a unique integer ID as the memo query parameter. MoneyGram will return a Stellar transaction that must be signed by the application's private key and sent back for verification.Because each user of a non-custodial application has their own Stellar account, non-custodial applications are identified by the home domain they register with MoneyGram during the onboarding process. When authenticating, the application must pass the user's public key as the account query parameter, and pass their home domain as the client_domain query parameter. MoneyGram will look up the SIGNING_KEY value at https://<client_domain>/.well-known/stellar.toml, and return a Stellar transaction that requires signatures from both the user's private key & the private key of the public SIGNING_KEY on the application's SEP-1 stellar.toml file. An example file can be found at https://vibrantapp.com/.well-known/stellar.toml.Transaction Initiation​Because users of custodial applications don't have individual Stellar accounts, only the application knows how much money a user has to withdraw. Because of this, MoneyGram requires custodial applications to always pass the amount field in the request to start a new transaction. Non-custodial applications do not need to do this, although they can if they prefer.Source & Destination of Funds​MoneyGram requires custodial applications to provide the Stellar accounts that may be used as the source or destination of funds during the onboarding process. For non-custodial applications, MoneyGram requires the source and destination of funds for each transaction to be the same account that was authenticated via SEP-10.Application Flow & Architecture​This guide will assume the application has a basic client-server architecture. The application’s client will request resources and initiate actions with the application’s server, which will communicate directly with MoneyGram’s server.Below are the 7 high-level steps to take to facilitate a cash-out (withdrawal) transaction.After Step 4, the application should open the URL provided by MoneyGram in a mobile webview or browser tab. MoneyGram will then prompt the user to provide KYC and transaction information. On completion of this flow, the application’s client should close the MoneyGram tab or webview and initiate the disbursement of funds.The provided reference number would then be taken to any MoneyGram cash agent in order to receive cash in the user’s fiat currency. These steps document the cash-out, or withdrawal flow. The deposit flow is similar and detailed in the steps below.Generate Stellar Keypairs​In this section, you will generate at least two Stellar keypairs, one that will be used to prove your application’s identity when authenticating with MoneyGram Access, and another that will hold, send, & receive USDC on Stellar. You should always use one keypair for authentication, but application could use many keypairs for sending & receiving payments. In this guide, we'll assume the application uses one keypair for each purpose.This section assumes that your application does not have any support for the Stellar network. If your application already supports deposits & withdrawals of XLM, you already have one or more Stellar accounts that can be used for these purposes, although it is heavily encouraged to use a new keypair for authentication.Go to Stellar Lab and generate 2 keypairs. The secret keys should be handled securely, because they will be used to authenticate with and disburse funds to MoneyGram.The first keypair will be called the “authentication” keypair (or public / secret key). The second keypair will be the “funds” keypair (or account, public key, or secret key). Unlike the authentication keypair, the funds keypair will reference a funded account on the Stellar network. The authentication keypair does not need to funded.Provide the public keys (starting with a G) of both the authentication and funds keypairs to MoneyGram. They will add these keys to their known lists of keys, granting them access to their deployment.Get XLM & USDC​Many cryptocurrency exchanges support purchasing XLM or USDC on Stellar. The SDF also maintains an Anchor Directory that attempts to list all the on & off-ramps for the Stellar Network.When you’ve purchased XLM and / or USDC on an exchange, you can make a payment to an external account, specifically to the funds public key you generated in the previous step. Note that you will first need to send XLM to create the account, then add a USDC trustline, then send the USDC. Creating a trustline to USDC can be done using Stellar Lab or any Stellar-enabled wallet application, such as Lobstr.Some exchanges support XLM but do not support USDC on Stellar. This is not a problem, because you can always sell XLM for USDC on Stellar’s decentralized exchange (or SDEX).To do this, send your XLM to the funds public key from the exchange, add a USDC trustline, and sell XLM for USDC using a sell offer.Authenticate​This section encompasses steps 1 & 2 of the diagram displayed in the Architecture section above. The application’s client should request a MoneyGram transaction URL from the application’s server on user initiation. This should trigger an authentication process between the application’s server and MoneyGram’s server. This process is standardized in SEP-10.This section assumes that the application’s server has the following pieces of information:The user’s integer ID (must be positive and represented using 64 bits or less) MoneyGram’s authentication endpointTesting: https://extstellar.moneygram.com/stellaradapterservice/authProduction: https://stellar.moneygram.com/stellaradapterservice/authMoneyGram’s authentication public keyTesting: GCSESAP5ILVM6CWIEGK2SDOCQU7PHVFYYT7JNKRDAQNVQWKD5YEE5ZJ4Production: GD5NUMEX7LYHXGXCAD4PGW7JDMOUY2DKRGY5XZHJS5IONVHDKCJYGVCLThe application’s authentication public and secret keyThe flow can be described with the following steps:The application requests an authentication challengeThe server (MoneyGram) provides the authentication challengeThe application verifies that MoneyGram signed the authentication with it's SIGNING_KEYThe application signs the authentication challenge with its own keyThe application sends the authentication challenge back to the serverThe server verifies the application signed the challenge with the account it initially used to request the challengeThe server returns a session token for the account & memo used in the initial authentication requestThe following code demonstrates how to implement the application’s side of this flow. Note that this code does not handle retries in the event of network connection issues. It also does not handle unexpected status codes, and does not include logging or metrics.Initiate a Transaction​This section encompasses steps 3 & 4 of the architecture diagram displayed above. The application’s server will make a deposit or withdrawal initiation request to MoneyGram’s server, and MoneyGram will return a transaction ID, which will be used later to poll the transaction’s status, and a transaction URL, which should be returned to the application’s client and opened for the user.For the purpose of this guide, we will go through the withdrawal case.Note: MoneyGram requires the amount field in requests for both deposit & withdraw transactions if your application is custodial.You will need the following pieces of information:The authentication token provided by MoneyGram. This token can only be used for actions associated with the user identified by the ID used in the previous steps.The public key of the keypair the application will use to send fundsThe language code MoneyGram should render their UI’s content withThe amount the user would like to withdraw / cash-outThis should be collected from the user prior to initiating this transactionThe following code can be used as a reference for implementing this logic yourself. This code is not necessarily production-ready.The logic for initiating a deposit transaction looks very similar. See the SEP-24 standard specification for detailed information.The &callback=postmessage query parameter added to the returned URL is critical; it informs MoneyGram that the application’s client would like to be notified when the user has completed the MGI experience and has requested to close the window. We’ll cover this in more detail in the subsequent section.Listen for the Close Notification​The next step is to open the provided URL in the application’s client using a mobile webview, browser tab, or popup. The user will then go through KYC if they have not before in a prior transaction. In the deposit case, the user may also select a MoneyGram agent location to go to when providing cash.Finally, when the user is done with the MoneyGram UI, the user will select a button displayed on MoneyGram’s UI and MoneyGram will send a postMessage to the window or app that opened its flow initially. The message sent will be the SEP-24 transaction JSON object that represents the transaction.Below is a simple JavaScript example listening for a postmessage notification.Send or Receive Funds​In withdrawal (or cash-out) transactions, applications must send USDC to the Stellar account MoneyGram specifies. In deposit (cash-in) transactions, applications must monitor their Stellar account for a payment from MoneyGram.In each case, the transaction submitted to Stellar must have a memo attached to it. This memo is provided by MoneyGram in the withdrawal case, and provided by the application in the deposit case. The memo is an identifier that allows the parties to tie the on-chain payment to the transaction record in the application’s or MoneyGram’s database.Poll Until MoneyGram is Ready​Before the application can send funds or instruct the user to provide cash to a MoneyGram agent, the application should confirm with MoneyGram’s server that the transaction is ready to proceed.You will need the following information to do so.The authentication token provided by MoneyGramThe transaction’s ID provided by MoneyGramMoneyGram’s transaction’s endpointTesting: https://extstellar.moneygram.com/stellaradapterservice/sep24/transactionProduction: https://stellar.moneygram.com/stellaradapterservice/sep24/transactionThis code uses a simple polling mechanism with no bail-out condition. The application’s code should be more robust.Sending Funds​Once MoneyGram is ready to receive funds, your application should extract the Stellar account and memo to use in the payment transaction, construct a Stellar transaction, and submit it to the Stellar network. You’ll need:A copy of MoneyGram’s transaction objectThe application’s funds public & secret keyCode for submitting transactions to Stellar should be developed thoughtfully. The SDF has a documentation page dedicated to submitting transactions and handling errors gracefully. Here are a few things you need to keep in mind:Offer a high fee. Your fee should be as high as you would offer before deciding the transaction is no longer worth sending. Stellar will only charge you the minimum necessary to be included in the ledger -- you won't be charged the amount you offer unless everyone else is offering the same amount or greater. Otherwise, you’ll pay the smallest fee offered in the set of transactions included in the ledger.Set a maximum timebound on the transaction. This ensures that if your transaction is not included in a ledger before the set time, you can reconstruct the transaction with a higher offered fee and submit it again with better chances of inclusion.Resubmit the transaction when you get 504 status codes. 504 status codes are just telling you that your transaction is still pending -- not that it has been canceled or that your request was invalid. You should simply make the request again with the same transaction to get a final status (either included or expired).Below is highly simplified code for submitting a payment transaction. It does not use timebounds, handle a transaction’s expiration, or handle 504 status codes.Receiving Funds​Once MoneyGram is ready for the user to drop off cash at an MGI agent (in deposit or cash-in cases), the application’s server should begin monitoring its Stellar account for an inbound USDC payment sent by MoneyGram.The application should have provided a memo for MoneyGram to use when it initiated the deposit. MoneyGram will attach this memo to the transaction used to send the payment to the application, and the application should use this check the memo of transactions involving it’s account to associate the payment back to the user and the specific transaction.The best way to monitor payments made to an account is to stream events from Stellar’s payments endpoint. The use of streaming cursors can help ensure you never miss an event, even if your application’s streaming process goes down for a period of time.Note that this code does not handle path payments or claimable balances, two slightly different forms of payment. At the time of writing, MoneyGram does not use either of these options, but you may want to add support for them in case they do in the future.Fetch the Reference Number​For deposit or cash-in transactions, MoneyGram does not provide reference numbers. All the user needs to do is drop off cash at the agent location chosen in the MoneyGram UI earlier in the flow, and the application should complete the transaction when a matching payment is detected on Stellar.For withdrawal or cash-out transactions, MoneyGram provides a reference number in their UI and API once MoneyGram detects the application’s payment of USDC on Stellar. Users should be able to use the application’s client interface to view the reference number directly or find the MoneyGram transaction details page and view it there.Note that MoneyGram’s transaction details page is protected with a JWT token in the url that expires relatively quickly after being fetched. This means applications must fetch the URL at the time the user requests the page, potentially requiring re-authentication via SEP-10.","metadata":{"source":"https://developers.stellar.org/docs/tutorials/moneygram-access-integration-guide","title":"Integrate with MoneyGram Access","contentLength":2800}},{"pageContent":"Assets OverviewIssuing assets is a core feature of Stellar: any asset can be tokenized (or minted) on the network and then tracked, held, and traded quickly and cheaply. Assets can represent many things: cryptocurrencies (such as bitcoin or ether), fiat currencies (such as dollars or pesos), other tokens of value (such as NFTs), pool shares, or even bonds and equity. Any Stellar account can issue an asset, and since anyone can set up an account, anyone can issue assets: banks, payment processors, money service businesses, for-profit enterprises, nonprofits, local communities, and individuals. It’s a self-serve process with no permission needed.Issuing an asset on Stellar is easy and only takes a few operations. However, there are additional considerations you may need to think about depending on your use case, such as publishing asset information, compliance, and asset supply, which we’ll cover in this documentation. Assets on Stellar have two identifying characteristics: the asset code and the issuer. Since more than one organization can issue a credit representing the same asset, asset codes often overlap (for example, multiple companies offer a USD token on Stellar). Assets are uniquely identified by the combination of their asset code and issuer.Stablecoins​One major category of assets is the stablecoin. A stablecoin is a blockchain-based token whose value is tied to another asset, such as the US dollar, other fiat currencies, commodities like gold, or even cryptocurrencies. There are two types of stablecoin: 1) reserve-backed stablecoins that must have a mechanism for redeeming the asset backing them, and 2) algorithmic stablecoins that don’t have assets backing them and instead rely on an algorithm to control the stablecoin supply. When discussing stablecoins, our documentation will focus on reserve-backed stablecoins.Reserve-backed stablecoins are pegged to a real-world asset at a 1:1 ratio. Because the underlying asset is maintained as collateral, users should be able to trade their stablecoin for the asset at any time. Asset reserves can be maintained by independent custodians and should be regularly audited.Currently, one of Stellar's most significant use cases is the tokenization of fiat currency for processes like cross-border payments. With anchors, users can connect Stellar tokens to existing rails that allow for the deposit of real-world assets in exchange for digital currency and vice versa. Learn more about anchors in our Anchors section.Treasury management​When issuing a reserve-backed stablecoin, you must set up its off-chain reserve, which securely stores the asset backing the stablecoin. When users wish to redeem their stablecoin, they can receive an equivalent amount of the underlying reserve asset from the issuer.Compliance​As an asset issuer, you may need to comply with regulatory requirements that vary based on jurisdiction. Stellar has built-in features that can help meet these requirements, such as:Controlling access to an asset with flagsSEP-0008: Regulated Assets - regulated assets are assets that require an issuer’s approval (or a delegated third party’s approval) on a per-transaction basis. Check out this Stellar Ecosystem Proposal to learn how to implement regulated assets into your use case.","metadata":{"source":"https://developers.stellar.org/docs/issuing-assets/anatomy-of-an-asset","title":"Assets Overview","contentLength":523}},{"pageContent":"Asset Design ConsiderationsIssuing and distribution accounts​It is best practice on the Stellar network to create two accounts when issuing an asset: 1) the issuing account and 2) the distribution account.The issuing account creates (or mints) the asset on the network by executing a payment operation. The issuing account will always be linked to the asset’s identity. Any account wanting to hold the asset must first establish a trustline with the issuing account. Read about trustlines in our Trustlines section.The distribution account is the first recipient of the issued asset and handles all other transactions.Note that you can also issue an asset by creating an offer or liquidity pool deposit with the issuing account.It is best practice to issue an asset by sending it from the issuing account to a distribution account for two main reasons: security and auditing.Security​The distribution account will be a hot account, meaning that some web service out there has direct access to sign its transactions.For example, if the account you're distributing from is also the issuing account and it is compromised by a malicious actor, the actor can now issue as much of the asset as they want. If the malicious actor redeems the newly issued tokens with an anchor service, the anchor may not have the liquidity to support the customer withdrawals. Stakes are lower if you use a distribution account- if the distribution account is compromised, you can freeze the account’s asset balance and start with a new distribution account without changing the issuing account.Auditing​Using a distribution account is better for auditing because an issuing account can’t actually hold a balance of its own asset. Sending an asset back to its issuing account burns (deletes) the asset. If you have a standing inventory of the issued asset in a separate account, it’s easier to track and can help with bookkeeping.Naming an asset​One thing you must decide when issuing an asset is what to call it. An asset code is the asset’s identifying code. There are three possible formats: Alphanumeric 4, Alphanumeric 12, and liquidity pool shares.Learn about liquidity pool shares in the Liquidity Pool Encyclopedia Entry.Alphanumeric 4-character maximum: Any characters from the set a-z, A-Z, 0-9 are allowed. The code can be shorter than 4 characters, but the trailing characters must all be empty.Alphanumeric 12-character maximum: Any characters from the set a-z, A-Z, 0-9 are allowed. The code can be any number of characters from 5 to 12, but the trailing characters must all be empty.The pool share asset is defined by the liquidity pool identifier (PoolID), which in turn is defined by the two assets its reserves are composed of.Provided it falls into one of these buckets, you can choose any asset code you like. That said, if you’re issuing a currency, you should use the appropriate ISO 4217 code, and if you’re issuing a stock or bond, the appropriate ISIN number. Doing so makes it easier for Stellar interfaces to properly display and sort your token in their listings and allows potential token holders to understand what your token represents.Controlling access to an asset with flags​When you issue an asset on Stellar, anyone can hold it by default. In general, that’s a good thing: easy access means better reach and better liquidity. However, if you need to control access to an asset to comply with regulations (or for any other reason), you can easily do so by enabling flags on your issuing account.Flags are created on the account level using a set_options operation. They can be set at any time in the life cycle of an asset, not just when you issue it.Flag types​The (0xn) next to each flag type denotes the bit settings for each flag.Authorization Required (0x1)​When AUTH_REQUIRED_FLAG is enabled, an issuer must approve an account before that account can hold its asset. This setting allows issuers to vet potential token holders and to approve trustlines.To allow access, the user creates a trustline, and the issuer approves it by changing the AUTHORIZE flag with the Set_Trust_Line_Flag operation.There are two levels of authorization an asset issuer can grant using the Set_Trust_Line_Flag operation:AUTHORIZED_FLAG: signifies complete authorization allowing an account to transact freely with the asset to make and receive payments and place orders.AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG: denotes limited authorization that allows an account to maintain current orders but not to otherwise transact with the asset.Authorization Revocable (0x2)​When AUTH_REVOCABLE_FLAG is enabled, an issuer can revoke an existing trustline’s authorization, thereby freezing the asset held by an account. Doing so prevents that account from transferring or trading the asset and cancels the account’s open orders for the asset.AUTH_REVOCABLE_FLAG also allows an issuer to reduce authorization from complete to limited, which prevents the account from transferring or trading the asset but does not cancel the account’s open orders for the asset. This setting is useful for issuers of regulated assets who need to authorize transactions on a case-by-case basis to ensure each conforms to certain requirements.All changes to asset authorization are performed with the Set Trustline Flags operation.There are three levels of authorization an asset issuer can remove using the Set_Trust_Line_Flag operation:AUTHORIZED_FLAG: signifies complete authorization allowing an account to transact freely with the asset to make and receive payments and place orders.AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG: denotes limited authorization that allows an account to maintain current orders but not to otherwise transact with the asset.CLAWBACK_ENABLED: enables the issuing account to take back (burning) all of the asset. See our section on Clawbacks for more information.Clawback Enabled (0x8)​With the AUTH_CLAWBACK_ENABLED_FLAG flag set, any subsequent trustlines established with this account will have clawbacks enabled. You can read more about clawbacks (and selectively controlling them on a per-trustline basis) here.Note that this flag requires that revocable is also set.Authorization Immutable (0x4)​With this setting, none of the other authorization flags (AUTH_REQUIRED_FLAG, AUTH_REVOCABLE_FLAG) can be set, and the issuing account can’t be merged. You set this flag to signal to potential token holders that your issuing account and its assets will persist on the ledger in an open and accessible state.Set Trustline Flag operation​The issuing account can configure various authorization and trustline flags for individual trustlines to an asset. The asset parameter is of the TrustLineAsset type. If you are modifying a trustline to a regular asset (i.e. one in a Code:Issuer format), this is equivalent to the asset type. If you are modifying a trustline to a pool share, this is the liquidity pool’s unique ID.Example flow​Let’s look at how an issuer of a regulated asset might use the AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG flag.If the issuer wants to approve transactions on a case-by-case basis while allowing accounts to maintain offers, they can leave an account in the AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG state. That account can own offers but cannot do anything else with the asset.To initiate a new operation, the holding account requests that the issuer approve and sign a transaction. Once the issuer inspects the operation and decides to approve it, they sandwich it between a set of operations, first granting authorization, then reducing it.Here’s a payment from A to B sandwiched between set_trust_line_flags operations:Operation 1: Issuer uses SetTrustLineFlags to fully authorize account A, asset XOperation 2: Issuer uses SetTrustLineFlags to fully authorize account B, asset XOperation 3: Payment from A to BOperation 4: Issuer uses SetTrustLineFlags to set account B, asset X to AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG stateOperation 5: Issuer uses SetTrustLineFlags to set account A, asset X to AUTHORIZED_TO_MAINTAIN_LIABILITIES_FLAG stateThe authorization sandwich allows the issuer to inspect the specific payment and to grant authorization for it and it alone. Since operations bundled in a transaction are simultaneous, A and B are only authorized for the specific, pre-approved payment operation. Complete authorization does not extend beyond the specific transaction.Sample code​In the following code samples, proper error checking is omitted. However, you should always validate your results, as there are many ways that requests can fail. Refer to the Error Handling Encyclopedia Entry for tips on error management strategies.The following example sets authorization to be both required and revocable:Limiting the supply of an asset​Warning! This section details how to lock your account with the purpose of limiting the supply of your issued asset. However, locking your account means you’ll never be able to do anything with it ever again- whether that’s adjusting signers, changing the home domain, claiming any held XLM, or any other operation. Your account will be completely frozen.With that warning in mind:It is possible to lock down the issuing account of an asset so that the asset’s supply is permanently fixed. To do this, set the issuing account’s master weight to 0 using the Set Options operation. This prevents the issuing account from being able to sign transactions and therefore, is unable to issue any more assets. Be sure to do this only after you’ve issued all desired assets to the distribution account.Learn more about signature weights in the Signature and Multisig Encyclopedia Entry.See how to do this in step five of the Issuing an Asset Tutorial.","metadata":{"source":"https://developers.stellar.org/docs/issuing-assets/control-asset-access","title":"Asset Design Considerations","contentLength":1571}},{"pageContent":"Issue an Asset TutorialIn this tutorial, we will walk through the steps to issue an asset on the Stellar test network.Prerequisites​You must ensure you have the required amount of XLM to create your issuing and distribution accounts and cover the minimum balance and transaction fees. If you’re issuing an asset on the testnet, you can fund your account by getting test XLM from friendbot. If you’re issuing an asset in production, you will need to acquire XLM from another wallet or exchange.If you’d like to avoid your users having to deal with transaction fees, consider using fee-bump transactions. Read more in our Fee-Bump Transaction Encyclopedia Entry.Learn about the testnet and pubnet in our Testnet and Pubnet section.Learn more about fees in our Fees, Surge Pricing, and Fee Strategies section.1. Create issuing account and an object to represent the new asset​2. Create distribution account​Although it is not required to create a distribution account, it is best practice, so we will do so in this example. Read more in our Issuing and Distribution Accounts section.3. Establish trustline between the two​An account must establish a trustline with the issuing account to hold that account’s asset. This is true for all assets except for Stellar’s native token, XLM.Read more about trustlines in the Trustlines section.If you’d like to avoid your users having to deal with trustlines or XLM, consider using sponsored reserves. Read more in our Sponsored Reserves Encyclopedia Entry.4. Make a payment from issuing to distribution account, issuing the asset​The payment operation is what actually issues (or mints) the asset.5. Optionally , lock the issuing account down so the asset’s supply is permanently fixed​Warning! This section details how to lock your account with the purpose of limiting the supply of your issued asset. However, locking your account means you’ll never be able to do anything with it ever again- whether that’s adjusting signers, changing the home domain, claiming any held XLM, or any other operation. Your account will be completely frozen.Learn more about asset supply in our section on Limiting the Supply of an AssetNote that you’ll want to make sure you publish information about your asset to establish trust with your users. Learn how to do so with our Publish Information About Your Asset section.Full Code Sample​","metadata":{"source":"https://developers.stellar.org/docs/issuing-assets/how-to-issue-an-asset","title":"Issue an Asset Tutorial","contentLength":404}},{"pageContent":"Publish Information About An AssetStellar assets are defined by who issued them, what they represent, and the terms and conditions for their use. These should all be defined and made public by the issuer in a Stellar info file. It’s crucial to provide clear information about what it represents. On Stellar, you do that by linking your issuing account to a home domain, publishing a Stellar info file on that domain, and making sure that file is complete and accurate.The most successful asset issuers give exchanges, wallets, and potential buyers lots of information about themselves in order to establish trust.Completing your Stellar info file is not a step you can skip.What is a Stellar info file?​A Stellar info file is a common place where the Internet can find information about your organization’s Stellar integration. You write it in TOML, a simple and widely used configuration file format designed to be readable by both humans and machines, and publish it at https://YOUR_DOMAIN/.well-known/stellar.toml.That way, everyone knows where to find it, anyone can look it up, and it proves that the owner of the HTTPS domain hosting the stellar.toml claims responsibility for the accounts and assets listed in it.Using a set_options operation, you can link your Stellar account to the domain that hosts your Stellar info file, thereby creating a definitive on-chain connection between this information and that account.Completing your stellar.toml​The first Stellar Ecosystem Proposal (SEP) is SEP-0001: Stellar Info File and specifies everything you would ever need to include in your Stellar info file. This section will walk through the sections of SEP-0001 that relate to asset issuers. Use this section in conjunction with the SEP to ensure you complete your stellar.toml correctly.The four sections we’ll cover are:General InformationOrganization DocumentationPoint of Contact DocumentationCurrency DocumentationFor each of those sections, we’ll let you know which fields are required, meaning all asset issuers must include them to be listed by exchanges and wallets, and which fields are suggested. Completing suggested fields is a good way to make your asset stand out.Note: it's a good idea to keep the sections in the order presented in SEP-0001: Stellar Info File, which is also the order they're presented here. TOML requires arrays to be at the end, so if you scramble the order, you may cause errors for TOML parsers.1. General Information​Required field for all asset issuers:ACCOUNTS: A list of public keys for all the Stellar accounts associated with your asset.Listing your public keys lets users confirm that you own them. For example, when https://google.com hosts a stellar.toml file, users can be sure that only the accounts listed on it belong to Google. If someone then says, \"You need to pay your Google bill this month, send payment to address GIAMGOOGLEIPROMISE\", but that key is not listed on Google's stellar.toml, then users know not to trust it.There are several fields where you list information about your Stellar integration to aid in discoverability. If you are an anchor service, and you have set up infrastructure to interoperate with wallets and allow for in-app deposit and withdrawal of assets, make sure to include the locations of your servers on your stellar.toml file so those wallets know where to find relevant endpoints to query. In particular, list these:Suggested fields for asset issuers:​TRANSFER_SERVER if you support SEP-0006: Deposit and Withdrawal APITRANSFER_SERVER_SEP0024 if you support SEP-0024: Interactive Deposit and WithdrawalKYC_SERVER if you support SEP-0012: KYC APIWEB_AUTH_ENDPOINT if you support SEP-0010: Stellar Web AuthenticationDIRECT_PAYMENT_SERVER if you support SEP-0031: Cross-Border Payments APIIf you support other Stellar Ecosystem Proposals — such as federation or delegated signing — or host a public Horizon instance that other people can use to query the ledger, you should also add the location of those resources to General Information so they're discoverable.2. Organization Documentation​Basic information about your organization goes into a TOML table called [DOCUMENTATION]. Organization Documentation is your chance to inform exchanges and buyers about your business and to demonstrate that your business is legitimate and trustworthy.Required field for all asset issuers:​ORG_NAME The legal name of your organization, and if your business has one, its official ORG_DBA.ORG_URL The HTTPS URL of your organization's official website. In order to prove the website is yours, you must host your stellar.toml on the same domain you list here. That way, exchanges and buyers can view the SSL certificate on your website and feel reasonably confident that you are who you say you are.ORG_LOGO A URL to a company logo, which will show up next to your organization on exchanges. This image should be a square aspect ratio transparent PNG, ideally of size 128x128. If you fail to provide a logo, the icon next to your organization will appear blank on many exchanges.ORG_PHYSICAL_ADDRESS The physical address of your organization. We understand you might want to keep your work address private. At the very least, you should put the city and country in which you operate. A street address is ideal and provides a higher level of trust and transparency to your potential asset holders.ORG_OFFICIAL_EMAIL The best business email address for your organization. This should be hosted at the same domain as your official website.ORG_SUPPORT_EMAIL The best email for support requests.Suggested fields for asset issuers:​ORG_GITHUB Your organization's official Github account.ORG_KEYBASE Your organization's official Keybase account. Your Keybase account should contain proof of ownership of any public online accounts you list here, including your organization's domain.ORG_TWITTER Your organization's official Twitter handle.ORG_DESCRIPTION A description of your organization. This is fairly open-ended, and you can write as much as you want. It's a great place to distinguish yourself by describing what it is that you do.Issuers that list verified information including phone/address attestations and Keybase verifications are prioritized by Stellar clients.3. Point of Contact Documentation​Information about the primary point(s) of contact for your organization goes into a TOML array of tables called [[PRINCIPALS]]. You need to put contact information for at least one person in your organization. If you don't, exchanges can't verify your offering, and it is unlikely that buyers will be interested. Multiple principals can be added with additional [[PRINCIPALS]] entries.Required field for all asset issuers:​name The name of the primary contact.email The primary contact's official email address. This should be hosted at the same domain as your organization's official website.Suggested fields for asset issuers:​github The personal Github account of the point of contact.twitter The personal Twitter handle of the point of contact.keybase The personal Keybase account for the point of contact. This account should contain proof of ownership of any public online accounts listed here and may contain proof of ownership of your organization's domain.4. Currency Documentation​Information about the asset(s) you issue goes into a TOML array of tables called [[CURRENCIES]]. If you issue multiple assets, you can include them all in one stellar.toml. Each asset should have its own [[CURRENCIES]] entry.(These entries are also used for assets you support but don’t issue, but as this section focuses on issuing assets the language will reflect that.)Required field for all asset issuers:​code The asset code. This is one of two key pieces of information that identify your token. Without it, your token cannot be listed anywhere.issuer The Stellar public key of the issuing account. This is the second key piece of information that identifies your token. Without it, your token cannot be listed anywhere.is_asset_anchored An indication of whether your token is anchored or native: true if your token can be redeemed for an asset outside the Stellar network, false if it can’t. Exchanges use this information to sort tokens by type in listings. If you fail to provide it, your token is unlikely to show up in filtered market views.If you're issuing anchored (tethered, stablecoin, asset-backed) tokens, there are several additional required fields:anchor_asset_type The type of asset your token represents. The possible categories are fiat, crypto, stock, bond, commodity, realestate, and other.anchor_asset The name of the asset that serves as the anchor for your token.redemption_instructions Instructions to redeem your token for the underlying asset.attestation_of_reserve A URL to attestation or other proof, evidence, or verification of reserves, such as third-party audits, which all issuers of stablecoins should offer to adhere to best practices.Suggested fields for asset issuers:​desc A description of your token and what it represents. This is a good place to clarify what your token does and why someone might want to own it.conditions Any conditions you place on the redemption of your token.image A URL to a PNG or GIF image with a transparent background representing your token. Without it, your token will appear blank on many exchanges.How to publish your Stellar info file​After you've followed the steps above to complete your Stellar info file, post it at the following location: https://YOUR_DOMAIN/.well-known/stellar.tomlEnable CORS so people can access this file from other sites, and set the following header for an HTTP response for a /.well-known/stellar.toml file request.Access-Control-Allow-Origin: *Set a text/plain content type so that browsers render the contents rather than prompting for a download.content-type: text/plainYou should also use the set_options operation to set the home domain on your issuing account.Sample code to set the home domain of your issuing account​Sample stellar.toml​","metadata":{"source":"https://developers.stellar.org/docs/issuing-assets/publishing-asset-info","title":"Publish Information About An Asset","contentLength":1637}},{"pageContent":"OverviewWhat is an anchor?​An anchor is a Stellar-specific term for the on and off-ramps that connect the Stellar network to traditional financial rails, such as financial institutions or fintech companies. Anchors accept deposits of fiat currencies (such as the US dollar, Argentine peso, or Nigerian naira) via existing rails (such as bank deposits or cash-in points), then sends the user the equivalent digital tokens on the Stellar network. The equivalent digital tokens can either represent that same fiat currency or another digital token altogether. Alternatively, anchors allow token holders to redeem their tokens for the real-world assets they represent.Stellar has anchor services operating worldwide. View the Anchor Directory for more information on existing Stellar anchors.Anchors can issue their own assets on the Stellar network, or they can honor assets that already exist. To learn about issuing assets, check out the Issue Assets section.This documentation will instruct you on how to become an anchor. To understand how to integrate anchor services into your blockchain-based application, check out the Build Apps section and [Connect to Anchors section][/docs/category]. If you’re looking specifically for MoneyGram Access, see the Integrate with MoneyGram Access tutorial.Stellar Ecosystem Proposals (SEPs) and interoperability​Stellar is an open-source network that is designed to interoperate with traditional financial institutions, various types of assets, and other networks. Network participants implement Stellar Ecosystem Proposals (SEPs) to ensure they can interoperate with other products and services on the network. SEPs are publicly created, open-source documents that live in a GitHub repository and they define how asset issuers, applications, exchanges, and other service providers should interact and interoperate.Read more about SEPs in the SEPs section.As an anchor, the most important SEPs are SEP-24: Hosted Deposit and Withdrawal, and SEP-31: Cross Border Payments API. You’ll also work with SEP-10: Stellar Authentication, SEP-12: KYC API, and SEP-38: Anchor RFQ API.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/overview","title":"Overview","contentLength":326}},{"pageContent":"OverviewThe Anchor Platform is the easiest and fastest way to deploy anchor services compatible with Stellar Ecosystem Proposals (SEPs).The goal of the Anchor Platform is to handle all Stellar-specific functionality and requirements for running an anchor, allowing businesses to focus on the core business logic necessary to provide these services.The Anchor Platform accomplishes this by implementing the ecosystem's standardized APIs (SEPs) for wallets, exchanges, and other applications to consume, while offering a set of backend APIs for businesses to provide information specific to them, such as transaction fees, exchange rates, and off-chain transaction statuses.Below is a list of SEPs currently supported:SEP-1: Stellar Info FileSEP-10: Stellar AuthenticationSEP-12: KYC APISEP-24: Hosted Deposit and WithdrawalSEP-31: Cross-Border Payments APISEP-38: Anchor RFQ APIThe documentation for the Anchor Platform is a work in progress. Developers are welcome to dive into the code and existing documentation on the GitHub repository, or if you're looking to build an on & off-ramp service compatible with SEP-24, see our getting started guide.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/","title":"Overview","contentLength":178}},{"pageContent":"ArchitectureArchitecture Overview​Before starting with the Anchor Platform, let's get familiar with the overall architecture. This section will describe the components involved and how they interact.Components​Client​The client is an application, such as a wallet or remittance sender, that acts on behalf of a user and makes requests to the system. Clients make requests to the SEP server component of the Anchor Platform using sets of standards called SEPs (Stellar Ecosystem Proposals).SEP Server​The SEP server is a client-facing server and therefore needs to be accessible from an external network. The SEP server processes user requests and manages the state of transactions they initiate. When the SEP server needs to provide information it doesn't have to the client, such as the exchange rate for an asset pair, it makes synchronous callback requests to the Business Server.Some SEP requests are designed for a client to fetch business-related data, such as quotes or fees. Because it's business-driven, the SEP server will create a request to your server, passing information back to the client. It will also transform the response into a SEP-compliant format. Note that your server only needs to implement endpoints required by the particular SEP you would like to support.Database​The Anchor Platform uses a PostgreSQL database to store Stellar events and entities. Its primary use is to store SEP (24 & 31) transactions.Platform Server​The platform server is an internal component. It should be hosted in a private network and should not be accessible from the Internet. This server enables the business to fetch and update the state of transactions using its API.Stellar Observer​The Stellar observer monitors the Stellar blockchain, automatically detects user payments sent to the business, and updates corresponding SEP transaction statuses.Business Server​Finally, the business server is a server that you (the business) must implement to fully support most of the SEPs offered by the Anchor Platform. The business server responds to callback requests sent by the Anchor Platform (such as requesting a quote for SEP-38) and provides updates to the Anchor Platform when off-chain events occur (like completing a bank transfer).Future architecture​New Components​Event Service​The event service is a new component that will push events to both the client and business via HTTP webhooks.Custody Server​The custody server is a new component that allows businesses to connect to a custodial service (such as Fireblocks) to send and receive payments on the Stellar network. When used in self-custodial mode, this service is a next generation of the existing Stellar Observer.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/architecture","title":"Architecture","contentLength":436}},{"pageContent":"Getting StartedInstallation​The easiest way to install the Anchor Platform is to pull the docker image.Set Up the Development Environment​In this guide we'll use docker compose for simplicity, but you can run the Anchor Platform using other tools that support docker as well, such as minikube or a full-blown kubernetes cluster.Let's create a minimal compose file to get started.The --sep-server option tells the Anchor Platform to make the API endpoints defined by the SEPs you've enabled via configuration available on port 8080.The --platform-sever option makes the Platform API available, which is the backend API your service(s) will use to communicate with the Anchor Platform. It will be available on port 8085Configuration​The Anchor Platform supports two approaches for configuration:using environment variablesusing a YAML configuration fileOne or a combination of both approaches can be used. Nested variables in the YAML file are expressed using underscores or dots (_, .) when using environment variables. We'll demonstrate both approaches here, but use enviroment variables exclusively in subsequent sections. See the full set of configuration options in the Anchor Platform's default values file.Lets create the environment file specified in our docker compose file.And if you're using a YAML configuration file, lets create that too.You'll need to inform the Anchor Platform where it can find your config file. So lets add an environment variable for that.Specify the configuration schema version in your YAML file.Changing Port of the Platform Server​For example, let's change port of the platform server.Using environment variables, this is simply:Or if using YAML configuration:Specify Your Service's Assets​Lets add the assets your Anchor Platform deployment will utilize. This configuration is specified in a YAML file. If you're only using the Anchor Platform for hosting a SEP-1 stellar.toml file or for running SEP-10 Stellar Authentication, you can skip this step.In this guide we'll build anchor services for Circle's USDC on Stellar's test network. Update the above values based on the assets you'll be issuing. Make sure to specify the testnet issuer in your development file, and create your own distribution_account using a tool like Stellar Lab. The distribution_account will be used by your clients as the destination account for payments to your service.This file needs to be referenced in our configuration so the Anchor Platform can find it.Using environment variables:Using a YAML file:Add Data Persistence​The Anchor Platform supports PostgreSQL and Aurora PostgreSQL for use in production, but also supports H2 or SQLite for use in development. For managing migrations, the Anchor Platform uses Flyway. The latest version of PostgreSQL supported by Flyway is PostgreSQL 14.Before we move forward, let's add a database to our development environment so the transactions we initiate persist after stopping the service.A database is only needed if using the Anchor Platform to facilitate transactions.Now let's update our environment so the platform server can connect to the database server.If you're using YAML configuration instead, the POSTGRES_ environment variables should always be in the environment, as they're for your database server, not the Anchor Platform. The secrets must also be specified in environment.We have to create the platform database before the platform server can connect to it, so let's make a script to create our database.Try to run the platform server in addition to the database.You should see the logs reporting a successful connection to the postgres database.Configure Platform API Authentication​To facilitate cross-border payments or deposit & withdrawal transactions, your business will need to fetch and update transaction records from the Anchor Platform's internal API. Currently, the --sep-server option makes public SEP APIs, while internal Platform API available on the Platform server, started by --platform-server option. Business should make Platform Server accessible only in the internal network, however it's possible to add authentication for accessing the internal Platform API.Add the following environment variables.When making requests to the Platform API, add a JWT signed by the secret defined in your environment to the Authorization header as a bearer token.PLATFORM_API_BASE_URL uses platform instead of localhost as the host because you'll be making requests to the Platform API within the local network created by docker compose. When configuring your service in a staging or production environment, make sure to update your service urls.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/getting_started","title":"Getting Started","contentLength":751}},{"pageContent":"ConfigurationLet's enable applications to learn more about your service by hosting a stellar.toml file at a standardized URL path. This file allows applications to find information about your business, the assets your services utilize, as well as the root URL paths for these services. We can host this file using the Anchor Platform.Let's create a file called dev.stellar.toml file using the contents below as a starting point. For the full set of attributes, see the SEP-1 specification.Note that you'll need to create another file for your production deployment that uses the public network's passphrase, your production service URLs, your Mainnet distribution accounts and signing key, as well as the Mainnet issuing accounts of the assets your service utilizes.In your dev.env file, specify the following.This will tell the Anchor Platform that it should host the file specified by SEP1_TOML_VALUE at ./well-known/stellar.toml.Alternatively, your stellar.toml file could be hosted using a proper static file server like nginx. As long as your info file includes the appropriate URLs pointing to the Anchor Platform, this will work just fine.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep1/configuration","title":"Configuration","contentLength":192}},{"pageContent":"ConfigurationEnable Stellar Authentication​Stellar-based wallet applications create authenticated sessions with Stellar anchors by proving they, or their users, have sufficient control over a Stellar account. Once authenticated, the wallet application uses a session token provided by the anchor in subsequent requests to the anchor's standardized services.The Anchor Platform supports this form of authentication with minimal configuration from the business.SEP_10_HOME_DOMAIN is the home_domain property used by [sep-10]. The configuration value must be equal to the host of the toml file. If you are hosting toml file via the Platform, (SEP1_ENABLED is set to true), toml file will be hosted on the SEP server.SECRET_SEP10_SIGNING_SEED is the private key to the public key you've specified as the SIGNING_KEY in your stellar.toml file. It will be used to sign authentication challenges presented to wallet applications, providing that you are in possession of the SIGNING_KEY. Wallets will check for this signature before signing and sending back the authentication challenge.SECRET_SEP10_JWT_SECRET is the encryption key that will be used to sign and verify the authentication tokens you issue to wallet applications after they or their users have proven control of their Stellar account.SEP10_CLIENT_ATTRIBUTION_REQUIRED informs the Anchor Platform whether or not it should allow users of non-custodial wallets to authenticate without the wallet also identifying itself, and SEP10_CLIENT_ATTTRIBUTION_ALLOWLIST is the list of non-custodial wallets that can create authenticated sessions with your services.SEP10_REQUIRE_KNOWN_OMNIBUS_ACCOUNT informs the Anchor Platform whether or not it should allow users of custodial wallets to authenticate without the custodial wallet's public key being included in the SEP10_OMNIBUS_ACCOUNT_LIST.Modify a Stellar Info File​Next, let's modify stellar.toml file created earlier. Wallets need to know that SEP-10 functionality is supported by your business.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep10/configuration","title":"Configuration","contentLength":292}},{"pageContent":"Getting StartedThis guide will walk you through configuring and integrating with the Anchor Platform for the purpose of building an on & off-ramp service compatible with SEP-24, the ecosystem's standardized protocol for hosted deposits and withdrawals.By leveraging the Anchor Platform's support for SEP-24, businesses make their on & off-ramp service available as an in-app experience through Stellar-based applications such as wallets and exchanges, extending their reach and connecting with users through the applications they already use.Before continuing with this section, make sure that you have already installed the Anchor Platform, and configured necessary features, required by SEP-24: SEP-1 (Stellar Info File) and SEP-10 (Stellar Authentication)The Basic User Experience​The complete customer experience a deposit and withdrawal goes something like this:The customer opens the SEP-24 wallet application of their choiceThe customer selects an asset to deposit and the wallet finds an anchor (clients could also chose the specific anchor)Once the wallet authenticates with the anchor, the customer begins entering their KYC and transaction information requested by the anchorThe wallet provides instructions, and the customer deposits real fiat currency with the anchor (e.g. makes a bank transfer)Once the wallet receives the deposit, the customer receives the tokenized asset on the Stellar network from the anchor's distribution accountThe customer can then use the digital asset on the Stellar network for remittance, payments, trading, store of value, or another use case not listed here. At some later date, the customer could decide to withdraw their assets from the Stellar network, which would look something like this:The customer opens their wallet applicationThe customer selects the asset for withdrawal and wallet finds the anchorAfter authenticating with the anchor, the wallet opens the given interactive URL and allows the customer to enter their transaction information (KYC has already been collected)After asking for customer approval, the wallet sends the specified amount of the customer's asset balance to the anchor's distribution account on StellarOnce the anchor receives the payment, the customer receives the withdrawn funds via bank transfer.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep24/","title":"Getting Started","contentLength":351}},{"pageContent":"ConfigurationModify a Stellar Info File​Next, let's modify stellar.toml file created earlier. Wallets need to know that SEP-24 functionality is supported by your business, and they also need to know all currencies you support.Note that you'll need to create another file for your production deployment that uses the public network's passphrase, your production service URLs, your Mainnet distribution accounts and signing key, as well as the Mainnet issuing accounts of the assets your service utilizes.Enable Hosted Deposits & Withdrawals​Now you're ready to enable hosted deposits and withdrawals via the SEP-24 API. Specify the following in your dev.assets.yaml file, and change the values depending on your preferences. This example asset file will enable support for Circle's USDC and a fiat USD.The information provided for the assets value closely maps to the information that will be exposed to the wallet application using the GET /info SEP-24 endpoint. The Anchor Platform also uses this information to validate requests made to your service.Add the following variables to your environment file.SEP24_INTERACTIVE_URL_BASE_URL is the URL that the Anchor Platform will provide to wallet applications when they initiate transactions. Wallet applications will open this URL in a web view inside their app, handing over control of the user experience from the wallet to your business. This URL points to the web widget your business implements. It contains all business-defined logic. We'll dive further into this experience in subsequent sections.SEP24_MORE_INFO_URL_BASE_URL is the URL that the Anchor Platform will provide to wallet applications when they want to show information about a transaction initiated previously. This URL is most often used by wallets in their transaction history views, and your business can define what information to display about the transaction.SECRET_SEP24_INTERACTIVE_URL_JWT_SECRET and SECRET_SEP24_MORE_INFO_URL_JWT_SECRET are encryption keys that the Anchor Platform will use to generate short-lived tokens it will add to the URLs provided to the wallet. Your business server must also have these keys in its environment so it can verify the token's signature.Test With the Demo Wallet​Wallets should now be able to discover, authenticate, and initiate transactions with your service! Your project and source files should now look something like this.Your environment should now look like the following.To test this out, go to the Stellar Demo Wallet.Initiate a transaction by doing the following:Create a new keypairClick the \"Add Asset\" button and enterthe code of the Stellar asset on your stellar.toml fileyour home domain, localhost:8080Select the dropdown and click \"SEP-24 Deposit\", then click \"Start\"The demo wallet should be able to find your stellar.toml file, authenticate using the Stellar keypair you just created, and initiate a transaction. However, when the demo wallet attempts to open the URL provided by the Anchor Platform, you'll get a not found page.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep24/configuration","title":"Configuration","contentLength":480}},{"pageContent":"IntegrationOne of the main points of interaction with the Anchor Platform is notifying the Anchor Platform about events related to the transaction.In general, you'll want to provide updates for the following events:Your business is processing the KYC information provided by the userYour business is ready to receive funds from the userYour business has received funds from the userYour business has sent funds to the userYour business has processed a refund for the user's transactionYour business experienced an unexpected errorThis is done by making a request to the Platform API's PATCH /transactions endpoint. This endpoint allows you to update the data returned from the Platform API's GET /transaction/:id endpoint as well as the data provided to wallet applications through the applicable SEP endpoints.The Anchor Platform PATCH /transactions endpoint is designed to notify the platform about changes of the transaction state. Given that, it will be called every time a user or you (the anchor) take some action that progresses the transaction state in the flow.You can find more about transaction flow and statuses in the SEP-24 protocol documentSecuring Platform API​Using API Key​To enable API key authentication, modify your dev.env file:After it's enabled, all requests must contain a valid X-Api-Key header, set to the configured API key.Using JWT​To enable JWT authentication, modify your dev.env file:After it's enabled, all requests must contain a valid Authorization header. The JWT provided must have the jti and exp fields representing a valid transaction and token expiration time, respectively.Making Patch Requests​Before diving into making PATCH requests, let's create a template for making a request to the Anchor Platform.This small script will make a PATCH /transactions request to the Anchor Platform hosted on the default port (8085). JSON transaction data stored in provided file will be used as body (wrapped into records singleton array).We will also be making a reference to the $transaction_id variable. It's an identification of transaction, that's being returned from the Anchor Platform on an interactive withdrawal or deposit start request. You can obtain the transaction ID by connecting the test wallet to your local Anchor Platform instance. Set this variable in your terminal to be able to execute scripts below.Updating Deposit Transaction Via PATCH​When the user has provided you the information necessary to facilitate the transaction, you need to update the status of the transaction and provide some of the information you collected to the Anchor Platform.The first step of the deposit flow after starting the deposit itself is collecting KYC. It's usually done in the web-app, but can also be optionally provided by the wallet application, using SEP-9. After necessary KYC is collected, a PATCH /transactions request should be made.Processing KYC Information​The update for this action is simply changing the transaction status. It's a good idea to modify the message too, reflecting details of the process:To execute this update, simply runReady to Receive Funds​After KYC is collected, you should be ready to receive the off-chain deposit. While you're waiting for the user to deliver funds, you'll want to provide an updated transaction status and basic transaction information.The amount should be collected in the interactive flow. However, it can also be specified by the wallet as part of the request (see data.amount of the JWT token).Please note that you must specify amount fields, as wallets do not provide this information.amount_in is the amount the user requested. If JWT token's data.amount is not null, amount_in should be equal to that value. In that case, the amount should not be collected in the interactive flow.amount_out is the amount the user will receive.amount_fee is the total fees collected by the application.asset is part of the amount_x field and is in a SEP-38 format. In this example, it's set to USD, assuming the user made a bank transfer to the system using USD.Waiting For User Funds​After the update in the previous chapter has been made, the user will be notified that your service is ready to receive funds. In the real world, the transfer confirmation process may take time. In such cases, transactions should be set to a new status indicating that the confirmation of the transfer has been received but the funds themselves have not yet been received.Sending Stellar Transaction​The next step is to send a Stellar transaction. First, let's change the status to reflect the latest transaction state:Next, send a transaction on the Stellar network to fulfill a user request. Currently, the Anchor Platform doesn't offer such functionality. You may use a custodial service, or manage the distribution account yourself. In the latter case, you may want to use the Stellar SDK on your server side to create, sign, and submit the transaction.Completing Transaction​Finally, after the transaction has been sent and successfully submitted to the network, it's time to complete the transaction:Handling Errors​If you encounter an unrecoverable error when processing the transaction, it's required to set the transaction status to error. The message field can be used to describe error details.Updating Withdrawal Transaction Via PATCH​Once the deposit flow is finished, implementing withdrawal becomes quite easy. Some parts of the flow are similar and can be reused.The starting point for withdrawal and deposit is the same, i.e., collecting and verifying KYC.Ready to Receive Funds​Similar to a deposit, the next step would be to notify the user that the anchor is ready to receive funds. However, as your service will be receiving transactions over the Stellar network, the update would look a bit different.Tracking Stellar Transactions​Using the Payment Observer allows you to delegate this step to the Anchor Platform. To enable the Payment Observer use the --stellar-observer flag in the command section of the compose file.The Payment Observer will track all transactions sent to the distribution account. When the transaction with the correct memo is detected in the network, the status will automatically change to pending_anchor and event will be the emitted (if Kafka is used).In order to update transaction statuses, the observer makes PATCH /transactions requests to the platform, so let's configure the URL it should use.Sending External Transfer​The next step is to send an external transfer, such as a bank transfer, to the user. When done, change the status to notify the user that the transfer has been sent, but has not been confirmed yet.Completing the Transaction​Finally, after the transaction has been successfully sent and submitted to the network, it's time to complete the transaction:Extra Transaction Updates​Expiring Transactions​Your business may want to expire transactions that have been abandoned by the user after some time. It's a good practice to clean up inactive transactions in the incomplete status. To do so, simply change the transaction status to expired","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep24/integration","title":"Integration","contentLength":1179}},{"pageContent":"ExampleIntegrating with the Anchor Platform involves three key areas:Building a web-based user experience that can be opened in a mobile web viewProviding transaction status updates to the Anchor PlatformFetching transaction status updates from the Anchor PlatformBuilding a Web-Based User Experience​The Anchor Platform does not offer a white-label UI that your business can utilize, and instead expects the business to build their own UI and backend system. We won't build an entire on & off-ramp user experience in this guide, but will cover the ways in which your existing product should be updated to be compatible with the Anchor Platform.Authentication​If your business has an existing on & off-ramp product, you likely have an existing system for user authentication. However, because the Anchor Platform authenticates the user prior to providing the business's URL, requiring the user to go through another form of authentication is actually unnecessary. In this way, the Anchor Platform can be thought of as providing an alternative form of authentication.The business is free to continue requiring users to authenticate using their existing system, but the ideal user experience would skip this step and create an authenticated session for the user if they have already authenticated using their Stellar account.The Anchor Platform adds a JWT token query parameter to the business's URL given to the wallet application. This token is signed by the previously-configured SECRET_SEP24_INTERACTIVE_URL_JWT_SECRET value, and includes the information you need to identify the user. The process should look something like this:Pass the token added to the URL of your backend systemVerify the signature on the token and check its expirationCreate an authenticated session for the user identified by token.subThe decoded contents of the token will look something like this:Note that the sub value identifies the user using a Stellar account and integer. This is what the value will be when custodial applications that use an omnibus account authenticate with your service. When non-custodial wallets authenticate, the token may look slightly different.The sub value here only contains a public key to identify the user, and the data.client_domain field identifies the wallet application used to authenticate.In both cases, all information in the data object is optional, and will only be present if the wallet provides that information.Let's add a backend server to our compose file that will be used to verify the token and create authenticated web sessions for users initiating transactions.Let's create a simple Docker container for our application.Now let's create a minimal NodeJS application.Below is an example of a backend server authenticating a user using NodeJS.Run this with the platform server and database and initiate a new transaction with the demo wallet. Then, we'll send the token to our server.Providing Updates to the Platform​Let's create an endpoint for our business server that accepts the information collected in our UI.This will update the Anchor Platform's database with the information provided and enable wallet applications to fetch this updated information so it can relay it back to the user. You should have already informed the user of the transaction's amounts and that your business's is waiting for the on-chain payment to arrive, but providing these updates allows users to view their transactions' statuses through their mobile application without opening the business' UI again.Fetching Updates from the Platform​If you only use the Anchor Platform to expose the SEP APIs to wallet applications, then you won't have a strong reason for fetching transaction status updates from the Anchor Platform, mostly because it won't update the transaction status until you make requests to PATCH /transactions.However, if you use the Anchor Platform to monitor the Stellar network for incoming payments (associated with withdrawal transactions), the Anchor Platform will update transaction statuses when payments are received.There are two ways to fetch updates from the Anchor Platform,Polling the Platform API's GET /transactions/:id endpoint for the transactions you're expecting a payment forStreaming transaction status change events from a Kafka clusterWhile streaming transaction status changes from a Kafka cluster may be a more robust and scalable approach, we're going to use the polling method in this guide. Setting up and using a Kafka cluster will be the subject of a different section of the docs.First, let's configure the Anchor Platform to observe the Stellar network for incoming payments.The --stellar-observer command starts a process that monitors the distribution accounts configured in your config.yaml file for withdrawal payments.If a payment is sent to one of these accounts and the memo attached to the transaction matches a memo value provided or generated by the Anchor Platform, the Anchor Platform will consider the transaction that memo is associated with as received and update the transaction's status to pending_anchor. It does this by making a request to the PATCH /transactions endpoint, so we need to configure the URL it should use.Let's make some additions to the server.js file so we can poll the Anchor Platform for our expected payments.Full Example Implementation​Stellar provides an example business server implementation for SEP-24. It's split into two parts: 1) a web UI, accessible for the end user; and 2) a back-end implementation, used to get and push updates from/to the Anchor Platform.The code for web UI can be found hereThe code for the backend is a part of the Anchor Platform, and is available as a submodule.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep24/example","title":"Example","contentLength":935}},{"pageContent":"FAQHow To Use Interactive JWTs?​As part of the flow, once a user makes an interactive withdrawal/deposit request, it will be processed by the Anchor Platform and forwarded to your service. The Anchor Platform will make a GET call to <configured interactive url>?token=<jwt token>.This JWT token will contain:exp is the expiration time of the token. You should check that the provided token has not expired.sub is the account associated with this transaction. It can be used to identify the user account. Note that this value may be different from the account that will be used to receive/send funds.jti is the hash of the transaction.data is the extra payload that has been set by the user. It will always contain the Stellar asset wants to deposit or withdraw. If provided by the client, it will also contain the amount the user wants to transact, the client_domain of the wallet verified during SEP-10 authentication, and the lang (language) preference of the user.How To Provide Fees?​Currently, it's recommended to provide fees/exchange rates in the iFrame/web view of your application.SEP-24 standard provides a /fee endpoint to allow businesses to set static fees for their transactions. However, it's not currently supported by the Anchor Platform.How to identify the user account?​You should use the sub field of the JWT token. For custodial wallets, this value will be in the format account:memo. Use the memo to identity the user. For noncustodial wallets, simply use the sub value itself, which will be equal to the user account.How to identify the wallet?​You should use a combination of sub and data.client_domain fields of the JWT token. For custodial wallets, the sub value will be in the format account:memo. Use the account to identify the wallet. For noncustodial wallets, use the data.client_domain field. Note that the wallet must provide the client_domain beforehand as a part of SEP-10 authentication.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep24/faq","title":"FAQ","contentLength":334}},{"pageContent":"Set Up a Production ServerOnce the test server is live and you have tested both deposit and withdraw flows, it's time to get started with the real deploy connected to real KYC and real banking rails providers. Before using any banking APIs, it's critical that you perform a full security audit on the system to make sure that there aren't any vulnerabilities.Deploying a Secure Environment​Make sure to keep the test server up, and deploy the production (mainnet) system in a separate environment. Having two deploys allows you to validate new features on the testnet before moving them to the final production deploy. You can also have a third staging environment if there's a big team working on this codebase and/or there will be many pushes to be tested internally before sharing with other institutions.To switch to Stellar's public (mainnet) network, all you have to do is change the network passphrase (for authenticating requests) and Horizon URL.You can copy your existing development configs to create a production configuration.First, you need to change your info file (stellar.toml):Next, change your Anchor Platform configuration in production.env file:Connecting to Real KYC​Most anchors need to collect Know Your Customer information to comply with local regulations before honoring deposits and withdrawals. The KYC flow usually consists of a simple form that gathers relevant information about the user such as name, email, address, age, and government-issued ID number.How you handle KYC is up to you: there are many services that provide KYC solutions through APIs and iFrames, and validate the input data and sync with governmental databases to verify requirements. Each jurisdiction has specific KYC requirements, and they differ from jurisdiction to jurisdiction, so it's best to find a country-specific KYC provider that meets your needs.Some countries require different KYC fields depending on the amount to be deposited or withdrawn. If that's the case in your jurisdiction and you need to adapt your KYC forms based on the deposit or withdrawal amount, simply add an amount field before the KYC form, and make sure that the KYC fields are updated based on that value.KYC information should be linked to the session created through Stellar Web Authentication and, consequently, to the user, so you only need to ask the user for it once. After the first KYC flow is complete, a user shouldn't have to input the information again.Make sure the errors and validation messages are clear and include instructions for what to do next to ensure a good user experience and increase the KYC conversion rate. You should also localize messages based on the user's language and location.Pre-Filling the KYC Form​Pre-filling the KYC form is a great way to reduce the friction of getting started using an anchor, and wallets usually provide a set of fields that are commonly used throughout the ecosystem. In summary, the anchor can render the KYC form with the user's values that were previously sent by the wallet in the /transactions/deposit/interactive and /transactions/withdraw/interactive endpoints.All fields from SEP-9 can be sent by wallets in the previously mentioned endpoints, but the most common are: email, first name, last name and phone number. Also, you should still enable the pre-filled fields to be editable, since the user might have inputted a different name in the Wallet's sign-up process, and could want to edit it before finalizing the Anchor's KYC process.All SEP-9 data that was sent from the wallet is a part of the Interactive JWT, send by the Anchor PlatformConnecting to Real Banking Rails​Fiat-backed token issuers are expected to manage a full reserve. That means there's a 1:1 relationship between Stellar-network tokens and money in the bank. Since each fiat token on Stellar is backed by, and can be redeemed for, an underlying, real-world asset, issuers of fiat-backed tokens need to connect to real banking rails to validate user deposits (through bank transfers, credit card payments, etc.) and to complete user withdrawals (generally through bank transfers). If you're an anchor honoring deposits and withdrawals of a token another organization issues, you'll follow a similar process.In order to fetch (and identify) a user transfer, issuers usually take one of two approaches:API Polling: this option consists of fetching the bank's API, through a cron job, to check for the updated status of the list of transfers received by (and sent from) the issuer's bank account. Once the system confirms a new transaction and identifies that it relates to a specific deposit, it can send the digital funds to that user's accountWebhook: not all banking rails support this option, but it's the leanest in terms of back-end logic. In this approach, the bank proactively hits an issuer's endpoint once it receives a new transfer, updating that information on the issuer's database. The issuer can then can match that transaction to an existing in-process deposit, and validate that the user can receive their digital fundsThere are many ways to identify that a specific bank transfer relates to a specific deposit (and, consequently, to a user). Some banks (and countries) have transfer infrastructure that allows the creation of a single bank account per transfer; others require users to add an identification parameter to their transfers. Some banks provide the user ID number in the transaction information so issuers can match that with the information provided in the KYC form.Make sure to do a full security audit on your systems when banking rails connections are in place. Some banks provide a testing API that can be used for development and deployment to testnet or staging environments, which means you can test and audit the codebase before moving to a final production-ready bank integration. For better security, some anchors also prefer to add a manual final step before approving withdrawal transfers. In terms of UX, this manual approval is acceptable as long as the wait times align with user expectations, which usually means they aren't longer than a couple of hours.Testing Edge Cases​Once your application is fully functional, it's a good idea to test different scenarios and edge cases to make sure the system is behaving as expected. Here's a list of testing suggestions that should cover a large amount of the application's edge cases:General Tests​Test the interactive flow usabilityTest the interface using different locale information, and check for translated content including error messages, responses, date formatting, and number formattingKYC Tests​Check that KYC appears with a new wallet SKCheck that KYC doesn't accept incorrectly formatted inputs, and that the error messages are comprehensibleCheck that you can use the same KYC information (email, phone number, username, etc) multiple timesCheck that you can go through KYC multiple times with the same Stellar SK.Interactive Test​Check that the deposit flow goes through, and that the banking rails are workingCheck that you cannot make a withdrawal with a value higher than the current balanceCheck that the withdrawal flow goes through, and that the banking rails are workingSecurity Tests​Make sure platform endpoints are securedPolishing and Internationalization​Supporting two languages (English and the fiat currency country language) allows users to have a seamless experience while navigating through screens, and supports international institutions (like wallets) that need to test the product before starting new integrations.You can support multiple languages in your webapp by using the Accept-Language parameter from the http request headers to localize the content and allowing users to change that in a simple way (e.g. a flag icon on the top bar). If a specific wallet doesn't send the header parameter, we recommend showing the user a language selection screen in the beginning of the deposit and withdraw processes. Once a user chooses a language, you can store their selection so you only need to ask them once. In addition to localizing text, make sure to check number formatting, dates, etc.Having a group of beta testers is a great way to check if there are any edge cases that need polishing, and to confirm that the system is working well with a variety of user inputs. You can beta test using a soft launch stage before you start putting effort into marketing and distribution. Documenting the testing process with screenshots and videos is very helpful for future security audits, and gives new partners and potential users clarity and confidence in the product.Connecting to Wallets​All Anchor user interactions are done through a Wallet, so it's vital for Anchors to be connected to Wallets that have a good market penetration in the region where the business is most focused. Connecting to Wallets is a simple process, since both ends of that integration are already compliant with SEPs.Stellar.org maintains a list of wallets, many of which currently support SEP-24 Sending them a message with more information on an asset and an issuer account is a great way to start getting some real users to the Anchor.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep24/setting-up-production-server","title":"Set Up a Production Server","contentLength":1542}},{"pageContent":"Getting StartedThis guide will walk you through configuring and integrating with the Anchor Platform for the purpose of building a cross-border payments recieve-side service compatible with SEP-31, the ecosystem's standardized protocol for cross-border payments.By leveraging the Anchor Platform's support for SEP-31, businesses make their service compatible with Stellar's existing set of send-side services.Before continuing with this section, make sure that you have already installed the Anchor Platform and configured the necessary features required by SEP-31: SEP-1 (Stellar Info File) and SEP-10 (Stellar Authentication).","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep31/","title":"Getting Started","contentLength":97}},{"pageContent":"ConfigurationModify a Stellar Info File​Let's start by modifying our stellar.toml file created earlier. Wallets need to know that SEP-31 functionality is supported by your business, and they also need to know all currencies you support.Note that you'll need to create another file for your production deployment that uses the public network's passphrase, your production service URLs, your mainnet distribution accounts and signing key, as well as the mainnet issuing accounts of the assets your service utilizes.Enable Cross Border Payments​Now you're ready to enable cross-border payments the SEP-31 API. Specify the following in your dev.assets.yaml file.The information provided in the sep31 and send objects closely map to the information that will be exposed to the wallet application using the GET /info SEP-31 endpoint. The Anchor Platform also uses this information to validate requests made to your service. sep31.fields.transaction should be left empty and will be removed in a future release, but you can adjust the send.min_amount and send.max_amount values according to your service's limits.The sep31.quotes_supported and sep31.quotes_required determine whether or not sending organizations can and are required to request an FX rate using the SEP-38 POST /quote endpoint. Almost all senders prefer this approach so that they can communicate the rate to their customers prior to proceeding.Add the following variable to your environment file.Senders should now be able to discover, authenticate, and initiate transactions with your service! Run the following command to start the Anchor Platform.Check that your API is live.You should get the following.Enable the Customer KYC API​Businesses need to collect and validate KYC information on the customers they're facilitating transactions for. Clients determine what KYC information needs to be collected and send that information via a SEP-12 KYC API hosted by the Anchor Platform, but the Anchor Platform never stores personally-identifiable information (PII). Instead, it forwards requests from clients to the business server, and returns the business' responses back to the client, acting as a proxy server.See the Anchor Platform KYC API specification for details on the endpoints that must be implemented on your business' server.To make this API available to clients, lets add the service URL to our Stellar Info File.Lets enable it in our environment too.Finally, we have to define your business' customer types. Each type of customer requires different a set of KYC information. For example, you can offer your cross-border payments service in two distinct regulatory jurisdictions, so customers in different jurisdictions have different KYC requirements and would be represented using different types.In this guide, we'll only have two types, a sending customer type and a receiving customer type. Currently, our customer types are defined in our assets configuration, but this will change in a future release.Lets ping the info endpoint again to verify. After docker compose up, run the following command:You should get the following:Enable the RFQ API​Businesses need to provide their send-side counterparts with an API to check the exchange rates they're offering between the on-chain asset being used for settlement and the fiat asset being used to pay the recipient. If the rate is competitive, senders also need to be able to request a commitment to the rate currently being offered from business for a short period of time.The Anchor Platform provides the SEP-38 RFQ API to senders for this purpose and requires receive-side services to implement the simplified GET /rate and GET /fee endpoints for the Anchor Platform to use on the backend.To make this API available to clients, lets add the service URL to our Stellar Info File.Lets enable it in our environment too.We also need to enable USDC to be used in this API, as well as add an off-chain asset it can be exchanged with.Lets test that your RFQ API is live! Following docker compose up:You should get the following:Configure Callback API Authentication​Just as your business will need to make requests to the Anchor Platform, the Anchor Platform will need to make requests to your business. Let's add authentication to these requests as well.CALLBACK_API_BASE_URL uses server instead of localhost as the host because the Anchor Platform will be making requests to your business server from within the local network created by docker compose. When configuring your service in a staging or production environment, make sure to update your service urls.We'll define the server that implements the endpoints defined in the Callback API in the following section.","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep31/configuration","title":"Configuration","contentLength":781}},{"pageContent":"IntegrationIntegrating with the Anchor Platform for facilitating cross-border payments involves implementing the following, at a mimimum:GET /customer & PUT /customer KYC API endpoints to request & collect customers' KYC dataGET /rate RFQ API endpoint to provide FX rates between the on & off-chain assets supportedGET /transactions requests to fetch updates on the Anchor Platform's transactions' statuses (documentation coming soon)PATCH /transactions requests to update the Anchor Platform's transactions' statusesThe following may also be required depending on your use case:GET /fee if your business wants to provide senders the option to skip the quote creation stepGET /unique_address if your business uses a custody service for on-chain assetsDELETE /customer if your business wants or is required to allow senders to request deletion of customer dataCreate a Business Server​First, lets create a business server and add it to our docker compose file.Next, create a simple web server using your preferred programming language and a Dockerfile that starts the server. docker compose up should successfully start all three services.This guide does not provide an example implementation of the endpoints, but you can find more information about the request and response schemas in the Anchor Platform API Reference, and the sections below will expand on concepts important to understand when implementing the endpoints.Customer Callback Endpoints​The Anchor Platform never stores your customers' PII, and instead acts as a proxy server between client applications and your business, forwarding requests and responses to the other party. Currently, requests and responses are almost identical to those defined in the SEP-12 KYC API specification.Identifying Customers​Customers can be identified using two approaches.The first approach uses a Stellar account and memo. When using the Anchor Platform for facilitating cross-border payments, the sending organization uses their own Stellar account, the one used to authenticate via SEP-10 Stellar Authentication, when registering customers with your business. Memos are used to distinguish unique customers originating from the same sending organization.The second approach uses customer IDs generated by your service. For example, if a sending organization is registering a customer, your business will receive a PUT /customer request like the following:In this example, the GDJ...X47 public key identifies the sending organization, and the 780284017 memo identifies the customer. Memos are usually 64-bit integers, but they can also be other data types, so they should be saved as strings. In response, your business should return a customer ID.Your business server can use any identifer for customers as long as it is a string.Following the registration of a customer, the sending organization can use either approach when checking the customer's status. For example, you may get a GET /customer request like the following:Or, the sending organziation could use the identifier you returned when they originally registered the customer.Your business will need to maintain a mapping between the account & memo used to originally register the customer and the ID you return in the response, as well as the KYC data provided. In future iterations of the Anchor Platform, we may maintain this mapping for your business so you only have to work with the IDs you generate.Customer Types​Your business likely requires different sets of KYC information depending on the type of customer. You can define the labels for each of these customer types in your dev.assets.yaml file, and your sending organizations will need to understand which label to use when registering or querying the status of customers.In PUT /customer requests, you should use the type passed to evaluate whether the sender has provided all of the required fields. In GET /customer requests, you should use the type to determine the customer's status.Test with the Demo Wallet​You can test your implementation with the Stellar Demo Wallet following the steps below.Select \"Generate keypair for new account\"Select \"Create account\"Select \"Add Asset\" and enter the asset code and the Anchor Platform's home domain, localhost:8080Select \"Add trustline\"Fund your account with a balance of the assetSelect \"SEP-31 Send\" in the dropdown menuYou should see the demo wallet find your service URLs, authenticate, and check which KYC fields it needs to collect. It should then present a form for you to enter the KYC details for the sender and reciever.Once you've entered in the information requested, it will send that information to the Anchor Platform, which will send it to your business server. Once the demo wallet has the customers' IDs you generated, it will initiate a transaction which should fail.Rate Callback Endpoint​Once the sending organization has registered the customers involved in the transaction, it will need to request a quote, or FX rate, from your business. The Anchor Platform requests this information from your business server using the GET /rate endpoint.Firm vs. Indicative Quotes​Requests for quotes will have a type parameter that is either indicative or firm. If type=firm, your response must include the id & expires_at date-time field and reserve the liquidity needed to fulfil this quote until the quote expires. If type=indicative, do not return id or expires_at fields because the rate provided will not be used in a transaction.Note that the client may request that the quote expires after a specific date-time using the expires_after parameter. Your business must honor this request by returning an expires_at value that is at or after the requested date-time or reject the request with a 400 Bad Request response, which will be forwarded to the client.Using the Client ID​Requests may include a client_id parameter that identifies the sending organization requesting the rate. You can use this parameter to adhere to the commercial terms agreed upon with that sending organization, such as offering discounted rates. client_id may not be present for indicative requests, in which case your market price should be returned. Currently client_id will always be the Stellar public key the sending organization used to authenticate with the Anchor Platform.Delivery Methods​It is common for businesses' rates and fees to differ depending on the payment rails used to send funds to the recipient. If your delivery methods are configured in your asset.yaml file, clients will always provide the payment rail they want your business to use for firm quote requests.Because this endpoint is currently only used paying out remittances in off-chain assets, the buy_delivery_method will be used. If this endpoint is ever used in other transaction flows such as SEP-24 deposits, then sell_delivery_method may also be passed for business that support these types of transactions.Fetching Transaction Status Updates​To facilitate cross-border payments, you'll need to be able to detect when a sending organization has sent your business an on-chain payment and determine which transaction that payment was meant to fulfil.The easiest way to do that is to run the Stellar Observer, which will detect these payments and update the corresponding transaction record with information about the payment. Your business can then detect these updates by polling the GET /transactions Platform API endpoint.Running the Stellar Observer​The Stellar Observer monitors the Stellar ledger for payments made to your account(s) and updates the corresponding transaction records with on-chain payment information. To run the observer, add the following to your docker compose file.Polling for Received Payments​The Stellar Observer makes PATCH /transactions requests to the Platform API whenever it detects payments received for transactions initiated by sending organizations, updating the transaction's transfer_received_at date-time. Your business should periodically poll the GET /transactions Platform API endpoint to detect these updates like so.The response will include a list of cross-border payment transactions initiated by sending organizations ordered by when a payment was received for that transaction. For each transaction returned, your business should check whether or not it has already detected the payment for that transaction. If it has, you have detected all payments made to your account(s).Providing Transaction Status Updates​Once your business detects that it has received an on-chain payment for a specific transaction, it must make the off-chain payment to the recipient and update the transaction's status to completed via a PATCH /transactions request.Fee Callback Endpoint​Your business may want to offer sending organizations the option to skip the quote creation process, allowing your business to use a rate determined at the time funds are paid out to the recipient. In this case, the Anchor Platform will not make a GET /rate request, but you will still need to provide the fee your business will charge for these types of transactions using the GET /fee endpoint.Configuration​You can enable these types of transactions by updating your assets.yaml file configuration:Unique Address Callback Endpoint​Businesses must provide a unique Stellar account and memo pair for each transaction requested by sending organizations so the Anchor Platform can identify and map the on-chain payment sent for the specific transaction. The Anchor Platform can generate these account & memo pairs itself, but most businesses use a custodial service to receive on-chain payments, in which case the business must request the custodian to generate the Stellar account & memo. This is done using the GET /unique_address endpoint.Configuration​To configure the Anchor Platform to make these requests, add the following to your configuration:","metadata":{"source":"https://developers.stellar.org/docs/anchoring-assets/anchor-platform/sep31/integration","title":"Integration","contentLength":1566}},{"pageContent":"OverviewStellar is an open-source distributed ledger that you can use as a backend to power various applications and services, such as wallets, payment apps, currency exchanges, micropayment services, platforms for in-game purchases, and more — check out projects being built on Stellar: Stellar Ecosystem Projects.Stellar has built-in logic for key storage, creating accounts, signing transactions, tracking balances, and queries to the Stellar database, and anyone can use the network to issue, store, transfer, and trade assets.Anchors​Many Stellar assets connect to real-world currencies, and Stellar has open protocols for integrating deposits and withdrawals of these assets via the anchor network. Because of this, a Stellar-based application can take advantage of real banking rails and connect to real money.Stellar Ecosystem Proposals (SEPs)​Stellar-based products and services interoperate by implementing various Stellar Ecosystem Proposals (SEPs), which are publicly created, open-source documents that live in a GitHub repository and define how asset issuers, anchors, wallets, and other service providers interact with each other.As a wallet, the most important SEPs are SEP-24: Hosted Deposit and Withdrawal, and SEP-31: Cross Border Payments API, SEP-10: Stellar Authentication, SEP-12: KYC API, and SEP-38: Anchor RFQ API.This documentation will walk you through how to build wallets using the Wallet SDK (Kotlin and Typescript are currently supported) and how to build a comprehensive basic payment application.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/overview","title":"Overview","contentLength":233}},{"pageContent":"Application Design ConsiderationsCustody models​When building an application, one of the first things you have to decide is how your users’ secret keys will be secured and stored. Stellar applications give users access to their accounts that are stored on the ledger, and access to these accounts is controlled by the account’s secret key. That secret key proves that the user has custody or “owns” the account.There are four custody options to consider:Non-custodial service - the user of the application stores their own secret keyCustodial service - the service provider (application) stores the users’ secret keysMixture of both - with the use of multisig, this option is useful for maintaining non-custodial status while still allowing for account recoveryThird-party key management services - integrate a third-party custodial service into your application that can store your users’ secret keysNon-custodial service​In a non-custodial service, the user of the application stores the secret key for their account and permissions the application to send requests to delegate transaction signing. There are some potential usability issues as the user has to know how to securely store their own account credentials and safely navigate transaction signing on their end. If they lose their secret key, they will also lose access to their account.Typically, non-custodial applications create or import a pre-existing Stellar account for each user.Custodial service​With a custodial service, the service provider (an application such as a centralized exchange) stores the users’ secret keys and delegates usage rights to the user.Many custodial services choose to use a single pooled Stellar account (called shared, omnibus, or pooled accounts) to handle transactions on behalf of their users instead of creating a new Stellar account for each user. To distinguish between individual users in a pooled account, we encourage the implementation of muxed accounts.Learn how to set up an application as a custodial service in this [tutorial].A mixture of non-custodial and custodial​Building an application with multi-signature capabilities allows you to have a non-custodial service with account recovery. If the user loses their secret key, they can still sign transactions with other authorized signatures, granted the signature threshold is high enough.Third-party key management services​​There are several apps and services that specialize in adding additional security layers to users' accounts. Check them out if you're interested in integrating a third-party key management service:StellarAuthStellar AuthenticatorLedgerTrezorStellarGuardLobstrVaultApplication security​Even though wallets can operate client-side, they deal with a user’s secret keys, which give direct access to their account, and to any value they hold. That’s why it’s essential to require all web traffic to flow over strong TLS methods. Even when developing locally, use a non-signed localhost certificate to develop secure habits from the very beginning. Stellar is a powerful money-moving software — don’t skimp on security.For more information, check out our guide to securing web-based products.Wallet services​A wallet typically has these basic functions: key storage, account creation, transaction signing, and queries to the Stellar database. There are some services that take care of all of these functions for you, so you can build whatever you’d like around it. Check out some of these wallet services below.AlbedoFreighterAccount creation strategies​In this section, we will go over the new user account creation flow between non-custodial wallets and anchors with SEP-24 and/or SEP-6 implementations. A Stellar account is created with a keypair (a public key and private key) and the minimum balance of XLM.When a new customer downloads the wallet application and goes through the deposit flow for the first time, their Stellar account can be created by either the user’s wallet application or the anchor facilitating the first deposit. This section describes each of these strategies.Option 1: The anchor creates and funds the Stellar account​​For this option, the wallet needs to allow users to initiate their first deposit without having to add an asset/establish a trustline. The wallet then prompts the user to add the trustline once funds are received by the anchor. The flow looks like this:The wallet registers a new user and issues a keypair.The wallet initiates the first deposit on behalf of the user without requiring the user to add the asset/create the trustline.The anchor provides deposit instructions to the customer.The user transfers money from a bank account to the anchor’s bank account.Once the anchor receives the transfer, the anchor creates and funds the Stellar account for the customer.The wallet detects that the account has been created and a trustline must be established.The wallet prompts the user to add the asset/create the trustline.Finally, the anchor sends the deposit funds to the user’s Stellar account.With the flow described above, the wallet and the anchor have to facilitate listening for and responding to the trustline status, which can create user experience frictions when waiting for the trustline to be established. To address this issue, Protocol 15 introduced claimable balances, which enhance the flow by allowing users to start using the wallet without having to secure XLM. Both the wallet and the anchor have to implement claimable balance support in order to make this flow work.The flow with Claimable Balances looks like this:The wallet registers a new user, and generates a keypair.The wallet initiates a deposit on behalf of a user.The anchor provides deposit instructions to the wallet.The user transfers money from a bank account to the anchor’s account.The anchor creates and funds the user's Stellar account plus the amount required for trustlines and transaction fees. Again, we suggest 2 XLM to start.The anchor creates a Claimable Balance.The wallet detects the Claimable Balance for the account, claims the funds, and posts it in the wallet.Option 2: the wallet creates and funds the Stellar account upon user sign-up​​For this option, the wallet creates and funds the Stellar account upon every new user sign-up with the minimum requirement of 1XLM, plus the .5XLM reserve for establishing the first trustline, plus a bit more to cover transaction fees. For more information on minimum balances, check out the Lumens section.The flow looks like this:Upon a new user signup, the wallet issues a keypair, then creates and funds the user's Stellar account with 2XLM.Then the wallet creates a trustline, and initiates the first deposit.Once the deposit request is sent to the anchor, the anchor provides instructions for the deposit.The customer transfer funds from a personal bank account to the anchor’s account.The anchor receives the funds, then sends them to the user’s Stellar account.The wallet detects that funds were sent and notifies the user.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/application-design-considerations","title":"Application Design Considerations","contentLength":1144}},{"pageContent":"OverviewIn this guide we will use the Wallet SDK to integrate with the Stellar blockchain and connect to anchors.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/wallet/overview","title":"Overview","contentLength":19}},{"pageContent":"Getting StartedInstallation​First, you need to add the SDK dependency to your project.Working with the SDK​Let's start with the main class that provides all SDK functionality. It's advised to have a singleton wallet object shared across the application. Creating a wallet with a default configuration connected to Stellar's Testnet is simple:The wallet instance can be further configured. For example, to connect to the public network:Configuring the Client​The Typescript wallet SDK uses the axios client for all network requests. You can read more about how to configure the axios client here.For example, we can configure our axios client to be globally configured with a timeout:You can find more configure options here.Stellar Basics​The wallet SDK provides some extra functionality on top of the existing Horizon SDK. For interaction with the Stellar network, the wallet SDK covers only the basics used in a typical wallet flow. For more advanced use cases, the underlying Horizon SDK should be used instead.To interact with the Horizon instance configured in the previous steps, simply do:This example will create a Stellar class that manages the connection to Horizon service.You can read more about working with the Stellar network in the respective section.Anchor Basics​Primary use of the SDK is to provide an easy way to connect to anchors via sets of protocols known as SEPs. Let's look into connecting to the Stellar test anchor:And the most basic interaction of fetching a SEP-1: Stellar Info File:The anchor class also supports SEP-10: Stellar Authentication and SEP-24: Hosted Deposit and Withdrawal features.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/wallet/intro","title":"Getting Started","contentLength":273}},{"pageContent":"Stellar NetworkIn the previous section we learned how to create a wallet and a Stellar object that provides a connection to Horizon. In this section, we will look at the usages of this class.Accounts​The most basic entity on the Stellar network is an account. Let's look into AccountService that provides the capability to work with accounts:Now we can create a keypair:Build Transaction​The transaction builder allows you to create various transactions that can be signed and submitted to the Stellar network. Some transactions can be sponsored.Building Basic Transactions​First, let's look into building basic transactions.Create Account​The create account transaction activates/creates an account with a starting balance of XLM (1 XLM by default).Modify Account​You can lock the master key of the account by setting its weight to 0. Use caution when locking the account's master key. Make sure you have set the correct signers and weights. Otherwise, you will lock the account irreversibly.Add a new signer to the account. Use caution when adding new signers and make sure you set the correct signer weight. Otherwise, you will lock the account irreversibly.Remove a signer from the account.Modify account thresholds (useful when multiple signers are assigned to the account). This allows you to restrict access to certain operations when the limit is not reached.Modify Assets (Trustlines)​Add an asset (trustline) to the account. This allows the account to receive transfers of the asset.Remove an asset from the account (the asset's balance must be 0).Building Advanced Transactions​In some cases a private key may not be known prior to forming a transaction. For example, a new account must be funded to exist and the wallet may not have the key for the account so may request the create account transaction to be sponsored by a third party.First, the account must be created.This transaction must be sent to external signer (holder of externalKeyPair) to be signed.Signed transaction can be submitted by the wallet.Now, after the account is created, it can perform operations. For example, we can disable the master keypair and replace it with a new one (let's call it the device keypair) atomically in one transaction:Sponsoring Transactions​Sponsor Operations​Some operations, that modify account reserves can be sponsored. For sponsored operations, the sponsoring account will be paying for the reserves instead of the account that being sponsored. This allows you to do some operations, even if account doesn't have enough funds to perform such operations. To sponsor a transaction, simply start a sponsoring block:Sponsoring Account Creation​One of the things that can be done via sponsoring is to create an account with a 0 starting balance. This account creation can be created by simply writing:Note how the transaction source account should be set to sponsorKeyPair. This time, we need to pass the sponsored account. In the example above, it was omitted and was defaulted to the transaction source account (sponsoredKey).However, this time, the sponsored account (freshly created) is different from the transaction source account. Therefore, it's necessary to specify it. Otherwise, the transaction will contain a malformed operation. As before, the transaction must be signed by both keys.Sponsoring Account Creation and Modification​If you want to create an account and modify it in one transaction, it's possible to do so with passing a sponsoredAccount optional argument to the sponsored block. If this argument is present, all operations inside the sponsored block will be sourced by sponsoredAccount. (Except account creation, which is always sourced by the sponsor).Fee-Bump Transaction​If you wish to modify a newly created account with a 0 balance, it's also possible to do so via FeeBump. It can be combined with a sponsoring block to achieve the same result as in the example above. However, with FeeBump it's also possible to add more operations (that don't require sponsoring), such as a transfer.First, let's create a transaction that will replace the master key of an account with a new keypair.Second, sign transaction with both keys.Next, create a fee bump, targeting the transaction.Finally, submit a fee-bump transaction. Executing this transaction will be fully covered by the sponsorKeyPair and sponsoredKeyPair and may not even have any XLM funds on its account.Using XDR to Send Transaction Data​Note, that a wallet may not have a signing key for sponsorKeyPair. In that case, it's necessary to convert the transaction to XDR, send it to the server, containing sponsorKey and return the signed transaction back to the wallet. Let's use the previous example of sponsoring account creation, but this time with the sponsor key being unknown to the wallet. The first step is to define the public key of the sponsor keypair:Next, create an account in the same manner as before and sign it with newKeyPair. This time, convert the transaction to XDR:It can now be sent to the server. On the server, sign it with a private key for the sponsor address:When the client receives the fully signed transaction, it can be decoded and sent to the Stellar network:Submit Transaction​Finally, let's submit a signed transaction to the Stellar network. Note that a sponsored transaction must be signed by both the account and the sponsor.The transaction is automatically re-submitted on the Horizon 504 error (timeout), which indicates a sudden network activity increase.However, the method above doesn't handle fee surge pricing in the network gracefully. If the required fee for a transaction to be included in the ledger becomes too high and transaction expires before making it into the ledger, this method will throw an exception.So, instead, the alternative approach is to:This will create and sign the transaction that originated from the sourceAccountKeyPair. Every 30 seconds this function will re-construct this transaction with a new fee (increased by 100 stroops), repeating signing and submitting. Once the transaction is successful, the function will return the transaction body. Note, that any other error will terminate the retry cycle and an exception will be thrown.Accessing Horizon SDK​It's very simple to use the Horizon SDK connecting to the same Horizon instance as a Wallet class. To do so, simply call:And you can work with Horizon Server instance:","metadata":{"source":"https://developers.stellar.org/docs/building-apps/wallet/stellar","title":"Stellar Network","contentLength":1068}},{"pageContent":"Stellar AuthenticationWallets connect to anchors using a standard way of authentication via the Stellar network defined by the SEP-10 standard.This guide will cover all ways to use SEP-10 to authenticate with an anchor.Creating Authentication Key​First, let's create an authentication key. While you can use the same key for authentication and sending funds, it's recommended to split the responsibilities. In your application, you will have one or more fund keypairs (keypairs for the accounts that hold funds and initiate and receive transactions) and one authentication key.The authentication key is only used for authentication purposes and doesn't need to hold any funds. Note that you don't need to create an account for this keypair either.Go to the Stellar Lab and generate a keypair. The secret key must be handled securely, because it will be used for authentication.Basic Authentication​Let's do a basic authentication. In this example, we will use wallet SDK to create an authentication token.First, let's create an anchor object to work with the anchor you are integrating with. In this example, we will be using a reference anchor implementation with the home domain testanchor.stellar.orgNext, authenticate with the authKey created earlier:For non-custodial wallets, you want to use the user's private key as an authKey.Home Domain (Optional)​The home domain is the optional parameter for SEP-10 authentication, when a single auth server is shared between multiple domains. Some anchors may require you to provide this argument. The SDK automatically sets the home_domain parameter in all SEP-10 requests.Client Domain (Optional)​Supporting client_domain comes in two parts, the wallet's client and the wallet's server implementations. In this setup, we will have an extra authentication key. This key will be stored remotely on the server. Using the SEP-1 info file, the anchor will be able to query this key and verify the signature. As such, the anchor would be able to confirm that the request is coming from your wallet, belonging to wallet's client_domain.Client Side​First, let's implement the client side. In this example we will connect to a remote signer that signs transactions on the endpoint https://demo-wallet-server.stellar.org/sign for the client domain demo-wallet-server.stellar.org.Let's add authentication with a bearer token. Simply update the request transformer:Server Side​Next, let's implement the server side.First, generate a new authentication key that will be used as a client_domain authentication key.Next, create a SEP-1 toml file placed under <your domain>/.well-known/stellar.toml with the following content:Don't forget to change the network passphrase for Mainnet deployment.Finally, let's add server implementation. This sample implementation uses express framework:You can see full example here. As mentioned before, this sample implementation doesn't have any protection against unauthorized requests, so you must add authorization checks as part of the request.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/wallet/sep10","title":"Stellar Authentication","contentLength":498}},{"pageContent":"Hosted Deposit and WithdrawalThe SEP-24 standard defines the standard way for anchors and wallets to interact on behalf of users. Wallets use this standard to facilitate exchanges between on-chain assets (such as stablecoins) and off-chain assets (such as fiat, or other network assets such as BTC).During the flow, a wallet makes several requests to the anchor, and finally receives an interactive URL to open in iframe. This URL is used by the user to provide an input (such as KYC) directly to the anchor. Finally, the wallet can fetch transaction information using query endpoints.Get Anchor Information​Let's start with getting an instance of Interactive class, responsible for all SEP-24 interactions:First, let's get the information about the anchor's support for SEP-24. This request doesn't require authentication, and will return generic info, such as supported currencies, and features supported by the anchor. You can get a full list of returned fields in the SEP-24 specification.Interactive Flows​Before getting started, make sure you have connected to the anchor and received an authentication token, as described in the Stellar Authentication wallet guide. We will use the token object in the examples below as the SEP-10 authentication token, obtained earlier.To initiate an operation, we need to know an asset. You may want to hard-code it, or get it dynamically from the anchor's info file, like shown above (for USDC):Basic Flow​Let's start with a basic deposit:As a result, you will get an interactive response from the anchor.Open the received URL in an iframe and deposit the transaction ID for future reference:Similarly to the deposit flow, a basic withdrawal flow has the same method signature and repose type:Providing KYC Info​To improve the user experience, the SEP-24 standard supports passing user KYC to the anchor via SEP-9. In turn, the anchor will pre-fill this information in the interactive popup.Changing Stellar Transfer Account​By default, the Stellar transfer will be sent to the authenticated account (with a memo) that initiated the deposit.While in most cases it's acceptable, some wallets may split their accounts. To do so, pass additional account (and optionally a memo):Similarly, for a withdrawal, the origin account of the Stellar transaction could be changed:Getting Transaction Info​On the typical flow, the wallet would get transaction data to notify users about status updates. This is done via the SEP-24 GET /transaction and GET /transactions endpoint.Alternatively, some anchors support webhooks for notifications. Note that this feature is not widely adopted yet.Tracking Transaction​Let's look into how to use the wallet SDK to track transaction status changes. We will use Watcher class for this purpose. First, let's initialize watcher and start tracking a transaction.Alternatively, we can track multiple transactions for the same asset.Fetching Transaction​While Watcher class offers powerful tracking capabilities, sometimes it's required to just fetch a transaction (or transactions) once. The Anchor class allows you to fetch a transaction by ID, Stellar transaction ID, or external transaction ID:It's also possible to fetch transaction by the assetSubmitting Withdrawal Transfer​Previously, we took a look at starting the withdrawal flow. Now, let's take a look at a full example.First, start the withdrawal:Next, open an interactive url :After that we need to wait until the anchor is ready to receive funds. To do so, we will be waiting until transaction reaches pending_user_transfer_start statusNext, sign and submit the Stellar transfer:Where keypair is the SEP-10 authenticated account. If you want to transfer funds from a different address, refer to Changing Stellar Transfer Account section.Finally, let's track transaction status updates. In this example we simply check if the transaction has been completed:","metadata":{"source":"https://developers.stellar.org/docs/building-apps/wallet/sep24","title":"Hosted Deposit and Withdrawal","contentLength":639}},{"pageContent":"Project SetupThroughout this tutorial we'll be making use of a little toolchain called StencilJs. It takes the best of modern frontend frameworks and pares everything back to small, blazing fast, 100% standards-based Web Components that run in every browser. Don’t worry if you've never heard of it: it's just TS (JS), SCSS (CSS) and JSX (HTML). You should be able to follow along just fine if you've ever built something with modern web dev tools.We chose Stencil so you can learn by doing: it’s an easy way to create a web-based application, which means you can see the ins and outs of building a Stellar wallet start to finish. Stellar also has a suite of SDKs in various programming languages, so if Javascript isn’t your thing, you can follow along, and recreate the steps below using one of them.To start the setup, open your terminal and initialize a new project.After running init you will be provided with a prompt to choose the type of project to start. While Stencil can be used to create entire apps, we’ll choose the component as we’ll just be dealing with modular components rather than building an entire applicationWe’ll walk through the prompt, cd into the project and run npm i ; npm startNow that our project is initialized, let’s take a look at the directory structure and familiarize ourselves with where things are and what roles they play.We’re mostly interested in the src/ directory. The dist/ and www/ directories are outputs for compiled code. In the src/components/ directory you’ll see a my-component/ folder. We’re about to generate our own component, so go ahead and delete that folder. You can also nuke the utils/ directory as we won’t be covering tests in this tutorial. Now run:This will initialize a component generation script. Enter a name of stellar-wallet. Disable Spec Test and E2E Test as we’re not interested in those Stencil features today. Press Return and your component will generate and wire up.Amazing! Just a few more setup bits and we can get coding. I don’t know about you but I prefer to style in SCSS rather than CSS so let’s get some modern CSS dev tools setup.Once those packages have successfully installed, hop over to the stencil.config.ts file at the root of the project and modify it to this:With that file saved, pop over to the src/components/wallet/ and rename the wallet.css to wallet.scss. While we’re here let’s go ahead and modify this new style file with some basic styling to put our project in a pretty place.Before we update our wallet.tsx with this new stylesheet, note that we’re also importing a global stylesheet. Go ahead and create that file at the root of the src/ directory. So src/global/style.scss.Save those style files and update the wallet.tsx to point to our new styles like so:You’ll notice we also include a few extra setup lines to get the StellarSdk loaded in and ready to use. Let’s ensure all those dependencies are loaded and ready to rock.The last mod: point the src/index.html file to use this brand new component. Modify that file to match this.You should be all set up now. Restart the server and let’s get coding.View the full setup code on GitHub","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/project-setup","title":"Project Setup","contentLength":590}},{"pageContent":"Create a Basic WalletView the setup boilerplate code on GitHubUser Flow​Because we've decided to build a non-custodial wallet, we don’t need to communicate with a server or database at all: everything can happen locally right on a user’s device. We’ll be doing all our work inside of src/components/wallet/, so head over there now. We’re going to use the StellarSdk.Keypair.random() from the StellarSdk to generate a new valid Stellar keypair. That's the easy part. The hard work will be storing that vital information in a secure yet accessible manner.The user flow we're building will work like this: Click “Create Account” → UI modal popup asking for a pin code → Enter pin code, click “OK” → App encrypts a new Stellar keypair secret key with pin code → App saves encrypted secret to localStorage. On page reload, we’ll fetch the publicKey to “login” the user, but for any protected action such as “Copy Secret”, the modal will pop back up asking for the original pin code.Create a Popup Modal​To start, let's look at at the popup modal. We’ll be mimicking the browser’s prompt functionality with our own new, more powerful component. First things first we should generate a new component:Call it stellar-prompt, and deselect both test files leaving only the styling. Once you have that, open src/components/prompt/ and rename the .css file to .scss. Fill that style file with this:Replace the prompt.tsx contents with this.One of the first things you’ll notice is the use of lodash-es. Let’s make sure we’ve got that imported before moving forward:There’s a lot going on in this file, but since this isn’t a Stencil tutorial we’ll skip the details. What this allows us to do it to use a <stellar-prompt prompter={this.prompter} /> component elsewhere in our project. It's worth noting the variables available to us in the prompter property.The values we’ll be making most use of are those first three: show, message and placeholder. The last two—resolve and reject—are for promisifying the prompt so we can await a response before continuing with further logic. Don't worry: that statement will make more sense in a moment once we include this component in src/components/wallet/. Speaking of, let’s swing over to that component now.We’ve got a lot of work to do in here so I’ll just paste the code in all its glory and we’ll walk through it block by block:They say the beginning is a good place to start. Let’s do that:Just one import from a library we should already have installed.The other relative path imports are all the events and methods we’ll create here in a moment. For now, just generate all those files in their appropriate directories. Ensure your console is at the root of the stellar-wallet project before running this string of commands:Next we have this funky line which may seem like an npm team import, but is actually a fancy typescript module alias path.This allows us to avoid long error prone ../../../ paths and just use @{alias}/{path?}/{module}. In order to get this past both the linter and compiler we’ll need to modify a couple files.First, modify the tsconfig.json file to include these values in the compilerOptions object.Next,modify the package.json file to include a _moduleAliases key at the root of the object.Finally, install the module-alias package and add it to the top of the src/index.ts file.Cool! With any luck we should be able to use these slick alias imports for the prompt and services directories now.Create Stellar Account Class​interface is just the TypeScript way of setting up a tidy typed class. StellarAccount will be our account class. It includes the publicKey for easy reference later in Horizon or Astrograph calls and the Top Secret keystore key containing the encrypted account secret cipher.Pretty standard boring bits, setting up the @Component with its defining values and initializing with some @State and @Prop data. You can see we’re setting up an account state with our StellarAccount class as well as a prompter state with that Prompter class from the stellar-prompt we imported earlier. We’re initializing that prompter state with a show value of false so the prompt modal rendereth not initially.Everything after this is the assignment of our imported events and methods from up above. Let’s begin with the ./events/componentWillLoad.tscomponentWillLoad is the Stencil way of pre-filling the state and prop values before actually rendering the component. In our case we’ll use this method to populate the account @State with the saved storage keyStore value if there is one. At first there won’t be, so we’ll come back to this once we’ve actually gone over how to create and save accounts. For now just know it’s here, and since you’re smart, I imagine you can already kind of see how it works.“But wait!” you say, “What are the @services/error and @services/storage packages?” Fine, yes, we should go over those. Remember the module alias stuff from earlier? Well one was for @prompt and the other was for @services. Go ahead and create these two files and add them to the src/services directory.error.ts will look like this.Nothing fancy, just a clean little error handler we’ll make use of later when processing API requests.Set Up Key Storage​Next is storage.ts.You’ll notice a new package @capacitor/core. Let’s install and set that up.We’re not really making full use of Capacitor , but it is an amazing service so be sure and check it out! For now we just need it to make storing and retrieving our data a bit more stable.This storage service is simply a key setter and getter helper for storing and retrieving data. We’ll use this for any persistent data we want to store. For now, that's our Stellar account data.Set Up Event Handling​That’s everything we need for the componentWillLoad event. On to the ./events/render.tsx file.It looks messy, but it’s actually a pretty simple .tsx file rendering out our DOM based off a series of conditional values. You can see we’re including the stellar-prompt component, and setting the prompter prop to our this.prompter state. We then have a ternary operation toggling between a Create Account button and a basic account UI. If this.account has a truthy value, we’ll print out the account’s publicKey along with some interaction buttons. If this.account is falsey, we’ll print out a singular Create Account button connected to, you guessed it, the createAccount method. After that logic, we print out an error if there is one, and finally a Sign Out button if there’s an account to sign out of. Those are the two Wallet @Component events.Create Methods​Let’s look at the methods now beginning with the ./methods/createAccount.ts file.Aha! Finally something interesting. This method forms the meat of our component. Before we dive into it, though let’s install the missing @tinyanvil/sjcl package.Create an Account​Essentially all we’re doing is making a request to create an account, which triggers the Prompt modal to ask for a pincode. That pincode will be used in the sjcl.encrypt method to encrypt the secret key from the Keypair.random() method. We set the this.account with the publicKey, which encrypted the keystore cipher, and now we're storing that cipher in base64 format in localStorage via our set('keyStore') method for easy retrieval when the browser reloads. We could also encode that cipher into a QR code or a link to share with other devices. Since it requires the pincode that encrypted cipher, it's as secure as the pincode you encrypt it with.Copy Address​Now that we’ve created an account, there are three more actions we'll enable: copyAddress, copySecret, and signOut.First ./methods/copyAddress.tsWell there you go, the easiest code you’ll see all day. Just copy the publicKey from the this.account object to the clipboard. Before we jump though don’t forget to install that copy-to-clipboard package.Copy Secret​Next ./methods/copySecret.tsYou may not actually include this in your production wallet, but for now it's a simple demonstration of how to programmatically gain access to the secret key at a later date for making payments, creating trustlines, etc. It’s essentially the createAccount in reverse: it asks for the pincode to decrypt the keystore which, once decrypted, we copy into the clipboard.Sign Out​Finally ./methods/signOut.tsIt’s important to allow users to nuke their account, but we need to be careful to confirm that action with our faithful setPrompt. Once they opt to “NUKE” the account we can remove the keyStore and reload the app.Set Prompt​Speaking of setPrompt the last method in our wallet.ts file is ./methods/setPrompt.ts.In setPrompt, we see how the prompt state is set, and how the Promise is set up to allow us to wait on the prompt whenever we call this method. It’s actually pretty slick, and it might be worth looking back at the src/components/prompt/prompt.tsx to see how the resolve and reject functions get called. It’s not central to our wallet creation, but it’s a pretty handy little component that will serve us well in the future as we continue to request input from the user.That’s it folks! Restart the server with npm start and you’ve got a perfectly legitimate, minimal Stellar wallet key creation and storage Web Component! It's a solid foundation for a non-custodial wallet that relies on a simple pincode.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/basic-wallet","title":"Create a Basic Wallet","contentLength":1684}},{"pageContent":"Set Up a Custodial AccountThis guide describes how to add assets from the Stellar network to your custodial service. First, we walk through adding Stellar's native asset: lumens (XLM). Following that, we describe how to add other assets. This example uses Node.js and the JS Stellar SDK, but it should be easy to adapt to other languages.Account Setup​Pooled account​Most custodial services, including cryptocurrency exchanges, choose to use a single pooled Stellar account to handle transactions on behalf of their users instead of creating a new Stellar account for each customer. Generally, they keep track of their customers in a separate, internal database and use the memo field of a Stellar transaction to map an incoming payment to the corresponding internal customer.The benefits of using a pooled account are lower costs – no base reserves are needed for each account – and lower key complexity – you only need to manage one account keypair. However, with a single pooled account, it is now your responsibility to manage all individual customer balances and payments. You can no longer rely on the Stellar ledger to accumulate value, handle errors and atomicity, or manage transactions on an account-by-account basis.Code Framework​You can use this code framework to integrate Stellar into your custodial service. For this guide, we use abstract placeholder functions for reading/writing to your internal customer database, since each organization will architect their infrastructure differently. Here are the functions we'll assume exist (along with their expected behavior):Integration points for listing XLM​Setting the memo required flag on your account​Before we get into the main integration points for adding XLM support to your product or service, make sure to configure your pooled account to require memos. This step is necessary to prevent users from forgetting to attach a memo, which can increase customer support requests and lead to a less desirable user experience for new customers. This article explains how to set that up.Listening for incoming payments from the Stellar network​First, you need to listen for payments to the pooled account and credit any user that receives XLM there. For every payment received by the pooled account:check the memo field to determine which user should receive the payment, andcredit the user’s account with the amount of XLM they received.This is the role of depositIntoPool, described above. You pass this function as the onmessage option when you stream payments:When someone outside of your customer base wants to send XLM to one of your customers, instruct them to make an XLM payment to your pooled account address with the customer ID in the memo field of the transaction. Assuming you have set the memo_required configuration on your account (see above), well-behaved wallets should enforce it and prevent users from forgetting to attach memos to incoming payments. To be on the safe side, however, you should make it incredibly clear to senders that their payment will end up in limbo if they fail to attach a valid one. You can learn more about the transaction memo field here.When someone inside of your customer base wants to send XLM to another one of your customers, you have two choices: you can send a memo'd payment exactly as above — this lets you maintain an audit trail, ensures the balance exists in the custodial account, etc. — or you can do the exchange \"off-chain\", i.e. by exclusively adjusting balances within your database.Submitting outgoing payments to the Stellar network​When one of your customers wants to make an outgoing XLM payment, you must generate a Stellar transaction to send XLM. See building transactions or the payments tutorial for more information.The aforementioned createPayment function will prepare the corresponding operation whenever a withdrawal is requested (while withdrawFromPool should manage your balance sheet). You can use these to queue up transactions (for periodic or batched submission) or submit them immediately. It's up to you how to architect this portion; we adopt the (simpler) latter approach here:This code would be called whenever one of your customers submitted a payment through your platform. Note that the balances are adjusted before the transaction is confirmed, so you should take care to adjust them back if there's a failure (e.g. implement reverseWithdrawal for your architecture).Listing Other Stellar Assets​All of the code above is asset-agnostic, so accepting other (non-native/lumen) assets into your custodial account can be achieved after fulfilling a few prerequisites.Account Setup​First, you must open a trustline with the issuing account of the asset you’d like to list – without this, you cannot begin accepting the asset. The Issue an Asset tutorial covers the code for this one-time process.Next, if the asset issuer has the authorization_required flag on their account set, you will need to wait for them to authorize the trustline before you can begin accepting the asset. Read more about trustline authorization here.Managing Supply​Custodians usually hold a float of the assets they list on their platform. Unlike Stellar’s native asset (XLM), which can only be sourced from the Stellar Decentralized Exchange (SDEX), non-native assets can also be sourced directly from the asset’s issuer. For example, custodians can establish a Circle Account to source Stellar USDC.Regardless of the strategies used to purchase the asset, you’ll need to adapt your balance sheet management (e.g. the internals of depositIntoPool and withdrawFromPool, above) to track things per-asset for each customer. Since this is backend-specific, we won’t provide example code here.For more information about non-native assets, check out the asset issuing guide.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/setup-custodial-account","title":"Set Up a Custodial Account","contentLength":949}},{"pageContent":"Make XLM PaymentsView keystore boilerplate code on GitHubIn the Build a Basic Wallet section, we did the hard work of wiring up a secure client and rock-solid key creation and storage structure with a clear plan for key use and management. Now that we have a method for creating an account — and for storing that account's secrets so they're safe and easy to use — we're ready to start making payments. We'll start with XLM payments since they're a little simpler; in the next section, we'll look at how to support payments for other assets.There isn’t too much that's new or complicated here: we'll be building on what we already have. Again, most of the work will be in src/components/wallet/; however, before we dive into that file let’s clean up our project just a touch and add some helpful polish. Namely a loader component.Add Loader Component​Hopefully by now you’re familiar with how to generate new Stencil components.We'll call the component stellar-loader, and deselect both test files leaving only the styling. Once you've done that, open src/components/loader/ and rename the .css file to .scss. Then replace the loader.tsx contents with this:Don’t forget to install new packages!It’s a fancy wackadoodle little component which at the end of the day just produces a little loader for use in our action buttons.Import Methods​We’re now ready to tackle the src/components/wallet/wallet.ts file.If you’ve followed other tutorials in this series much of this may be review, but we’ll just walk along this file and see exactly what’s going on.Imports galore! Nothing really noteworthy here other than you’ll notice we’re importing ./methods/updateAccount and ./methods/makePayment methods which we’ll be creating soon. There are a number of updates in the other methods from previous tutorials, and we’ll walk through all of those in a moment as well.Here we’re setting up two TypeScript classes: one for our account and the other for our loading states.Here we set up our @State’s, those dynamic properties with values that will change and alter the DOM of the component, and our @Prop, which in this case will hold a static reference to our Stellar server instance.Update Component Events​Next let’s update our two component events ./events/componentWillLoad.ts and ./events/render.tsx:In Stencil’s componentWillLoad method, we set up default values for the States and Props we initialized earlier. Most notably, we’re setting our server and account. You’ll notice we’re using the public horizon-testnet for now — we're just learning, and not ready to send live XLM — but in production you’d want to change this to the public horizon endpoint or, if you're running your own Horizon, to one of your own Horizon API endpoints.For the account we’re simply checking to see if a keyStore value has been stored, and if so we’re grabbing the public key and keystore from it and adding those to the account @State. The state value, which is optional, is not set here as we’ll need to run the method updateAccount() to find if the account exists, and if so what the state of that account looks like. We’ll get to that method shortly. For now let’s update our render.tsx method:Yikers amirite!? Don’t worry though: it’s actually quite simple if you’ve spent any time with HTML in JS before. What we're looking at are a few ternary operators toggling the UI between different states based on the account status. Basically just a bunch of buttons wired up to their subsequent actions. Turns out creating those buttons is next on our to-do list!Create Buttons​updateAccount and makePayment are new; createAccount will just need a few tweaks. Let’s start with that one.Fund Account Using Friendbot​The only new thing we’re adding here — other than a loading state and an initial this.updateAccount() call at the end — is the call to friendbot.stellar.org, which is a testnet tool that we can use to automatically fund our new testnet account with 10,000 XLM. Nice little shortcut to kickstart our development.In production, you would have to find an actual source for funding the account. Some wallets fund users' accounts for them; some require the user to supply the funds.So that’s the updated ./methods/createAccount.ts file.Update Account Method​Now let’s create two new files for updating the account and making XLM payments.Let’s start with the simpler one, ./methods/updateAccount.tsAll we’re doing here is looking up the state of the Stellar account on the ledger and saving it to the this.account.state. You’ll also notice we’re omitting several fields from the account and balances for easier readability. You may choose to save these and selectively display the values you care about, but in our example we’re just displaying the raw JSON, so cleaning things up a little is the right move.this.account = {...this.account, state: loOmit(account, ['id', ...])} may feel odd, but it’s just the Stencil way of updating a state’s object key to trigger a re-render of the DOM. You’ll notice this.loading follows the same pattern. We’ll make use of this data further down in the render method, but for now just know this is how we would grab ahold of the account to get the latest state.Make Payment Method​Next let’s break down the main subject method for this tutorial, ./methods/makePayment.ts:This method is quite massive, so let’s break it down further so it's easier to understand exactly what is going on.We’re going to need a couple pieces of info from the user: the amount of XLM to send, what address to send it to, and the pincode for unlocking the keystore file. We request those asynchronously and cancel out of the method if they aren’t provided.Next we unpack the keystore with the pincode, reset any existing errors, and trigger the pay loading boolean:From there we call the keypair account to retrieve its current sequence number so we can prepare a transaction with a payment operation. We set the destination and amount using the instructions from the prompt we collected and split earlier. Finally, we build, sign, and submit that transaction to the Stellar Horizon API server.If the account we want to send XLM is unfunded (and therefore doesn't yet exist on the ledger), we'll get back op_no_destination. This catch handles that issue by trying again with a createAccount operation. For any other issues we just pass the error on unmodified.Finally, we log any success transaction, kill the loader, and updateAccount to reflect the new balance in our account after successfully sending XLM. We also have our catch block that passes to the handleError service. We will render that in a nice error block in the UI.There we go! That wasn’t so bad right? Pretty simple, and yet from this tutorial we have the power to hold and observe balances, and to make payments using the power of the Stellar ledger. Amazing!","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/xlm-payments","title":"Make XLM Payments","contentLength":1242}},{"pageContent":"Handle Custom AssetsView pay boilerplate code on GitHubWhat's a Custom Asset?​Stellar allows anyone to easily issue an asset, and all assets can be held, transferred, and traded just like XLM, the network token. Every asset other than XLM exists on the network in the form of trustlines: an asset holder explicitly agrees to allow a balance of a specific token issued by a specific issuing account by creating a persistent ledger entry tied to the holding account. You can find out more in the guide to creating custom assets.Each trustline increases the user's base reserve by 0.5 XLM, and in this tutorial, we'll go over how to set up your wallet to create trustlines and manage the base reserve on behalf of a user.Add Trustlines Button​To enable custom asset handling, we need to modify three files and create one new one. Let’s start with our modifications. First up the ./events/render.tsx file. We need to add a button for creating these new trustlines!If you look closely you’ll spot the Trust Asset button right below our account-key div. Nothing funky here, just a button that triggers this.trustAsset method which we’ll add in a moment.Next up, let’s update the ./methods/makePayment.ts file.This is a big file that was covered in great detail in the Make XLM Payments tutorial, so we’ll just focus on the changes we need to make to support custom asset payments.This change allows us to indicate a specific asset code we’d like use to make a payment and triggers an additional prompt to set the issuer for that asset if it’s not the native XLM.This is just a nifty little helper shortcut to allow us to use the ME “issuer” to swap with our actual account publicKey. Niceties make the world go ‘round.The final noteworthy change is a ternary operation that switches our payment asset between the native XLM and a custom asset based off of responses to our prompt. Essentially, if instructions[3] exists — meaning there is an issuer — use that issuer and custom token as the asset for the payment. Otherwise, just use the native Asset.The final changes are in the wallet.ts itself and tie together all the other updates as well as pull in the new trustAsset method.Only thing worth seeing here besides the inclusion of the new trustAsset method is the addition of the trust?: boolean, in the Loading class.Add Trustlines​Alright so, finally we get to the ./methods/trustAsset.ts file!This is similar to the makePayment method but there are a couple tiny tweaks worth noting:We’re allowing the inclusion of several arguments in this function, namely asset, issuer, and pincode. We won’t be making use of them here, but transparently creating trustlines from within other functions will prove useful later.If we have any of those variables set, we can “preload” our interface a bit, and even bypass user input altogether if a pincode is provided. Again, not something we’ll make use of quite yet, but once we look into depositing and withdrawing assets from an Anchor or accepting incoming payments for which we don’t yet have a trustline this functionality will prove useful.So there we have it! The ability to accept and pay with custom assets on Stellar!","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/custom-assets","title":"Handle Custom Assets","contentLength":571}},{"pageContent":"Fund the Account and make the First DepositIn this section, we will go over the new user account creation flow between non-custodial wallets and anchors with SEP-24 and/or SEP-6 implementations. Before we dive into the flow, it’s important to understand how Stellar accounts are created in the first place.The first step in creating a Stellar account is to generate a keypair. This keypair includes public and private keys. However, an account does not exist and does not warrant space on the ledger until it’s funded with the minimum balance of 1XLM by a Create Account operation. This requirement was created to minimize unused accounts from bloating the ledger. For a more in-depth look at this topic, check out this page.Who creates the new user accounts?​When a new customer downloads the wallet application and goes through the deposit flow for the first time, their Stellar account can be created by either the user’s wallet application or the anchor facilitating the first deposit. This section describes the possible strategies and flows for you to consider.Option 1: The anchor creates and funds the Stellar account​For this option, the wallet needs to allow users to initiate their first deposit without having to add an asset/establish a trustline. The wallet then prompts the user to add the trustline once funds are received by the anchor. The flow looks like this:The wallet registers a new user and issues a keypair.The wallet initiates the first deposit on behalf of the user without requiring the user to add the asset/create the trustline.The anchor provides deposit instructions to the customer.The user transfers money from a bank account to the anchor’s bank account.Once the anchor receives the transfer, the anchor creates and funds the Stellar account for the customer.The wallet detects that the account has been created and a trustline must be established.The wallet prompts the user to add the asset/create the trustline.Finally, the anchor sends the deposit funds to the user’s Stellar account.Note: An anchor should always maintain a healthy amount of XLM in its distribution account to support new account creations. If doing so becomes unsustainable, it’s recommended that the anchor collaborates with wallets to determine a strategy based on the number of account creation requests. The recommended amount is 2XLM per user account creation (1XLM to meet the minimum balance requirement, and 1XLM for establishing trustlines and covering transaction fees).With the flow described above, the wallet and the anchor have to facilitate listening for and responding to the trustline status, which can create user experience frictions when waiting for the trustline to be established. To address this issue, Protocol 15 introduced Claimable Balances, which enhance the flow by allowing users to start using the wallet without having to secure XLM wait to create the trustline after they made their first deposit. Both the wallet and the anchor have to implement Claimable Balance support in order to make this flow work.The flow with Claimable Balances looks like this:The wallet registers a new user, and generates a keypair.The wallet initiates a deposit on behalf of a user.The anchor provides deposit instructions to the wallet.The user transfers money from a bank account to the anchor’s account.The anchor creates and funds the user's Stellar account plus the amount required for trustlines and transaction fees. Again, we suggest 2 XLM to start.The anchor creates a Claimable Balance.The wallet detects the Claimable Balance for the account, claims the funds, and posts it in the wallet.Option 2: The wallet creates and funds the Stellar account upon user sign-up​For this option, the wallet creates and funds the Stellar account upon every new user sign-up with the minimum requirement of 1XLM, plus the .5XLM reserve for establishing the first trustline, plus a bit more to cover transaction fees. For more information on minimum balances, check out the Lumens section.The flow looks like this:Upon a new user signup, the wallet issues a keypair, then creates and funds the user's Stellar account with 2XLM.Then the wallet creates a trustline, and initiates the first deposit.Once the deposit request is sent to the anchor, the anchor provides instructions for the deposit.The customer transfer funds from a personal bank account to the anchor’s account.The anchor receives the funds, then sends them to the user’s Stellar account.The wallet detects that funds were sent and notifies the user.Note: In the examples above, we suggest having the anchor or wallet cover minimum balance and trustline XLM requirements by depositing funds directly into a user's account. We made that suggestion for the sake of simplicity, but in all cases, the anchor or wallet could instead use Sponsored Reserves to ensure that when a user closes a trustline or merges their account, the reserve reverts to the sponsoring account rather than to the user's account.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/first-deposit","title":"Fund the Account and make the First Deposit","contentLength":845}},{"pageContent":"Interoperability BasicsStellar makes it easy to issue assets and to connect them to existing banking rails so that users can move value onto — and off of — the network. The services that create those connections are called anchors.Most Anchors set up infrastructure to enable wallets to offer in-app deposits and withdrawals by following best practices specified in Stellar Ecosystem Proposals. SEPs are publicly created, open-source documents that live in a Github repository. They define how different institutions (such as asset issuers, wallets, exchanges, and service providers) should interact and interoperate. If you're building an app, you can implement the client side of some key SEPs and immediately give your users access to a whole world of local fiat currenciesThis part of the tutorial will focus on the Interactive Anchor/Wallet Asset Transfer Server SEP (aka SEP-24), which defines the specs for deposit and withdrawal implementations. It's focused on the client side of interactive user flows — meaning flows where users interact with an Anchor-hosted interface rendered inside a wallet — and by the end, you should have an implementation which can be re-purposed to work with any SEP-supporting Anchor.When you implement SEP-0024, users can tokenize their grocery-buying dollars, pesos, or naira, use them on the Stellar network and, when they're ready, redeem them for cash in hand or money in the bank — and they can do it all from the comfort of your app.Most Anchors offer fiat-backed assets, and SEP-24 is set up to allow them to handle various KYC and AML requirements. But SEP-24 allows for the deposit and withdraw of cryptocurrencies like BTC, ETH, and ERC20 tokens like USDT. If the financial landscape is a bunch of lakes, SEP-0024 is a series of rivers by which you move your currency canoe in and out of the Stellar lake.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/connect-to-anchors","title":"Interoperability Basics","contentLength":315}},{"pageContent":"Setup for Anchored AssetsSo how do we make use of SEP-0024 to allow deposits and withdrawals of anchored assets? First let’s boot up our project:View trustline boilerplate code on GitHubNext, let's think about our goals. What we’re trying to do is communicate with Anchors to get information about the assets they honor, and about the requirements and steps necessary to initiate a deposit or withdrawal on behalf of a user. When a user deposits with an Anchor — by sending dollars to their bank account via ACH, for example — the Anchor will credit their Stellar account with the equivalent amount of tokens. The user can then hold, transfer, or trade those tokens just like any other Stellar asset. When a user withdraws those tokens — generally by making a payment back to the Anchor's Stellar account — the Anchor redeems them for cash in hand or money in the bank. If you’re still a little lost it will all hopefully become clear as we get coding.This tutorial will consist of a few minor ./events/ updates and two new ./methods/. Let’s start with the updates first. We actually need to update the core wallet.ts component.Update Wallet Component​You can see from the // NEW and // UPDATE comments what we are adding and updating. Nothing worth noting here other than near the bottom two new @Prop’s.We’ll talk more about home domain’s and stellar.toml files in a moment, but take special note of these as they will play a critical roll in connecting tp the world outside of Stellar.Add Deposit and Withdraw Buttons​Next let’s add a couple buttons for deposit and withdraw to the ./events/render.tsx.This is the same as what we did in the previous tutorial except that we're adding two buttons.“Deposit Asset” and “Withdraw Asset” connect to the this.depositAsset and this.withdrawAsset methods respectively. We’ll create those methods momentarily.Before that though let’s make a change to the ./events/componentWillLoad.ts file.Update Components​Here, the only changes we're making are to include of the StellarTomlResolver from the stellar-sdk package and to set the values for this.homeDomain and this.toml.About stellar.toml Files​You know what, let’s just go ahead and cover stellar.toml files. A stellar.toml file is a static resource that organizations building on Stellar publish on their home domain at https://{homeDomain}/.well-known/stellar.toml. By linking their home domain to a Stellar account using a set_options operation, they create a verifiable connection from that account to the information published there. To find out everything you'd ever want to know about stellar.toml files, check out [SEP-1], which is the complete stellar.toml specification.Stellar.toml files contain all sorts of information about an organization, the assets they offer, and the integrations they support. Wallets can look at an account, find the home domain, and crawl a stellar.toml to find out pretty much everything they need to know about an Anchor, and that's exactly what the Stellar SDK StellarTomlResolver.resolve method does: it pulls in a stellar.toml and parses it.Let's look at some concrete examples: here’s StellarX.com’s stellar.toml file.And here's [AnchorUSD]'s3.You can see the data provided by these companies that identifies who they are, what they do, and what services they provide. In this tutorial, we’re interested in the [[CURRENCIES]] they issue as that’s what we’re trying to get ahold of. We’re also looking for the TRANSFER_SERVER keyword, which indicates that an Anchor supports SEP-24, and the WEB_AUTH_ENDPOINT, which allows a wallet to set up an authenticated user session. Any time you find these three fields, and you’ve found an Anchor you can interoperate with.Once we’ve found an Anchor that supports deposit and withdrawal, we can begin the process of connecting with them from our wallet. This tutorial builds on the testnet, so from we’ll be use an SDF testing anchor server located at testanchor.stellar.org You can view the TOML file for this entity here.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/connect-to-anchors/setup-for-anchored-assets","title":"Setup for Anchored Assets","contentLength":702}},{"pageContent":"Deposit Anchored AssetsCreate Deposit Method​Let’s create ./methods/depositAsset.ts.It’s a lot of code, but keep in mind this is everything we need to completely interoperate with financial infrastructure foreign to the Stellar ecosystem, which is a big ask and in ~130 lines of code. It’s a modern day miracle!Currency Code and Issuer Prompt​First things first install the missing axios package.We’ll skip the rest of the top import stuff as you’re well aware of what that is, and we’ve installed and walked through anything noteworthy here already.Only thing here we haven’t seen before is the prompt selection of the currency code and issuer we’d like to deposit. To get this, we send the this.setPrompt a final options array argument, in this case the values from this.toml.CURRENCIES. This will open the prompt with a select<>options input field rather than a text input field.That selection will come back as a string in the form of {code}:{issuer} so we split that by the : so we’ll have a nice tidy array of [{code}, {issuer}] to use later.Check Trustline​Once we’ve got the currency we’re dealing with we need to check if we have a trustline for that asset setup for our account. The anchor won’t be able to deposit their token into our account if we don’t have a trustline set for it first. So we get the balance from the this.account.state and then inspect the balances to see if that currency exists. If it doesn’t we trigger the this.trustAsset method with the arguments set to automatically add that trustline to our account.Get Info​Once our account is setup, it’s time to start asking the Anchor some questions about itself and the features it supports. We get at that info by calling a GET on the TRANSFER_SERVER/info url from the anchor’s TOML file. We won’t make use of any of this data right now, but this is where you'd find fee and feature information which to display in you UI for your wallet user to review.Create Authenticated User Session​This call is actually a part of SEP-0010, which allows us to verify ownership of a user's public key so the Anchor knows the deposit request is coming from a valid entity. You don’t want someone else issuing deposit requests on your account, so to prove you control the Stellar account request the deposit, you sign a dummy authentication transaction and send it to the Anchor's web auth server. The server responds with a JWT token, which will be used to verify all further API calls to the anchor.The endpoint for creating an authenticated user session is specified the WEB_AUTH_ENDPOINT on an Anchor's stellar.toml file. The first thing our wallet does is make a GET request with a public account param which will send back an unsigned Stellar transaction for that account that has an invalid sequence number, so it doesn't actually do anything when submitted to the network. In response you’ll sign that transaction on behalf of the user and POST it back. If the signature checks out, the success response will contain an Authorization Bearer header JWT which you’ll want to store and use for all future interactions with the Anchor.Initiate Deposit​This call is our first little bit of magic. Once we setup our multipart/form-data entry values we can POST them to the ${this.toml.TRANSFER_SERVER}/transactions/withdraw/interactive endpoint along with our auth Authorization Bearer auth token we acquired earlier. The response to this call will contain a special url that allows a user to interact directly with the Anchor to provide the data required for a deposit.In a moment we’ll open that url in an iframe, popup, or new tab. Once we’ve sent that request, there will be a pending transaction request we can inspect at the ${this.toml.TRANSFER_SERVER}/transactions route.Check Transaction Status​This request should return the deposit status for the request we just made.Once we’re certain we’ve got a \"status\": \"incomplete\", which is the correct response since we haven't served the user the URL that allows them to initiate a deposit, we know everything's working, so we can go back to the interactive.url route and open that to begin filling out the deposit requirements.Serve the Anchor Webapp​We’ll opt for a popup. When you first open that url, it’s likely the anchor will ask for some level of KYC data from the user: name, email, address, verification docs like bank statements, passport, or license, etc. The SDF demo server we're using — which is hooked up to the testnet — will ask for name and email.After passing that screen your user enters the amount of an asset they'd like to deposit on the next screen. If, for instance, a user enters $500, once that deposit clears — and on this demo it clears automatically — the Anchor will credit the user's wallet with 500 of the token less any fees. In our case, the user ends up with 498.95: 1.05 is taken out in fees for a $500 deposit.If popups are disabled, we should kill the loader and show that error in the UI.Check Deposit Status​SEP-0024 allows specifies two methods for further communication between the anchor window and the wallet: a POST JSON for when you have a server, message and postMessage for when you have a client-side service. We don’t have a server, so we opt for the urlBuilder.searchParams.set('callback', 'postMessage'). With that set, we can setup a window 'message' event listener which will fire whenever the anchor popup window sends a postMessage to our popup window. From there we just listen to the popup message until transaction.status equals 'completed'. At that point our deposit has succeeded, and we can this.updateAccount() and kill the loader. If the transaction is still in a pending status we’ll wait 1 second before reloading the anchor popup window and checking again.If at any point during this flow there’s an error we should catch that, kill the loader, and display the error to the user.Whew! *wipes sweat from brow then hands on sleeves Nice work! “Just like that” we’ve deposited an anchored asset into our wallet! We can now make payments with that asset to anyone else who has a trustline enabled for this asset.","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/connect-to-anchors/deposit-anchored-assets","title":"Deposit Anchored Assets","contentLength":1113}},{"pageContent":"Withdraw Anchored AssetsIn a live situation, this is the step when a user takes a Stellar-based token and redeems it with an Anchor for the underlying asset it represents. It's how they'd move money off the network and back into their bank account, for instance.Create Withdraw Method​To start, create ./methods/withdrawAsset.ts and pop this in.We’ll actually skip everything except the stuff that is significantly different than the deposit flow. The main difference between the two is who submits the Stellar transaction: in the deposit flow the anchor is sends the wallet a Stellar asset; in the withdraw flow the wallet sends the asset to the anchor. So for the withdraw flow, we’ll need to build and submit a payment transaction.Create and Submit Payment Transaction​First thing we’ll see is the use of a Promise. This allows us to respond to any errors in the transaction we’re about to build and submit. Inside the promise we have three if statement blocks. The first if statement is a response to a status of success, which is where we'll end up once the withdraw has registered and everything is hunky dory.Otherwise if the transaction status is pending_user_transfer_start and we haven’t yet submitted a transaction to the Anchor, we attempt that. We load up the user's account to get the next valid sequence number, and build a Stellar transaction consisting of a payment operation with all the details from the transaction object that the anchor is expecting. Once we have a valid transaction built, we’ll sign it with the keypair, submit the transaction to the network, and wait for a response. If the transaction is successful, we save that value to submittedTxn and reload the anchor popup to observe the pending status. Make sure to set the submittedTxn to a truthy value or else you run the risk of submitting the transaction multiple times, as the anchor may take a moment to realize you’ve successfully submitted a transaction to them.The last if block is that if all else fails just keep reloading the anchor popup every second until we get a 'completed' status.Finally catch and respond to any errors.With this method saved and the server reloaded we have a fully functional SEP-0024 compliant wallet! Noice!View this code on GitHub","metadata":{"source":"https://developers.stellar.org/docs/building-apps/example-application-tutorial/connect-to-anchors/withdraw-anchored-assets","title":"Withdraw Anchored Assets","contentLength":398}},{"pageContent":"PrerequisitesYou can install Stellar Core a number of different ways, and once you do, you can configure it to participate in the network on a several different levels: it can be either a Basic Validator or a Full Validator. No matter how you install Stellar Core or what kind of node you run, however, you need to set up to connect to the peer-to-peer network and store the state of the ledger in a SQL database.Compute Requirements​We recently asked Stellar Core operators about their setups, and should have some updated information soon based on their responses. So stay tuned. In early 2018, Stellar Core with PostgreSQL running on the same machine worked well on a m5.large in AWS (dual core 2.5 GHz Intel Xeon, 8 GB RAM). Storage-wise, 20 GB was enough in 2018, but the ledger has grown a lot since then, and most people seem to have at least 1TB on hand.If you decide to run Stellar Core on the same machine as Horizon (though note that this is a deprecated architecture, since Horizon now bundles Core for its needs), you will additionally need to ensure that your setup is also equipped to handle Horizon's compute requirements as well.Stellar Core is designed to run on relatively modest hardware so that a whole range of individuals and organizations can participate in the network, and basic nodes should be able to function pretty well without tremendous overhead. That said, the more you ask of your node, the greater the requirements.Network access​Stellar Core interacts with the peer-to-peer network to keep a distributed ledger in sync, which means that your node needs to make certain TCP ports available for inbound and outbound communication.Inbound: a Stellar Core node needs to allow all IPs to connect to its PEER_PORT over TCP. You can specify a port when you configure Stellar Core, but most people use the default, which is 11625.Outbound: a Stellar Core needs to connect to other nodes via their PEER_PORTs TCP. You can find information about other nodes' PEER_PORTs on a network explorer like Stellarbeat, but most use the default port, which is, again, 11625.Internal System Access​Stellar Core also needs to connect to certain internal systems, though exactly how varies based on your setup.Outbound:Stellar Core requires access to a PostgreSQL database. If that database resides on a different machine on your network, you'll need to allow that connection. You specify the database when you configure Stellar Core.You can block all other connections.Inbound: Stellar Core exposes an unauthenticated HTTP endpoint on its HTTP_PORT. You can specify a port when you configure Stellar Core, but most people use the default, which is 11626.The HTTP_PORT is used by Horizon to submit transactions, so may have to be exposed to the rest of your internal IPsIt's also used to query Stellar Core info and provide metricsAnd to perform administrative commands such as scheduling upgrades and changing log levelsFor more on that, see commandsNote: if you need to expose your HTTP endpoint to other hosts in your local network, we recommended using an intermediate reverse proxy server to implement authentication. Don't expose the HTTP endpoint to the raw and cruel open internet.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/prerequisites","title":"Prerequisites","contentLength":551}},{"pageContent":"InstallingThere are three ways to install Stellar Core: you can use a Docker image, use pre-built packages, or build from source. Using a Docker image is the quickest and easiest method, so it's a good choice for a lot of developers, but if you're running Stellar Core in production you may need to use packages or, if you want to sacrifice convenience for maximum control, build from source. Whichever method you use, you should make sure to install the latest release since releases are cumulative and backwards compatible.Docker-based installation​Development environments​SDF maintains a quickstart image that bundles Stellar Core with Horizon and postgreSQL databases. It's a quick way to set up a default, non-validating, ephemeral configuration that should work for most developers.In addition to SDF images, Satoshipay maintains separate Docker images for Stellar Core and Horizon. The Satoshipay Stellar Core Docker image comes in a few flavors, including one with the AWS CLI installed and one with the Google Cloud SDK installed. The Horizon image supports all Horizon environment variables.Production environments​The SDF also maintains a Stellar-Core-only standalone image.Example usage:To run daemon you need to provide a configuration file:The image utilizes deb packages so it's possible to confirm checksum of the stellar-core binary in the docker image matches that in the cryptographically signed deb package. See packages documentation for information on installing Ubuntu packages. To calculate checksum in the docker image you can run:Package-based Installation​If you are using Ubuntu 18.04 LTS or later, we provide the latest stable releases of stellar-core and stellar-horizon in Debian binary package format.You may choose to install these packages individually, which offers the greatest flexibility but requires manual creation of the relevant configuration files and configuration of a PostgreSQL database.Most people, however, choose to install the stellar-quickstart package which configures a Testnet stellar-core and stellar-horizon both backed by a local PostgreSQL database. Once installed you can easily modify either the Stellar Core configuration if you want to connect to the public network.Installing from source​See the install from source for build instructions.Release version​In general you should install the latest release build. Builds are backward compatible and are cumulative.The version number scheme that we follow is protocol_version.release_number.patch_number where:protocol_version is the maximum protocol version supported by that release (all versions are 100% backward compatible), release_number is bumped when a set of new features or bug fixes not impacting the protocol are included in the release, patch_number is used when a critical fix has to be deployed.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/installation","title":"Installing","contentLength":444}},{"pageContent":"ConfiguringAfter you've installed Stellar Core, your next step is to complete a configuration file that specifies crucial things about your node — like whether it connects to the testnet or the public network, what database it writes to, and which other nodes are in its quorum set. You do that using TOML, and by default Stellar Core loads that file from ./stellar-core.cfg. You can specify a different file to load using the command line:$ stellar-core --conf betterfile.cfg <COMMAND>This section of the docs will walk you through the key fields you'll need to include in your config file to get your node up and runninig.Example Configurations​This doc works best in conjunction with concrete config examples, so as you read through it, you may want to check out the following:The complete example config documents all possible configuration elements, as well as their default values. It's got every knob you can twiddle and every setting you can tweak along wiith detailed explanations of how to twiddle and tweak them. You don't need to put everything from the complete example config into your config file — fields you omit will assume the default setting, and the default setting will generally serve you well — but there are a few required fields, and this doc will explain what they are.If you want to connect to the testnet, check out the example test network config. As you can see, most of the fields from the complete example config are omitted since the default settings work fine. You can easily tailor this config to meet your testnet needs.If you want to connect to the public network, check out this public network config for a Full Validator. It includes a properly crafted quorum set with all the current Tier 1 validators, which is a good place to start for most configurations. This node is set up to both validate and write history to a public archive, but you can disable either feature by adjusting this config so it's a little lighter.Database​Stellar Core stores two copies of the ledger: one in a SQL database and one in XDR files on local disk called buckets. The database is consulted during consensus, and modified atomically when a transaction set is applied to the ledger. It's random access, fine-grained, and fast.While a SQLite database works with Stellar Core, we generally recommend using a separate PostgreSQL server. A Postgres database is the bread and butter of Stellar Core.You specify your node's database in the aptly named DATABASE field of your config file, which you can can read more about in the complete example config. It defaults to an in-memory database, but you can specify a path as per the example.If using Postgresql, We recommend you configure your local database to be accessed over a Unix domain socket as well as updating the below Postgresql configuration parameters:Buckets​Stellar-core also stores a duplicate copy of the ledger in the form of flat XDR files called \"buckets.\" These files are placed in a directory specified in the config file as BUCKET_DIR_PATH, which defaults to buckets. The bucket files are used for hashing and transmission of ledger differences to history archives.Buckets should be stored on a fast local disk with sufficient space to store several times the size of the current ledger.For the most part, the contents of both the database and buckets directories can be ignored as they are managed by Stellar Core. However, when running Stellar Core for the first time, you must initialize both with the following command:$ stellar-core new-dbThis command initializes the database and bucket directories, and then exits. You can also use this command if your DB gets corrupted and you want to restart it from scratch.Network Passphrase​Use the NETWORK_PASSPHRASE field to specify whether your node connects to the testnet or the public network. Your choices:NETWORK_PASSPHRASE=\"Test SDF Network ; September 2015\"NETWORK_PASSPHRASE=\"Public Global Stellar Network ; September 2015\"For more about the Network Passphrase and how it works, check out the encyclopedia entry.Validating​By default, Stellar Core isn't set up to validate. If you want your node to be a Basic Validator or a Full Validator, you need to configure it to do so, which means preparing it to take part in SCP and sign messages pledging that the network agrees to a particular transaction set.Configuring a node to participate in SCP and sign messages is a three step process:Create a keypair stellar-core gen-seedAdd NODE_SEED=\"SD7DN...\" to your configuration file, where SD7DN... is the secret key from the keypairAdd NODE_IS_VALIDATOR=true to your configuration fileIf you want other validators to add your node to their quorum sets, you should also share your public key (GDMTUTQ... ) by publishing a stellar.toml file on your homedomain following specs laid out in SEP-20.It's essential to store and safeguard your node's secret key: if someone else has access to it, they can send messages to the network and they will appear to originate from your node. Each node you run should have its own secret key.If you run more than one node, set the HOME_DOMAIN common to those nodes using the NODE_HOME_DOMAIN property. Doing so will allow your nodes to be grouped correctly during quorum set generation.Choosing Your Quorum Set​No matter what kind of node you run — Basic Validator, Full Validator, or Archiver — you need to select a quorum set, which consists of validators (grouped by organization) that your node checks with to determine whether to apply a transaction set to a ledger. If you want to know more about how quorum sets work, check this article about how Stellar approaches quorums. If you want to see what a quorum set consisting of all the Tier 1 validators looks like — a tried and true setup — check out the public network config for a Full ValidatorA good quorum set:aligns with your organization’s prioritieshas enough redundancy to handle arbitrary node failuresmaintains good quorum intersectionSince crafting a good quorum set is a difficult thing to do, stellar core automatically generates a quorum set for you based on structured information you provide in your config file. You choose the validators you want to trust; stellar core configures them into an optimal quorum set.To generate a quorum set, stellar core:Groups validators run by the same organization into a subquorumSets the threshold for each of those subquorumsGives weights to those subquorums based on qualityWhile this does not absolve you of all responsibility — you still need to pick trustworthy validators and keep an eye on them to ensure that they’re consistent and reliable — it does make your life easier and reduces the chances for human error.Validator discovery​When you add a validating node to your quorum set, it’s generally because you trust the organization running the node: you trust SDF, not some anonymous Stellar public key.In order to create a self-verified link between a node and the organization that runs it, a validator declares a home domain on-chain using a set_options operation, and publishes organizational information in a stellar.toml file hosted on that domain. To find out how that works, take a look at SEP-20.As a result of that link, you can look up a node by its Stellar public key and check the stellar.toml to find out who runs it. It’s possible to do that manually, but you can also just consult the list of nodes on Stellarbeat.io. If you decide to trust an organization, you can use that list to collect the information necessary to add their nodes to your configuration.When you look at that list, you will discover that the most reliable organizations actually run more than one validator, and adding all of an organization’s nodes to your quorum set creates the redundancy necessary to sustain arbitrary node failure. When an organization with a trio of nodes takes one down for maintenance, for instance, the remaining two vote on the organization’s behalf, and the organization’s network presence persists.One important thing to note: you need to either depend on exactly one entity OR have at least 4 entities for automatic quorum set configuration to work properly. At least 4 is the better option.Home domains array​To create your quorum set, Stellar Core relies on two arrays of tables: [[HOME_DOMAINS]] and [[VALIDATORS]]. Check out the example config to see those arrays in action.[[HOME_DOMAINS]] defines a superset of validators: when you add nodes hosted by the same organization to your configuration, they share a home domain, and the information in the [[HOME_DOMAINS]] table, specifically the quality rating, will automatically apply to every one of those validators.For each organization you want to add, create a separate [[HOME_DOMAINS]] table, and complete the following required fields:FieldRequirementsDescriptionHOME_DOMAINstringURL of home domain linked to a group of validatorsQUALITYstringRating for organization's nodes: HIGH, MEDIUM, or LOWHere’s an example:Validators array​For each node you would like to add to your quorum set, complete a [[VALIDATORS]] table with the following fields:FieldRequirementsDescriptionNAMEstringA unique alias for the nodeQUALITYstringRating for node (required unless specified in [[HOME_DOMAINS]]): HIGH, MEDIUM, or LOW.HOME_DOMAINstringURL of home domain linked to validatorPUBLIC_KEYstringStellar public key associated with validatorADDRESSstringPeer:port associated with validator (optional)HISTORYstringarchive GET command associated with validator (optional)If the node's HOME_DOMAIN aligns with an organization defined in the [[HOME_DOMAINS]] array, the quality rating specified there will apply to the node. If you’re adding an individual node that is not covered in that array, you’ll need to specify the QUALITY here.Here’s an example:Validator quality​QUALITY is a required field for each node you add to your quorum set. Whether you specify it for a suite of nodes in [[HOME_DOMAINS]] or for a single node in [[VALIDATORS]], it means the same thing, and you have the same three rating options: HIGH, MEDIUM, or LOW.HIGH quality validators are given the most weight in automatic quorum set configuration. Before assigning a high quality rating to a node, make sure it has low latency and good uptime, and that the organization running the node is reliable and trustworthy.A high quality validator:publishes an archivebelongs to a suite of nodes that provide redundancyChoosing redundant nodes is good practice. The archive requirement is programmatically enforced.MEDIUM quality validators are nested below high quality validators, and their combined weight is equivalent to a single high quality entity. If a node doesn't publish an archive, but you deem it reliable or have an organizational interest in including in your quorum set, give it a medium quality rating.LOW quality validators are nested below medium quality validators, and their combined weight is equivalent to a single medium quality entity. Should they prove reliable over time, you can upgrade their rating to medium to give them a bigger role in your quorum set configuration.Automatic quorum set generation​Once you add validators to your configuration, stellar core automatically generates a quorum set using the following rules:Validators with the same home domain are automatically grouped together and given a threshold requiring a simple majority (2f+1)Heterogeneous groups of validators are given a threshold assuming byzantine failure (3f+1)Entities are grouped by QUALITY and nested from HIGH to LOWHIGH quality entities are at the top, and are given decision-making priorityThe combined weight of MEDIUM quality entities equals a single HIGH quality entityThe combined weight of LOW quality entities equals a single MEDIUM quality entityQuorum and Overlay Network​It is generally a good idea to give information to your validator on other validators that you rely on. This is achieved by configuring KNOWN_PEERS and PREFERRED_PEERS with the addresses of your dependencies.Additionally, configuring PREFERRED_PEER_KEYS with the keys from your quorum set might be a good idea to give priority to the nodes that allow you to reach consensus.Without those settings, your validator depends on other nodes on the network to forward you the right messages, which is typically done as a best effort.Updating and Coordinating Your Quorum Set​When you join the ranks of node operators, it's also important to join the conversation. The best way to do that: get on the #validators channel on the Stellar Keybase and sign up for the Stellar Validators Google Group; You can also join the #validators channel on our Developer Discord. That way, you can and coordinate changes with the rest of the network.When you need to make changes to your validator or to your quorum set — say you take a validator down for maintenance or add new validators to your node's quorum set — it's crucial to stage the changes to preserve quorum intersection and general good health of the network:Don't remove too many nodes from your quorum set before the nodes are taken down. If different validators remove different sets, the remaining sets may not overlap, which could cause network splitsDon't add too many nodes in your quorum set at the same time. If not done carefully, the new nodes could overpower your configurationWhen you want to add or remove nodes, start by making changes to your own nodes' quorum sets, and then coordinate work with others to reflect those changes gradually.History​Stellar Core normally interacts with one or more history archive, which are configurable facilities where Full Validators and Archivers store flat files containing history checkpoints: bucket files and history logs. History archives are usually off-site commodity storage services such as Amazon S3, Google Cloud Storage, Azure Blob Storage, or custom SCP/SFTP/HTTP servers. To find out how to publish a history archive, consult Publishing History Archives.No matter what kind of node you're running, you should configure it to get history from one or more public archives. You can configure any number of archives to download from: Stellar Core will automatically round-robin between them.When you're choosing your quorum set, you should include high-quality nodes — which, by defintion, publish archives — and add the location for each node's archive in the HISTORY field in the validators array.You can also use command templates in the config file to specify additional archives you'd like to use and how to access them. The example config shows how to configure a history archive through command templates.Note: if you notice a lot of errors related to downloading archives, you should check that all archives in your configuration are up to date.Automatic Maintenance​Some tables in Stellar Core's database act as a publishing queue for external systems such as Horizon and generate meta data for changes happening to the distributed ledger.If not managed properly those tables will grow without bounds. To avoid this, a built-in scheduler will delete data from old ledgers that are not used anymore by other parts of the system (external systems included).The settings that control the automatic maintenance behavior are: AUTOMATIC_MAINTENANCE_PERIOD, AUTOMATIC_MAINTENANCE_COUNT and KNOWN_CURSORS.By default, Stellar Core will perform this automatic maintenance, so be sure to disable it until you have done the appropriate data ingestion in downstream systems (Horizon for example sometimes needs to reingest data).If you need to regenerate the metadata, the simplest way is to replay ledgers for the range you're interested in after (optionally) clearing the database with newdb.Metadata Snapshots and Restoration​Some deployments of Stellar Core and Horizon will want to retain metadata for the entire history of the network. This metadata can be quite large and computationally expensive to regenerate anew by replaying ledgers in stellar-core from an empty initial database state, as described in the previous section.This can be especially costly if run more than once. For instance, when bringing a new node online. Or even if running a single node with Horizon, having already ingested the metadata once: a subsequent version of Horizon may have a schema change that entails re-ingesting it again.Some operators therefore prefer to shut down their stellar-core (and/or Horizon) processes and take filesystem-level snapshots or database-level dumps of the contents of Stellar Core's database and bucket directory, and/or Horizon's database, after metadata generation has occurred the first time. Such snapshots can then be restored, putting stellar-core and/or Horizon in a state containing metadata without performing full replay.Any reasonably recent state will do — if such a snapshot is a little old, stellar-core will replay ledgers from whenever the snapshot was taken to the current network state anyways — but this procedure can greatly accelerate restoring validator nodes, or cloning them to create new ones.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/configuring","title":"Configuring","contentLength":2808}},{"pageContent":"Publishing History ArchivesIf you want to run a Full Validator or an Archiver, you need to set up your node to publish a history archive. You can host an archive using a blob store such as Amazon's S3 or Digital Ocean's spaces, or you can simply serve a local archive directly via an HTTP server such as Nginx or Apache. If you're setting up a Basic Validator, you can skip this section. No matter what kind of node you're planning to run, make sure to set it up to get history, which is covered in Configuration.Caching and History Archives​You can significantly reduce the data transfer costs associated with running a public History archive by using common caching techniques or a CDN.Three simple rules apply to caching the History archives:Do not cache the archive state file .well-known/stellar-history.json (\"Cache-Control: no-cache\")Do not cache HTTP 4xx responses (\"Cache-Control: no-cache\")Cache everything else for as long as possible (> 1 day)Local History Archive Using nginx​To publish a local history archive using nginx:Add a history configuration stanza to your /etc/stellar/stellar-core.cfg:Run new-hist to create the local archive# sudo -u stellar stellar-core --conf /etc/stellar/stellar-core.cfg new-hist localThis command creates the history archive structure:Configure a virtual host to serve the local archive (Nginx)Amazon S3 History Archive​To publish a history archive using Amazon S3:Add a history configuration stanza to your /etc/stellar/stellar-core.cfg:Run new-hist to create the s3 archive# sudo -u stellar stellar-core --conf /etc/stellar/stellar-core.cfg new-hist s3Serve the archive using an Amazon S3 static siteOptionally place a reverse proxy and CDN in front of the S3 static siteBackfilling a history archive​Given the choice, it's best to configure your history archive prior to your node's initial synch to the network. That way your validator's history publishes as you join/synch to the network.However, if you have not published an archive during the node's initial synch, it's still possible to use the stellar-archivist command line tool to mirror, scan, and repair existing archives.Using the SDF package repositories you can install stellar-archivist by running apt-get install stellar-archivistThe steps required to create a History archive for an existing validator — in other words, to upgrade a Basic Validator to a Full Validator — are straightforward:Stop your stellar-core instance (systemctl stop stellar-core)Configure a history archive for the new nodeRun new-hist to create the local archive# sudo -u stellar stellar-core --conf /etc/stellar/stellar-core.cfg new-hist localThis command creates the History archive structure:Start your Stellar Core instance (systemctl start stellar-core)Allow your node to join the network and watch it start publishing a few checkpoints to the newly created archiveAt this stage your validator is successfully publishing its history, which enables other users to join the network using your archive (although it won't allow them to CATCHUP_COMPLETE=true as the archive only has partial network history).Complete History Archive​If you decide to publish a complete archive — which enables other users to join the network from the genesis ledger — it's also possible to use stellar-archivist to add all missing history data to your partial archive, and to verify the state and integrity of your archive. For example:As you can tell from the output of the scan command, some history, ledger, transactions, and results are missing from the local history archive.You can repair the missing data using stellar-archivist's repair command combined with a known full archive — such as the SDF public history archive:# stellar-archivist repair http://history.stellar.org/prd/core-testnet/core_testnet_001/ file:///mnt/xvdf/stellar-core-archive/node_001/A final scan of the local archive confirms that it has been successfully repaired# stellar-archivist scan file:///mnt/xvdf/stellar-core-archive/node_001Start your stellar-core instance (systemctl start stellar-core), and you should have a complete history archive being written to by your full validator.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/publishing-history-archives","title":"Publishing History Archives","contentLength":692}},{"pageContent":"RunningStarting Stellar Core​Once you've set up your environment, configured your node, set up your quorum set, and selected archives to get history from, you're ready to start Stellar Core.Use a command equivalent to:$ stellar-core runAt this point, you're ready to observe your node's activity as it joins the network.You may want to skip ahead and review the logging section to familiarize yourself with Stellar Core's output.Interacting With Your Instance​When your node is running, you can interact with Stellar Core via an administrative HTTP endpoint. Commands can be submitted using command-line HTTP tools such as curl, or by running a command such as$ stellar-core http-command <http-command>That HTTP endpoint is not intended to be exposed to the public internet. It's typically accessed by administrators, or by a mid-tier application to submit transactions to the Stellar network.See commands for a description of the available commands.Joining the Network​Your node will go through the following phases as it joins the network:Establishing Connection to Other Peers.​You should see authenticated_count increase.Observing Consensus​Until the node sees a quorum, it will say:After observing consensus, a new field quorum will display information about network decisions. At this point the node will switch to \"Catching up\":Catching up​This is a phase where the node downloads data from archives. The state will start with something like:And then go through the various phases of downloading and applying state such asYou can specify how far back your node goes to catch up in your config file. If you setCATCHUP_COMPLETE to true, your node will replay the entire history of the network, which can take a long time. Weeks. Satoshipay offers a parallel catchup script to speed up the process, but you only need to replay the complete network history if you're setting up a Full Validator. Otherwise, you can specify a starting point for catchup using CATCHUP_RECENT. See the complete example configuration for more details.Synced​When the node is done catching up, its state will change to:Logging​Stellar Core sends logs to standard output and stellar-core.log by default, configurable as LOG_FILE_PATH.Log messages are classified by progressive priority levels:TRACE, DEBUG, INFO, WARNING, ERROR and FATAL. The logging system only emits those messages at or above its configured logging level.The log level can be controlled by configuration, the -ll command-line flag, or adjusted dynamically by administrative (HTTP) commands. To do so, run:$ stellar-core http-command \"ll?level=debug\"while your system is running.Log levels can also be adjusted on a partition-by-partition basis through the administrative interface. For example the history system can be set to DEBUG-level logging by running:$ stellar-core http-command \"ll?level=debug&partition=history\"Against a running system.The default log level is INFO, which is moderately verbose and should emit progress messages every few seconds under normal operation.Validator maintenance​Maintenance here refers to anything involving taking your validator temporarily out of the network (to apply security patches, system upgrade, etc).As an administrator of a validator, you must ensure that the maintenance you are about to apply to the validator is safe for the overall network and for your validator.Safe means that the other validators that depend on yours will not be affected too much when you turn off your validator for maintenance and that your validator will continue to operate as part of the network when it comes back up.If you are changing some settings that may impact network wide settings such as protocol version, review the section on network configuration.If you're changing your quorum set configuration, also read the section on what to do.Recommended steps to perform as part of a maintenance​We recommend performing the following steps in order (repeat sequentially as needed if you run multiple nodes).Advertise your intention to others that may depend on you. Some coordination is required to avoid situations where too many nodes go down at the same time.Dependencies should assess the health of their quorum, refer to the section \"Understanding quorum and reliability\".If there is no objection, take your instance downWhen done, start your instance that should rejoin the networkThe instance will be completely caught up when it's both Synced and there is no backlog in uploading history.Special considerations during quorum set updates​Sometimes an organization needs to make changes that impact other's quorum sets:taking a validator down for long period of timeadding new validators to their poolIn both cases, it's crucial to stage the changes to preserve quorum intersection and general good health of the network:removing too many nodes from your quorum set before the nodes are taken down : if different people remove different sets the remaining sets may not overlap between nodes and may cause network splitsadding too many nodes in your quorum set at the same time : if not done carefully can cause those nodes to overpower your configurationRecommended steps are for the entity that adds/removes nodes to do so first between their own nodes, and then have people reflect those changes gradually (over several rounds) in their quorum configuration.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/running-node","title":"Running","contentLength":879}},{"pageContent":"MonitoringOnce your node is up and running, it's important to keep an eye on it to make sure it stays afloat and continues to contribute to the health of the overall network. To help with that, Stellar Core exposes vital information that you can use to monitor your node and diagnose potential problems.You can access this information using commands and inspecting Stellar Core's output, which is what the first half of this doc covers. You can also connect Prometheus to make monitoring easier, combine it with Alertmanager to automate notification, and use pre-built Grafana dashboards to create visual representations of your node's well-being.However you decide to monitor, the most important thing is that you have a system in place to ensure that your integration keeps ticking.General Node Information​If you run $ stellar-core http-command 'info', the output will look something like this:Some notable fields in info are:build: the build number for this Stellar Core instanceledger: the local state of your node, which may be different from the network state if your node was disconnected from the network. Some important sub-fields:age: time elapsed since this ledger closed (during normal operation less than 10 seconds)num: ledger numberversion: protocol version supported by this ledgernetwork is the network passphrase that this core instance is using to decide whether to connect to the testnet or the public networkpeers: information on the connectivity to the networkauthenticated_count: the number of live connectionspending_count: the number of connections that are not fully established yetprotocol_version: the maximum version of the protocol that this instance recognizesstate: the node's synchronization status relative to the networkquorum: summarizes the state of the SCP protocol participants, the same as the information returned by the quorum command (see below).Overlay information​The peers command returns information on the peers your node is connected to.This list is the result of both inbound connections from other peers and outbound connections from this node to other peers.$ stellar-core http-command 'peers'Quorum Health​To help node operators monitor their quorum sets and maintain the health of the overall network, Stellar Core also provides metrics on other nodes in your quorum set. You should monitor them to make sure they're up and running, and that your quorum set is maintaining good overlap with the rest of the network.Quorum set diagnostics​The quorum command allows to diagnose problems with the quorum set of the local node.If you run:$ stellar-core http-command 'quorum'The output will look something like:This output has two main sections: qset and transitive. The former describes the node and its quorum set; the latter describes the transitive closure of the node's quorum set.Per-node Quorum-set Information​Entries to watch for in the qset section — which describe the node and its quorum set — are:agree : the number of nodes in the quorum set that agree with this instance.delayed : the nodes that are participating in consensus but seem to be behind.disagree: the nodes that are participating but disagreed with this instance.fail_at : the number of failed nodes that would cause this instance to halt.fail_with: an example of such potential failure.missing : the nodes that were missing during this consensus round.value : the quorum set used by this node (t is the threshold expressed as a number of nodes).In the example above, 6 nodes are functioning properly, one is down (stronghold1), and the instance will fail if any two nodes still working (or one node and one inner-quorum-set) fail as well.If a node is stuck in state Joining SCP, this command allows to quickly find the reason:too many validators missing (down or without a good connectivity), solutions are:adjust your quorum set based on the nodes that are not missingtry to get a better connectivity path to the missing validatorsnetwork split would cause SCP to stick because of nodes that disagree. This would happen if either there is a bug in SCP, the network does not have quorum intersection, or the disagreeing nodes are misbehaving (compromised, etc).Note that the node not being able to reach consensus does not mean that the network as a whole will not be able to reach consensus (and the opposite is true: the network may fail because of a different set of validators failing).You can get a sense of the quorum set health of a different node using using: $ stellar-core http-command 'quorum?node=$sdf1 or $ stellar-core http-command 'quorum?node=@GABCDEOverall network health can be evaluated by walking through all nodes and looking at their health. Note that this is only an approximation, as remote nodes may not have received the same messages (in particular: missing for other nodes is not reliable).Transitive Closure Summary Information​When showing quorum-set information about the local node, a summary of the transitive closure of the quorum set is also provided in the transitive field. This has several important sub-fields:last_check_ledger : the last ledger in which the transitive closure was checked for quorum intersection. This will reset when the node boots and whenever a node in the transitive quorum changes its quorum set. It may lag behind the last-closed ledger by a few ledgers depending on the computational cost of checking quorum intersection.node_count : the number of nodes in the transitive closure, which are considered when calculating quorum intersection.intersection : whether or not the transitive closure enjoyed quorum intersection at the most recent check. This is of utmost importance in preventing network splits. It should always be true. If it is ever false, one or more nodes in the transitive closure of the quorum set is currently misconfigured, and the network is at risk of splitting. Corrective action should be taken immediately, for which two additional sub-fields will be present to help suggest remedies:last_good_ledger : this will note the last ledger for which the intersection field was evaluated as true; if some node reconfigured at or around that ledger, reverting that configuration change is the easiest corrective action to take.potential_split : this will contain a pair of lists of validator IDs, which is a potential pair of disjoint quorums allowed by the current configuration. In other words, a possible split in consensus allowed by the current configuration. This may help narrow down the cause of the misconfiguration: likely it involves too-low a consensus threshold in one of the two potential quorums, and/or the absence of a mandatory trust relationship that would bridge the two.critical: an \"advance warning\" field that lists nodes that could cause the network to fail to enjoy quorum intersection, if they were misconfigured sufficiently badly. In a healthy transitive network configuration, this field will be null. If it is non-null then the network is essentially \"one misconfiguration\" (of the quorum sets of the listed nodes) away from no longer enjoying quorum intersection, and again, corrective action should be taken: careful adjustment to the quorum sets of nodes that depend on the listed nodes, typically to strengthen quorums that depend on them.Detailed transitive quorum analysis​The quorum endpoint can also retrieve detailed information for the transitive quorum.This is a format that's easier to process than what scp returns as it doesn't contain all SCP messages.$ stellar-core http-command 'quorum?transitive=true'The output looks something like:The output begins with the same summary information as in the transitive block of the non-transitive query (if queried for the local node), but also includes a nodes array that represents a walk of the transitive quorum centered on the query node.Fields are:node : the identity of the validatordistance : how far that node is from the root node (ie. how many quorum set hops)heard : the latest ledger sequence number that this node voted onqset : the node's quorum setstatus : one of behind|tracking|ahead (compared to the root node) or missing|unknown (when there are no recent SCP messages for that node)value_id : a unique ID for what the node is voting for (allows to quickly tell if nodes are voting for the same thing)value : what the node is voting forUsing Prometheus​Monitoring stellar-core using Prometheus is by far the simplest solution, especially if you already have a Prometheus server within your infrastructure. Prometheus is a free and open source time-series database with a simple yet incredibly powerful query language PromQL. Prometheus is also tightly integrated with Grafana, so you can render complex visualisations with ease.In order for Prometheus to scrape stellar-core application metrics, you will need to install the stellar-core-prometheus-exporter (apt-get install stellar-core-prometheus-exporter) and configure your Prometheus server to scrape this exporter (default port: 9473). On top of that grafana can be used to visualize metrics.Install a Prometheus server within your infrastructure​Installing and configuring a Prometheus server is out of scope of this document, however it is a fairly simple process: Prometheus is a single Go binary which you can download from https://prometheus.io/docs/prometheus/latest/installation/.Install the stellar-core-prometheus-exporter​The stellar-core-prometheus-exporter is an exporter that scrapes the stellar-core metrics endpoint (http://localhost:11626/metrics) and renders these metrics in the Prometheus text-based format available for Prometheus to scrape and store in its time series database.The exporter needs to be installed on every Stellar Core node you wish to monitor.apt-get install stellar-core-prometheus-exporterYou will need to open up port 9473 between your Prometheus server and all your Stellar Core nodes for your Prometheus server to be able to scrape metrics.Point Prometheus to stellar-core-prometheus-exporter​Pointing your Prometheus instance to the exporter can be achieved by manually configuring a scrape job; however, depending on the number of hosts you need to monitor this can quickly become unwieldy. Luckily, the process can also be automated using Prometheus' various \"service discovery\" plugins. For example with AWS hosted instance you can use the ec2_sd_config plugin.Manual​Using Service Discovery (EC2)​Create Alerting Rules​Once Prometheus scrapes metrics we can add alerting rules. Recommended rules are here (require Prometheus 2.0 or later). Copy rules to /etc/prometheus/stellar-core-alerting.rules on the Prometheus server and add the following to the prometheus configuration file to include the file:Rules are documented in-line,and we strongly recommend that you review and verify all of them as every environment is different.Configure Notifications Using Alertmanager​Alertmanager is responsible for sending notifications. Installing and configuring an Alertmanager server is out of scope of this document, however it is a fairly simple process. Official documentation is here.All recommended alerting rules have \"severity\" label:critical normally require immediate attention. They indicate an ongoing or very likely outage. We recommend that critical alerts notify administrators 24x7warning normally can wait until working hours. Warnings indicate problems that likely do not have production impact but may lead to critical alerts or outages if left unhandledThe following example alertmanager configuration demonstrates how to send notifications using different methods based on severity label:In the above examples alerts with severity \"critical\" are sent to pagerduty and warnings are sent to slack.Useful Exporters​You may find the below exporters useful for monitoring your infrastructure as they provide incredible insight into your operating system and database metrics. Installing and configuring these exporters is out of the scope of this document but should be relatively straightforward.node_exporter can be used to track all operating system metrics.postgresql_exporter can be used to monitor the local stellar-core database.Visualize metrics using Grafana​Once you've configured Prometheus to scrape and store your stellar-core metrics, you will want a nice way to render this data for human consumption. Grafana offers the simplest and most effective way to achieve this. Installing Grafana is out of scope of this document but is a very simple process, especially when using the prebuilt apt packagesWe recommend that administrators import the following two dashboards into their grafana deployments:Stellar Core Monitoring - shows the most important metrics, node status and tries to surface common problems. It's a good troubleshooting starting pointStellar Core Full - shows a simple health summary as well as all metrics exposed by the stellar-core-prometheus-exporter. It's much more detailed than the Stellar Core Monitoring and might be useful during in-depth troubleshooting","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/monitoring","title":"Monitoring","contentLength":2083}},{"pageContent":"CommandsStellar Core can be controlled via the following commands.Common options​Common options can be placed at any place in the command line.--conf <FILE-NAME>: Specify a config file to use. You can use '-' and provide the config file via STDIN. default 'stellar-core.cfg'--ll <LEVEL>: Set the log level. It is redundant with http-command ll but we need this form if you want to change the log level during test runs.--metric <METRIC-NAME>: Report metric METRIC on exit. Used for gathering a metric cumulatively during a test run.--help: Show help message for given command.Command line options​Command options can only by placed after command.catchup <DESTINATION-LEDGER/LEDGER-COUNT>: Perform catchup from history archives without connecting to network. For new instances (with empty history tables - only ledger 1 present in the database) it will respect LEDGER-COUNT configuration and it will perform bucket application on such a checkpoint that at least LEDGER-COUNT entries are present in history table afterwards. For instances that already have some history entries, all ledgers since last closed ledger will be replayed.check-quorum: Check quorum intersection from history to ensure there is closure over all the validators in the network.convert-id <ID>: Will output the passed ID in all known forms and then exit. Useful for determining the public key that corresponds to a given private key. For example:$ stellar-core convert-id SDQVDISRYN2JXBS7ICL7QJAEKB3HWBJFP2QECXG7GZICAHBK4UNJCWK2dump-xdr <FILE-NAME>: Dumps the given XDR file and then exits.force-scp: This command is used to start a network from scratch or when a network has lost quorum because of failed nodes or otherwise. It sets a flag in the database. The next time stellar-core is run, stellar-core will start emitting SCP messages based on its last known ledger. Without this flag stellar-core waits to hear a ledger close from the network before starting SCP. force-scp doesn't change the requirements for quorum so although this node will emit SCP messages SCP won't complete until there are also a quorum of other nodes also emitting SCP messages on this same ledger. Value of force-scp can be reset with --reset flag.fuzz <FILE-NAME>: Run a single fuzz input and exit.gen-fuzz <FILE-NAME>: Generate a random fuzzer input file.gen-seed: Generate and print a random public/private key and then exit.help: Print the available command line options and then exit..http-command <COMMAND> Send an HTTP command to an already running local instance of stellar-core and then exit. For example:$ stellar-core http-command infoinfer-quorum: Print a potential quorum set inferred from history.load-xdr <FILE-NAME>: Load an XDR bucket file, for testing.new-db: Clears the local database and resets it to the genesis ledger. If you connect to the network after that it will catch up from scratch.new-hist <HISTORY-LABEL> ...: Initialize the named history archives HISTORY-LABEL. HISTORY-LABEL should be one of the history archives you have specified in the stellar-core.cfg. This will write a .well-known/stellar-history.json file in the archive root.offline-info: Returns an output similar to --c info for an offline instanceprint-xdr <FILE-NAME>: Pretty-print a binary file containing an XDR object. If FILE-NAME is \"-\", the XDR object is read from standard input. Option --filetype [auto|ledgerheader|meta|result|resultpair|tx|txfee]** controls type used for printing (default: auto). Option --base64 alters the behavior to work on base64-encoded XDR rather than raw XDR.publish: Execute publish of all items remaining in publish queue without connecting to network. May not publish last checkpoint if last closed ledger is on checkpoint boundary.report-last-history-checkpoint: Download and report last history checkpoint from a history archive.run: Runs stellar-core service.sec-to-pub: Reads a secret key on standard input and outputs the corresponding public key. Both keys are in Stellar's standard base-32 ASCII format.sign-transaction <FILE-NAME>: Add a digital signature to a transaction envelope stored in binary format in <FILE-NAME>, and send the result to standard output (which should be redirected to a file or piped through a tool such as base64). The private signing key is read from standard input, unless <FILE-NAME> is \"-\" in which case the transaction envelope is read from standard input and the signing key is read from /dev/tty. In either event, if the signing key appears to be coming from a terminal, stellar-core disables echo. Note that if you do not have a STELLAR_NETWORK_ID environment variable, then before this argument you must specify the --netid option. For example, the production stellar network is \"Public Global Stellar Network ; September 2015\" while the test network is \"Test SDF Network ; September 2015\". Option --base64 alters the behavior to work on base64-encoded XDR rather than raw XDR.test: Run all the unit tests.Sub-options specific to stellar-core:--all-versions : run with all possible protocol versions--version <N> : run tests for protocol version N, can be specified multiple times (default latest)--base-instance <N> : run tests with instance numbers offset by N, used to run tests in parallelFor further info on possible options for test.For example this will run just the tests tagged with [tx] using protocol versions 9 and 10 and stop after the first failure: stellar-core test -a --version 9 --version 10 \"[tx]\"upgrade-db: Upgrades local database to current schema version. This is usually done automatically during stellar-core run or other command.version: Print version info and then exit.write-quorum: Print a quorum set graph from history.HTTP Commands​By default stellar-core listens for connections from localhost on port 11626. You can send commands to stellar-core via a web browser, curl, or using the --c command line option (see above). Most commands return their results in JSON format.bans List current active banscheckdb Triggers the instance to perform a background check of the database's state.checkpoint Triggers the instance to write an immediate history checkpoint. And uploads it to the archive.connect connect?peer=NAME&port=NNN Triggers the instance to connect to peer NAME at port NNN.dropcursor\\ dropcursor?id=ID Deletes the tracking cursor identified by id. See setcursor for more information.droppeer droppeer?node=NODE_ID[&ban=D] Drops peer identified by NODE_ID, when D is 1 the peer is also banned.info Returns information about the server in JSON format (sync state, connected peers, etc).ll\\ ll?level=L[&partition=P] Adjust the log level for partition P where P is one of Bucket, Database, Fs, Herder, History, Ledger, Overlay, Process, SCP, Tx (or all if no partition is specified). Level is one of FATAL, ERROR, WARNING, INFO, DEBUG, VERBOSE, TRACE.logrotate Rotate log files.maintenance maintenance?[queue=true] Performs maintenance tasks on the instance.queue performs deletion of queue data. See setcursor for more information.metrics Returns a snapshot of the metrics registry (for monitoring and debugging purpose).clearmetrics clearmetrics?[domain=DOMAIN] Clear metrics for a specified domain. If no domain specified, clear all metrics (for testing purposes).peers?[&fullkeys=true] Returns the list of known peers in JSON format. If fullkeys is set, outputs unshortened public keys.quorum quorum?[node=NODE_ID][&compact=true][&fullkeys=true][&transitive=true] Returns information about the quorum for NODE_ID (local node by default). If transitive is set, information is for the transitive quorum centered on NODE_ID, otherwise only for nodes in the quorum set of NODE_ID.NODE_ID is either a full key (GABCD...), an alias ($name) or an abbreviated ID (@GABCD).If compact is set, only returns a summary version.If fullkeys is set, outputs unshortened public keys.setcursor setcursor?id=ID&cursor=N Sets or creates a cursor identified by ID with value N. ID is an uppercase AlphaNum, N is an uint32 that represents the last ledger sequence number that the instance ID processed. Cursors are used by dependent services to tell stellar-core which data can be safely deleted by the instance. The data is historical data stored in the SQL tables such as txhistory or ledgerheaders. When all consumers processed the data for ledger sequence N the data can be safely removed by the instance. The actual deletion is performed by invoking the maintenance endpoint or on startup. See also dropcursor.getcursor getcursor?[id=ID] Gets the cursor identified by ID. If ID is not defined then all cursors will be returned.scp scp?[limit=n][&fullkeys=true] Returns a JSON object with the internal state of the SCP engine for the last n (default 2) ledgers. Outputs unshortened public keys if fullkeys is set.tx tx?blob=Base64 Submit a transaction to the network. blob is a base64 encoded XDR serialized 'TransactionEnvelope', and it returns a JSON object with the following properties status:\"PENDING\" - transaction is being considered by consensus\"DUPLICATE\" - transaction is already PENDING\"ERROR\" - transaction rejected by transaction engine error: set when status is \"ERROR\". Base64 encoded, XDR serialized 'TransactionResult'upgradesupgrades?mode=get Retrieves the currently configured upgrade settings.upgrades?mode=clear Clears any upgrade settings.upgrades?mode=set&upgradetime=DATETIME&[basefee=NUM]&[basereserve=NUM]&[maxtxsize=NUM]&[protocolversion=NUM]upgradetime is a required date (UTC) in the form 1970-01-01T00:00:00Z. It is the time the upgrade will be scheduled for. If it is in the past by less than 12 hours, the upgrade will occur immediately. If it's more than 12 hours, then the upgrade will be ignoredfee (uint32) This is what you would prefer the base fee to be. It is in stroopsbasereserve (uint32) This is what you would prefer the base reserve to be. It is in stroops.maxtxsize (uint32) This defines the maximum number of transactions to include in a ledger. When too many transactions are pending, surge pricing is applied. The instance picks the top maxtxsize transactions locally to be considered in the next ledger. Where transactions are ordered by transaction fee(lower fee transactions are held for later). {\" \"} protocolversion (uint32) defines the protocol version to upgrade to. When specified it must match one of the protocol versions supported by the node and should be greater than ledgerVersion from the current ledgersurveytopology surveytopology?duration=DURATION&node=NODE_ID Starts a survey that will request peer connectivity information from nodes in the backlog. DURATION is the number of seconds this survey will run for, and NODE_ID is the public key you will add to the backlog to survey. Running this command while the survey is running will add the node to the backlog and reset the timer to run for DURATION seconds. By default, this node will respond to/relay a survey message if the message originated from a node in it's transitive quorum. This behaviour can be overridden by adding keys to SURVEYOR_KEYS in the config file, which will be the set of keys to check instead of the transitive quorum. If you would like to opt-out of this survey mechanism, just set SURVEYOR_KEYS to $self or a bogus keystopsurvey stopsurvey Will stop the survey if one is running. Noop if no survey is runninggetsurveyresult getsurveyresult Returns the current survey results. The results will be reset everytime a new survey is startedThe following HTTP commands are exposed on test instances​generateload generateload[?mode=(create|pay)&accounts=N&offset=K&txs=M&txrate=R&batchsize=L&spikesize=S&spikeinterval=I] Artificially generate load for testing; must be used with ARTIFICIALLY_GENERATE_LOAD_FOR_TESTING set to true. Depending on the mode, either creates new accounts or generates payments on accounts specified (where number of accounts can be offset). Additionally, allows batching up to 100 account creations per transaction via 'batchsize'. When a nonzero I is given, a spike will occur every I seconds injecting S transactions on top of txrate.manualclose If MANUAL_CLOSE is set to true in the .cfg file. This will cause the current ledger to close.testacc testacc?name=N Returns basic information about the account identified by name. Note that N is a string used as seed, but \"root\" can be used as well to specify the root account used for the test instance.testtx testtx?from=F&to=T&amount=N&[create=true] Injects a payment transaction (or a create transaction if \"create\" is specified) from the account F to the account T, sending N XLM to the account. Note that F and T are seed strings but can also be specified as \"root\" as shorthand for the root account for the test instance.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/commands","title":"Commands","contentLength":2090}},{"pageContent":"Upgrading the NetworkThe network itself has network wide settings that can be updated.This is performed by validators voting for and agreeing to new values the same way that consensus is reached for transaction sets, etc.A node can be configured to vote for upgrades using the upgrades endpoint . See Commands for more information.The network settings are:the version of the protocol used to process transactionsthe maximum number of transactions that can be included in a given ledger closethe cost (fee) associated with processing operationsthe base reserve used to calculate the lumen balance needed to store things in the ledgerWhen the network time is later than the upgradetime specified in the upgrade settings, the validator will vote to update the network to the value specified in the upgrade setting. If the network time is passed the upgradetime by more than 12 hours, the upgrade will be ignoredWhen a validator is armed to change network values, the output of info will contain information about the vote.For a new value to be adopted, the same level of consensus between nodes needs to be reached as for transaction sets.Important notes on network wide settings​Changes to network wide settings have to be orchestrated properly between validators as well as non validating nodes:a change is vetted between operators (changes can be bundled)an effective date in the future is picked for the change to take effect (controlled by upgradetime)if applicable, communication is sent out to all network usersAn improper plan may cause issues such as:nodes missing consensus (aka \"getting stuck\"), and having to use history to rejoinnetwork reconfiguration taking effect at a non deterministic time (causing fees to change ahead of schedule for example)For more information look at Network Upgrade.Example upgrade command​Example here is to upgrade the protocol version to version 9 on January-31-2018.$ stellar-core http-command 'upgrades?mode=set&upgradetime=2018-01-31T20:00:00Z&protocolversion=9'$ stellar-core http-command infoAt this point info will tell you that the node is setup to vote for this upgrade:","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/network-upgrades","title":"Upgrading the Network","contentLength":347}},{"pageContent":"Tier 1 OrganizationsTo help with Stellar’s decentralization, the most reliable and advanced Stellar teams join the ranks of “Tier 1 Organizations.” These organizations run three validators, coordinate any changes to their quorumsets, and hold themselves to a higher standard of uptime and responsiveness.SDF works closely with Tier 1 Orgs to ensure the health of the network, maintain good quorum intersection, and build in redundancy to minimize network disruptions. This guide outlines what it takes to be a Tier 1 Org.Why Three Validators​The most important function of a Tier 1 Org is to set up and maintain three Full Validators. Why three?On Stellar, validators choose to trust organizations when they build a quorum set. If you are a trustworthy organization, you want your presence on the network to persist even if a node fails or you take it down for maintenance. A trio of validating nodes allows that to happen: other participants can create a quorum slice for your organization that requires ⅔ of your validating nodes to agree. If 1 has issues, no big deal: the other two still vote on your organization’s behalf, so the show goes on. To ensure redundancy, it's also important that those three Full Validators are geographically dispersed: if they're in the same data center, they run the risk of going down at the same time.Here’s what else Tier 1 Orgs expect of one another:Publish History Archives​In addition to participating in SCP, a full validator publishes an archive of network transactions. To do that, you need to configure Stellar Core to record history to a publicly accessible archive, and add the location of that archive to your stellar.toml. To be a Tier 1 Org, you should set each of your nodes to record history to a separate archive.Public archives make the network more resilient: when new nodes come online, or when existing nodes lose synch, they need to consult an archive to figure out what they missed. Sharing snapshots of the ledger, which detail transactions and their results, allows those nodes to catch up, and more archives mean more redundancy and greater decentralization. Plus, sharing history keeps everyone honest.Set Up a Safe Quorum Set​To maximize network resilience, we’re asking every Tier 1 node to use the same quorum set configuration, which is made up of subquorums of all validators from each Tier 1 Org.That way, the validator community can experiment with a larger quorum, and can analyze the results of those experiments without disrupting the network. Using existing Tier 1 Orgs as a safety net, we can work together to expand the quorum methodically and deliberately. To see what that quorum set currently looks like, check out the example Full Validator config file.Declare Your Node​SEP-20 is an open spec that explains how self-verification of validator nodes works. The steps it specifies are pretty simple: you set the home domain of your validator’s Stellar account to your website, where you publish information about your node and your organization in a stellar.toml file.It’s an easy way to propagate information, and it harnesses the network to allow other participants to discover your node and add it to their quorum sets without the need for a centralized database.Keep Your Nodes Up To Date​Running a validator requires vigilance. You need to keep an eye on your nodes, keep them up to date with the latest version of Stellar Core, and check in on public channels for information about what’s currently happening with other validators.The best two ways to do that:Join the validators email listdownload Keybase and join the #validators channel on the stellar.public teamWe always announce new Stellar Core releases in those channels. You can also find those releases on our github.It’s also critical that you pay attention to information about what those updates mean: often, you’ll need to set your validators to vote on something timely, such as when to upgrade the network as a whole, or how high to set the operations-per-ledger limit.Coordinate With Other Validators​Whether you run a trio of validators or a single node, it’s important that you coordinate with other validators when you make a significant change or notice something wrong. You should let them know when you plan to:Take your node down for maintenanceMake changes to your quorum setLetting other validators know when you plan to take your node down for maintenance or to upgrade to the latest version of stellar-core prevents a critical mass of nodes from going offline at the same time.Letting other validators know when you plan to change your quorum set allows them to respond, adjust, and think through the implications of expanding the quorum. For the quorum to expand safely, we all need to coordinate to ensure we maintain good quorum intersection.Monitor your quorum set​We recommend using Prometheus to to scrape and store your stellar-core metrics, and Grafana to render that data for human consumption. You can find step-by-step instructions for setting up monitoring and alerts in Monitoring and Diagnostics, along with links to Grafana dashboards we’ve created to make things easier.You can also use stellarbeat.io to view validators’ quorum configurations, and get information about their availability and uptime, and the quorum command to diagnose problems with the quorum set of the local node.You should do regular check-ins on your quorum set. If nodes have bad uptime or prove otherwise unreliable, you may need to remove them from your quorum set so that you don’t get stuck and so that the network doesn’t halt. You may also want to add new organizations that come online and prove reliable. If you plan to do either of those things, remember to communicate and coordinate with other validators.Get in touch​If you think you can be a Tier 1 Org, let us know on the #validators channel on Keybase. We can help you through the process, and once you’re up and running, we’ll work to fold you into the quorum so that you can take your rightful place as a pillar of the network. Once you’ve proven that you are responsive, reliable, and maintain good uptime, we will adjust the quorum set recipe above to include your validators.As Stellar grows, and more and more businesses build on the network, Tier 1 Orgs will be crucial to the methodical expansion of the network.","metadata":{"source":"https://developers.stellar.org/docs/run-core-node/tier-1-orgs","title":"Tier 1 Organizations","contentLength":1099}},{"pageContent":"PrerequisitesHorizon only has one true dependency: a PostgreSQL server that it uses to store data that has been processed and ingested from Stellar Core. Horizon requires PostgreSQL version >= 9.5.As far as system requirements go, there are a few main things to keep in mind. Starting from version 2.0, Horizon must be run as a standalone service. A full Horizon build consists of three functions:ingesting data from the decentralized Stellar network,submitting transactions to the network, andserving API requestsThe first two happen through Captive Core, a pared down, non-validating version of Stellar Core packaged directly into Horizon.With these three functions in mind, you can also run Horizon in two different ways: real-time ingestion and historical catch-up:Real-time ingestion is an “online” process: it involves keeping in sync with the live Stellar network state and digesting ledger data into a holistic view of the network. If you just want function (3) from above, you still need to do this.Historical catch-up is an “offline” process: it lets you look into the past and catch up your Horizon instance to a given retention period (e.g. 30 days of history). Because it’s typically done offline and a one-time process, you can dedicate more compute power and configure parallel workers to catch up faster.Historical Catch-up​In this scenario, the hardware specifications are more demanding than what is necessary for the day-to-day operation of real-time ingestion, but catch-up only needs to occur once.However, the requirements will vary depending on your chosen retention period and desired catch-up speed. Note that most operators will not need full history, and as the network continues to grow, tracking full history will become increasingly prohibitive. As of late 2021, DB storage to support historical retention is growing at a rate of 0.8 TB / month. It is highly recommended to configure retention of only the history needed to support your functionality.Requirements​Minimally, your disk storage type must be an SSD (e.g. NVMe, Direct Attached Storage) and your I/O must handle >15k iops (I/O operations per second). The following table breaks down hardware specifications for ingestion at different retention levels and performance tiers.Note that each component can be scaled independently and for redundancy, in the manner of traditional n-tier systems which is covered later in Scaling. Ingestion can be sped up via configuring more Captive Core parallel workers (requiring more compute and RAM).ComponentRetention Period30 days90 daysFull HistoryParallel worker count(est. ingestion time)6 workers (1 day)10 workers (1 day)20+ workers (2 days)HorizonCPU: 10 cores (min: 6) RAM: 64 GB (min: 32)CPU: 16 (min: 8) RAM: 128 GB (64)CPU: 16 (10) RAM: 512 GB (256)DatabaseCPU: 16 cores (min: 8)RAM: 64 GB (min: 32GB)Storage: 2 TBIOPS: 20K (min: 15K)CPU: 16 (12)RAM: 128 GB (64)Storage: 4 TBIOPS: 20K (15K)CPU: 64 (32)RAM: 512 GB (256)Storage: 10 TBIOPS: 20k (15k)Storage(all same)SSD (NVMe, Direct Attached Storage preferred)AWS(reference)Captive Core: m5.2xlargeDatabase: r5.2xlargeCaptive Core: m5.4xlargeDB: r5.4xlargeCaptive Core: c5.2xlarge (x2)DB: r5.16xlarge (ro)r5.8xlarge (rw)Real-Time Ingestion​In this scenario, the goal is just to stay in sync with the Stellar network for day-to-day operations.There are two extremes to this spectrum: running a single private instance of Horizon for a specific application all the way up to a serious enterprise public instance of Horizon. In the former case, you’d run all three functions on a single machine and have low request volume; in the latter case, you’d have high-availability, redundancy, high request volume, full history, etc.Requirements​The following table breaks down requirements along this spectrum; if you fall somewhere in between, interpolate the requirements accordingly.CategoryPrivate InstanceEnterprise Public InstanceComputeBoth API Service + Captive Core:CPU: 4RAM: 32 GBAPI ServiceCPU: 4RAM: 8 GBN instances, load balanced Captive CoreCPU: 8RAM: 256 GB2 instances for redundancyDatabaseCPU: 4 RAM: 32 GB IOPS: 7k (min: 2.5k)CPU: 32 - 64 RAM: 256 - 512 GB IOPS: 20k (min: 15k) 2 HA instances: 1RO, 1RWStorage (SSD)depends on retention period10 TBAWS (reference)API Service + Captive Corem5.2xlargeDatabaser5.2xlarge (ro)r5.xlarge (rw)API Servicec5.xlarge (n) Captive Corec5.2xlarge (x2)Database r5.16xlarge (ro)r5.8xlarge (rw)","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/prerequisites","title":"Prerequisites","contentLength":730}},{"pageContent":"Migrating From 1.xIntroduction​Starting with version v1.6.0, Horizon allows using Stellar Core in \"captive\" mode for ingestion. This mode has been enabled by default since Horizon 2.0, so even though you can enable captive mode on 1.6+, this migration guide is catered towards upgrading to 2.x due to the stability and configuration improvements introduced in the later versions.Please start with the blog post to understand the major changes that Horizon 2.0 introduces with the Captive Core architecture. In summary, Captive Core is a specialized, narrowed-down Stellar-Core instance with the sole aim of emitting transaction metadata to Horizon. It means:no separate Stellar Core instanceno Core database: everything done in-memorymuch faster ingestionCaptive Stellar Core completely eliminates all Horizon issues caused by connecting to Stellar Core's database, but it requires extra time to initialize and manage its Stellar Core subprocess. Captive Core can be used in both reingestion (horizon db reingest range) and normal Horizon operation (horizon serve). In fact, using Captive Core to reingest historical data is considerably faster than without it.How It Works​The blog post linked above gives a high-level overview, while this section dives a little deeper into the technical differences relative to Horizon's relationship with standalone, \"Watcher\" Core.When using Captive Core, Horizon runs the stellar-core binary as a subprocess. Then, both processes communicate over filesystem pipe: Core sends xdr.LedgerCloseMeta structs with information about each ledger and Horizon reads it.The behaviour is slightly different when reingesting old ledgers and when reading recently closed ledgers:When reingesting, Stellar Core is started in a special catchup mode that simply replays the requested range of ledgers. This mode requires an additional 3GiB of RAM because all ledger entries are stored in memory, making it extremely fast. This mode only depends on the history archives, so a Captive Core configuration (see below) is not required.When reading recently closed ledgers, Core is started with a normal run command. This mode also requires an additional 3GiB of RAM for in-memory ledger entries. In this case, a configuration file (again, read on below) is required in order to configure a quorum set so that it can connect to the Stellar network.Known Limitations​As discussed earlier, Captive Core provides much better decoupling for Horizon at the expense of persistence. You should be aware of the following consequences:Captive Core requires a couple of minutes to complete the \"apply buckets\" stage first time Horizon is started, but it should reuse the cached buckets on subsequent restarts (as of Horizon 2.5 and Core 17.1).If the Horizon process terminates, Stellar Core is also terminated.Running Horizon now requires more RAM and less disk space. You can refer to the earlier Prerequisites page for details.To hedge against these limitations, we recommend running multiple ingesting Horizon servers in a single cluster. This allows other ingesting instances to maintain service without interruptions if a Captive Core instance is restarted.Migration​Now, we'll discuss migrating existing systems running the pre-2.0 versions of Horizon to the new Captive Core world.Configuration​The first major change from 1.x is how you will configure Horizon. You will no longer need your Stellar Core configuration, but will rather need to craft a configuration file describing Captive Core's behavior. Read this section to understand what the stub should contain.Your old configuration cannot be used directly: Horizon needs special settings for Captive Core. Otherwise, running Horizon may fail with the following error, or errors like it:Again, while the Captive Core configuration file may appear to just be a subset of Stellar Core's configuration, you shouldn't think about it that way and treat it as its own format. It may diverge in the future, and not all of Core's options are available to Captive Core.You should pass the location of this new TOML configuration to the --captive-core-config-path/CAPTIVE_CORE_CONFIG_PATH command-line flag / environmental variable.If you want to continue to have access to the underlying Stellar Core subprocess (like you did previously with a standalone Watcher Core), you should set the HTTP_PORT field in your configuration file accordingly.Installation​Once you have a configuration file ready, you should also modify your Horizon configuration to include Captive Core parameters. Within /etc/default/stellar-horizon, you should add:You may need to adjust these accordingly, for example by pointing CAPTIVE_CORE_CONFIG_PATH to your configuration file and possibly CAPTIVE_CORE_STORAGE_PATH to where you'd like Captive Core to store its bucket files (but keep in mind the disk space and permissions requirements).Finally, the process for upgrading both Stellar Core and Horizon is covered here.Restarting Services​Now, we can stop Core and restart Horizon:After a few moments, the logs should show Captive Core running successfully as a subprocess, and eventually Horizon will be running as usual except with Captive Core rapidly generating transaction metadata in-memory!Private Networks​If you want your Captive Core instance to connect to a private Stellar network, you will need to specify the validator(s) of the private network in the Captive Core configuration file.Assuming the validator of your private network has a public key of GD5KD2KEZJIGTC63IGW6UMUSMVUVG5IHG64HUTFWCHVZH2N2IBOQN7PS and can be accessed at private1.validator.com, then the Captive Core config would consist of the following:UNSAFE_QUORUM=true and FAILURE_SAFETY=0 are required when there are too few validators in the private network to form a quorum.You will also need to set RUN_STANDALONE=false in the Stellar Core configuration for the validator. Otherwise, the validator will not accept connections on its peer port, which means Captive Core will not be able to connect to the validator.On a new Stellar network, the first history archive snapshot is published after ledger 63 is closed. Captive Core depends on the history archives, which means that Horizon ingestion via Captive Core will not begin until after ledger 63 is closed. Assuming the standard 5 second delay in between ledgers, it will take ~5 minutes for the network to progress from the genesis ledger to ledger 63.There are cases where you may need to repeatedly create new private networks (e.g. spawning a private network during integration tests) and this 5 minute delay is too costly. In that case, you can consider including ARTIFICIALLY_ACCELERATE_TIME_FOR_TESTING=true in both the validator configuration and the Captive Core configuration. When this parameter is set, Stellar Core will publish a new ledger every second. It will also publish history archive snapshots every 8 ledgers, so you will need to set Horizon's checkpoint frequency parameter (--checkpoint-frequency/CHECKPOINT_FREQUENCY) to 8.Reingestion​After migrating to the Captive Core world, you will assuredly need to reingest your history again.The Ingestion guide should refresh your memory on this: nothing has really changed aside from how quickly reingestion gets done. For example, a full reingestion of the entire network only takes ~1.5 days (as opposed to weeks previously) on an m5.8xlarge instance.","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/migrating","title":"Migrating From 1.x","contentLength":1175}},{"pageContent":"InstallingTo install Horizon, you have a few choices. You can...install prebuilt binaries from our repositories via your package manager if running a Debian-based system,download a prebuilt release of Horizon for your target architecture and operation system, orbuild Horizon and Stellar Core yourself from scratch.The first method is recommended: Not only do you ensure OS compatibility and dependency management, you'll also install some convenient wrappers that make running Horizon and Stellar Core in their respective environments much simpler.Installation Methods​Package Manager​SDF publishes new releases to its custom Ubuntu repositories. Follow this guide to add the stable SDF repository to your system. This page outlines the various commands that these packages make available. We'll need:Next, you can jump to Testing Your Installation.Building​Should you decide not to use one of our prebuilt releases, you may instead build Horizon from source. To do so, you need to prepare a developer environment, including:A Unix-like operating system with the common core commands (cp, tar, mkdir, bash, etc.)A compatible distribution of Golang (v1.15 or later)git(Though Horizon can run on Windows, building directly on Windows is not supported.)At this point, you can easily build the Horizon binary:(You should refer to the list of Horizon releases and git checkout accordingly before building if you're looking for a stable release rather than the bleeding edge master branch.)At this point, you can either copy the binary from the GOPATH to the system PATH (as we'll do later), or add Go binaries to your PATH in your .bashrc (or equivalent):You will also need to compile Stellar Core from its source code if you need ingestion or transaction submission. You should refer to their installation guide for details.Next, jump ahead to Testing Your Installation.Completing and Testing Your Installation​If you built from source or downloaded a release from GitHub, make sure to copy the native binary into a directory that is part of your PATH. Most Unix-like systems have /usr/local/bin in PATH by default, so unless you have a preference or know better, we recommend you copy the binary there:(We've renamed it here to keep it consistent with the results of the recommended Package Manager method.)To test your installation, simply run stellar-horizon --help from a terminal. If the help for Horizon is displayed, your installation was successful.Note: Some shells (such as zsh) cache PATH lookups. You may need to clear your cache (by using rehash in zsh, for example) or restart your shell before trying to run the aforementioned command.","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/installing","title":"Installing","contentLength":440}},{"pageContent":"ConfiguringOnce Horizon is installed, you are ready to configure it. Note that Horizon fulfills three important, distinct roles:serving requests like a regular web-based API,ingesting ledgers from the Stellar network to keep its world-view up to date, andtransaction submission for interacting with the Stellar network.Though we encourage operators to separate these responsibilities across instances for resilience and independent scaling, a single Horizon instance can perform all of these functions at once.For the remainder of this guide, we will assume that you want a single, standalone Horizon instance that performs ingestion and allows transaction submission. We'll cover ingestion in detail later if you want to read ahead and decide which approach is right for you.Parameters​Horizon can be configured by both command line flags and environment variables. To see Horizon's list of available command line flags, their default values, and their corresponding environmental variable names, run:You'll see that Horizon defines a large number of flags; however, only a handful are required to get started:flagenvvarexample--db-urlDATABASE_URLpostgres://localhost/horizon_testnet--history-archive-urlsHISTORY_ARCHIVE_URLShttps://history.stellar.org/prd/core-testnet/core_testnet_001,https://history.stellar.org/prd/core-testnet/core_testnet_002The most important parameter, --db-url, specifies the Horizon database; its value should be a valid PostgreSQL Connection URI.The other parameter, --history-archive-urls, specifies a set of comma-separated locations from which Horizon should download history archives.With Ingestion​As outlined at the beginning, we presume you are interested in starting an ingesting instance. For this, you need to specify some additional flags:flagenvvarexample--captive-core-config-pathCAPTIVE_CORE_CONFIG_PATH/etc/default/stellar-captive-core.toml--stellar-core-binary-pathSTELLAR_CORE_BINARY_PATH/usr/bin/stellar-coreNote that ingestion is enabled by default.The first parameter, --captive-core-config-path, points to a Captive Core configuration file. This TOML file only requires a few fields (explained below) to get up and running.The second parameter, --stellar-core-binary-path, is a filesystem path to a Stellar Core binary. Horizon will actually search your PATH for stellar-core by default, so if your environment is configured appropriately, you don't need to pass this.Without Ingestion​If you aren't configuring your Horizon instance to perform ingestion, it still needs awareness about what's going on in the Stellar network to be useful. Thus, you need to point Horizon to a running Stellar Core instance:flagenvvarexample--ingestINGESTfalse--stellar-core-urlSTELLAR_CORE_URLhttp://127.0.0.1:11626This would be a standalone Stellar-Core instance.Manual Installation​Specifying command line flags every time you invoke Horizon can be cumbersome, so we recommend using environment variables. There are many tools you can use to manage them, such as direnv or dotenv.For configuration related to Captive Core, you should prepare a separate TOML file and pass it to the --captive-core-config-path/CAPTIVE_CORE_CONFIG_PATH argument.Package Manager Installation​If you installed Horizon via your package manager, the provided stellar-horizon-cmd wrapper will import a configuration from /etc/default/stellar-horizon and set up the environment accordingly. Hence, if you want to change things, edit the configuration file in /etc/default/stellar-horizon.Note that the default configuration (located at /etc/default/stellar-horizon) provided by the package manager enables ingestion by default. Again, refer to the later Ingestion page to see what setup is right for you. If you want certain nodes dedicated exclusively to fulfilling requests, you should set this flag to false accordingly.Preparing the Database​Before running the Horizon server, you must first prepare the Horizon database specified by the DATABASE_URL. This database will be used for all of the information produced by Horizon, most notably historical information about transactions that have occurred on the Stellar network.To prepare a database for Horizon's use, you must first ensure it is blank. It's easiest to create a new database on your PostgreSQL server specifically for Horizon's use (e.g. createdb horizon). Note that you may need to add a role for yourself (or the stellar user) through the postgres user if you're starting from scratch. Next, install the schema by running stellar-horizon db init. This command will log any errors that occur.Remember to update the appropriate DB-related flags or environment variables to configure Horizon as explained above.Postgres Configuration​It is recommended to set random_page_cost=1 in Postgres' configuration if you are using SSD storage. With this setting, Query Planner will make a better use of indices, especially for JOIN queries. We've noticed a huge speed improvement for some queries with this setting.To improve availability of both ingestion and frontend servers it's recommended to set the following values:tcp_keepalives_idle: 10 secondstcp_keepalives_interval: 1 secondtcp_keepalives_count: 5With the config above, if there are no queries from a given client for 10 seconds, Postgres should start sending TCP keepalive packets. It will retry 5 times every second. If there is no response from the client after that time it will drop the connection.Configuring Captive Core​While a full Stellar Core node requires a complex configuration with lots of possible fields, the Captive Core configuration file can be kept extremely barebones. Most of the configuration will be generated automagically at runtime. Here's is a minimal working example, operating under the assumption that you want to connect to the testnet and trust SDF's validators exclusively:(For the remainder of this guide, we'll assume this file lives at /etc/default/stellar-captive-core.toml.)The minimum required fields are the [[HOME_DOMAINS]] and a set of [[VALIDATORS]].If you wanted to adapt this and configure your nodes to work on the Stellar pubnet, you'll need to think more carefully about the validators you want to trust in your quorum. As inspiration, here is the set of domains and validators that SDF includes in its pubnet quorum. You should also familiarize yourself with how to configure a proper quorum set; the Core documentation has more on this.Captive Core's functionality is controlled through this file. Note that while the Captive Core configuration looks like a subset of a traditional Stellar Core configuration file, you cannot use a traditional Stellar Core configuration file to configure Captive Core. The TOML format is preserved for operator ease of migrating from Horizon 1.x, but this is a fundamentally different architecture and should be treated as such.Now, jump ahead to Running Horizon!","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/configuring","title":"Configuring","contentLength":1066}},{"pageContent":"RunningOnce your Horizon database and Captive Core configuration is set up properly, you're ready to run Horizon. Run stellar-horizon with the appropriate parameters set (or stellar-horizon-cmd serve if you installed via the package manager, which will automatically import your configuration from /etc/default/stellar-horizon), which starts the HTTP server and starts logging to standard out. When run, you should see output similar to:Note that the numbers may naturally be different for your installation. The log line above announces that Horizon is ready to serve client requests.Next, you can confirm that Horizon is responding correctly by loading the root resource. In the example above, that URL would be http://127.0.0.1:8000/, and simply running curl http://127.0.0.1:8000/ would show you that the root resource loads correctly:","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/running","title":"Running","contentLength":139}},{"pageContent":"IngestionHorizon provides access to both current and historical state on the Stellar network through a process called ingestion.Horizon provides most of its utility through ingested data, and your Horizon server can be configured to listen for and ingest transaction results from the Stellar network. Ingestion enables API access to both current (e.g. someone's balance) and historical state (e.g. someone's transaction history).Ingestion Types​There are two primary ingestion use-cases for Horizon operations:ingesting live data to stay up to date with the latest, real-time changes to the Stellar network, andingesting historical data to peek how the Stellar ledger has changed over timeIngesting Live Data​Though this option is disabled by default, in this guide we've assumed you turned it on. If you haven't, pass the --ingest flag or set INGEST=true in your environment.For a serious setup, we highly recommend having more than one live ingesting instance, as this makes it easier to avoid downtime during upgrades and adds resilience to your infrastructure, ensuring you always have the latest network data.Ingesting Historical Data​Providing API access to historical data is facilitated by a Horizon subcommand:(The command name is a bit of a misnomer: you can use reingest both to ingest new ledger data and reingest old data.)You can run this process in the background while your Horizon server is up. It will continuously decrement the history.elder_ledger in your /metrics endpoint until the <end> ledger is reached and the backfill is complete. If Horizon receives a request for a ledger it hasn't ingested, it returns a 503 error and clarify that it's Still Ingesting (see below).Deciding on how much history to ingest​You should think carefully about the amount of ingested data you'd like to keep around. Though the storage requirements for the entire Stellar network are substantial, most organizations and operators only need a small fraction of the history to fit their use case. For example,If you just started developing a new application or service, you can probably get away with just doing live ingestion, since nothing you do requires historical data.If you're moving an existing service away from reliance on SDF's Horizon, you likely only need history from the point at which you started using the Stellar network.If you provide temporal guarantees to your users--a 6-month guarantee of transaction history like some online banks do, or history only for the last thousand ledgers (see below), for example--then you similarly don't have heavy ingestion requirements.Even a massively-popular, well-established custodial service probably doesn't need full history to service its users. It will, however, need full history to be a Full Validator with published history archives.Reingestion​Regardless of whether you are running live ingestion or building up historical data, you may occasionally need to _re_ingest ledgers anew (for example on certain upgrades of Horizon). For this, you use the same command as above.Parallel ingestion​Note that historical (re)ingestion happens independently for any given ledger range, so you can reingest in parallel across multiple Horizon processes:Managing storage​Over time, the recorded network history will grow unbounded, increasing storage used by the database. Horizon needs sufficient disk space to expand the data ingested from Stellar Core. Unless you need to maintain a history archive, you should configure Horizon to only retain a certain number of ledgers in the database.This is done using the --history-retention-count flag or the HISTORY_RETENTION_COUNT environment variable. Set the value to the number of recent ledgers you wish to keep around, and every hour the Horizon subsystem will reap expired data. Alternatively, Horizon provides a command to force a collection:Common Issues​Ingestion is a complicated process, so there are a number of things to look out for.Some endpoints are not available during state ingestion​Endpoints that display state information are not available during initial state ingestion and will return a 503 Service Unavailable/Still Ingesting error. An example is the /paths endpoint (built using offers). Such endpoints will become available after state ingestion is done (usually within a couple of minutes).State ingestion is taking a lot of time​State ingestion shouldn't take more than a couple of minutes on an AWS c5.xlarge instance or equivalent.It's possible that the progress logs (see below) will not show anything new for a longer period of time or print a lot of progress entries every few seconds. This happens because of the way history archives are designed.The ingestion is still working but it's processing entries of type DEADENTRY. If there is a lot of them in the bucket, there are no active entries to process. We plan to improve the progress logs to display actual percentage progress so it's easier to estimate an ETA.If you see that ingestion is not proceeding for a very long period of time:Check the RAM usage on the machine. It's possible that system ran out of RAM and is using swap memory that is extremely slow.If above is not the case, file a new issue in the Horizon repository.CPU usage goes high every few minutes​This is by design. Horizon runs a state verifier routine that compares state in local storage to history archives every 64 ledgers to ensure data changes are applied correctly. If data corruption is detected, Horizon will block access to endpoints serving invalid data.We recommend keeping this security feature turned on; however, if it's causing problems (due to CPU usage) this can be disabled via the --ingest-disable-state-verification/INGEST_DISABLE_STATE_VERIFICATION parameter.Ingesting Full Public Network History​In some (albeit rare) cases, it can be convenient to (re)ingest the full Stellar Public Network history into Horizon (e.g. when running Horizon for the first time). Using multiple Captive Core workers on a high performance environment (powerful machines on which to run Horizon + a powerful database) makes this possible in ~1.5 days.The following instructions assume the reingestion is done on AWS. However, they should be applicable to any other environment with equivalent capacity. In the same way, the instructions can be adapted to reingest only specific parts of the history.Prerequisites​Before we begin, we make some assumptions around the environment required. Please refer to the Prerequisites section for the current HW requirements to run Horizon reingestion for either historical catch up or real-time ingestion (for staying in sync with the ledger). A few things to keep in mind:For reingestion, the more parallel workers are provisioned to speed up the process, the larger the machine size is required in terms of RAM, CPU, IOPS and disk size. The size of the RAM per worker also increases over time (14GB RAM / worker as of mid 2022) due to the growth of the ledger. HW specs can be downsized once reingestion is completed.Horizon latest version installed on the machine from (1).Core latest version installed on the machine from (1).A Horizon database where to reingest the history. Preferably, the database should be empty to minimize storage (Postgres accumulates data during usage, which is only deleted when VACUUMed) and have the minimum spec's for reingestion as outlined in Prerequisites.As the DB storage grows, the IO capacity will grow along with it. The number of workers (and the size of the instance created in (1), should be increased accordingly if we want to take advantage of it. To make sure we are minimizing reingestion time, we should watch write IOPS. It should ideally always be close to the theoretical limit of the DB.Parallel Reingestion​Once the prerequisites are satisfied, we can spawn two Horizon reingestion processes in parallel:One for the first 17 million ledgers (which are almost empty).Another one for the rest of the history.This is due to first 17 million ledgers being almost empty whilst the rest are much more packed. Having a single Horizon instance with enough workers to saturate the IO capacity of the machine for the first 17 million would kill the machine when reingesting the rest (during which there is a higher CPU and memory consumption per worker).64 workers for (1) and 20 workers for (2) saturates instance with RAM and 15K IOPS. Again, as the DB storage grows, a larger number of workers and faster storage should be considered.In order to run the reingestion, first set the following environment variables in the configuration (updating values to match your database environment, of course):(Naturally, you can also edit the configuration file at /etc/default/stellar-horizon directly if you installed from a package manager.)If Horizon was previously running, first ensure it is stopped. Then, run the following commands in parallel:stellar-horizon db reingest range --parallel-workers=64 1 16999999stellar-horizon db reingest range --parallel-workers=20 17000000 <latest_ledger>(Where you can find <latest_ledger> under SDF Horizon's core_latest_ledger field.)When saturating a database instance with 15K IOPS capacity:(1) should take a few hours to complete.(2) should take about 3 days to complete.Although there is a retry mechanism, reingestion may fail half-way. Horizon will print the recommended range to use in order to restart it.When reingestion is complete it's worth running ANALYZE VERBOSE [table] on all tables to recalculate the stats. This should improve the query speed.Monitoring reingestion process​This script should help monitor the reingestion process by printing the ledger subranges being reingested:Ideally we would be using Prometheus metrics for this, but they haven't been implemented yet.Here is an example run:Reading Logs​In order to check the progress and status of ingestion you should check your logs regularly; all logs related to ingestion are tagged with service=ingest.It starts with informing you about state ingestion:During state ingestion, Horizon will log the number of processed entries every 100,000 entries (there are currently around 10M entries in the public network):When state ingestion is finished, it will proceed to ledger ingestion starting from the next ledger after the checkpoint ledger (25565887+1 in this example) to update the state using transaction metadata:Managing Stale Historical Data​Horizon ingests ledger data from a managed, pared-down Captive Stellar Core instance. In the event that Captive Core crashes, lags, or if Horizon stops ingesting data for any other reason, the view provided by Horizon will start to lag behind reality. For simpler applications, this may be fine, but in many cases this lag is unacceptable and the application should not continue operating until the lag is resolved.To help applications that cannot tolerate lag, Horizon provides a configurable \"staleness\" threshold. If enough lag accumulates to surpass this threshold (expressed in number of ledgers), Horizon will only respond with an error: stale_history. To configure this option, use the --history-stale-threshold/HISTORY_STALE_THRESHOLD parameter.Note: Non-historical requests (such as submitting transactions or checking account balances) will not error out if the staleness threshold is surpassed.","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/ingestion","title":"Ingestion","contentLength":1850}},{"pageContent":"MonitoringTo ensure that your instance of Horizon is performing correctly, we encourage you to monitor it and provide both logs and metrics to do so.Metrics​Metrics are collected while a Horizon process is running and they are exposed privately via the /metrics path, accessible only through the Horizon admin port. You need to configure this via --admin-port or ADMIN_PORT, since it's disabled by default. If you're running such an instance locally, you can access this endpoint:Logs​Horizon will output logs to standard out. Information about what requests are coming in will be reported, but more importantly, warnings or errors will also be emitted by default. A correctly running Horizon instance will not output any warning or error log entries.Below we present a few standard log entries with associated fields. You can use them to build metrics and alerts. Please note that these represent Horizon app metrics only. You should also monitor your hardware metrics like CPU or RAM Utilization.Starting HTTP request​KeyValuemsgStarting requestclient_nameValue of X-Client-Name HTTP header representing client nameclient_versionValue of X-Client-Version HTTP header representing client versionapp_nameValue of X-App-Name HTTP header representing app nameapp_versionValue of X-App-Version HTTP header representing app versionforwarded_ipFirst value of X-Forwarded-For headerhostValue of Host headeripIP of a client sending HTTP requestip_portIP and port of a client sending HTTP requestmethodHTTP method (GET, POST, ...)pathFull request path, including query string (ex. /transactions?order=desc)streamingBoolean, true if request is a streaming requestrefererValue of Referer headerreqRandom value that uniquely identifies a request, attached to all logs within this HTTP requestFinished HTTP request​KeyValuemsgFinished requestbytesNumber of response bytes sentclient_nameValue of X-Client-Name HTTP header representing client nameclient_versionValue of X-Client-Version HTTP header representing client versionapp_nameValue of X-App-Name HTTP header representing app nameapp_versionValue of X-App-Version HTTP header representing app versiondurationDuration of request in secondsforwarded_ipFirst value of X-Forwarded-For headerhostValue of Host headeripIP of a client sending HTTP requestip_portIP and port of a client sending HTTP requestmethodHTTP method (GET, POST, ...)pathFull request path, including query string (ex. /transactions?order=desc)routeRoute pattern without query string (ex. /accounts/{id})statusHTTP status code (ex. 200)streamingBoolean, true if request is a streaming requestrefererValue of Referer headerreqRandom value that uniquely identifies a request, attached to all logs within this HTTP requestMetrics​Using the entries above you can build metrics that will help understand performance of a given Horizon node. For example:Number of requests per minute.Number of requests per route (the most popular routes).Average response time per route.Maximum response time for non-streaming requests.Number of streaming vs. non-streaming requests.Number of rate-limited requests.List of rate-limited IPs.Unique IPs.The most popular SDKs/apps sending requests to a given Horizon node.Average ingestion time of a ledger.Average ingestion time of a transaction.Alerts​Below are example alerts with potential causes and solutions. Feel free to add more alerts using your metrics:AlertCauseSolutionSpike in number of requestsPotential DoS attackLower rate-limiting thresholdLarge number of rate-limited requestsRate-limiting threshold too lowIncrease rate-limiting thresholdIngestion is slowHorizon server spec too lowIncrease hardware specSpike in average response time of a single routePossible bug in a code responsible for rendering a routeReport an issue in Horizon repository.I'm Stuck! Help!​If any of the above steps don't work or you are otherwise prevented from correctly setting up Horizon, please join our community and let us know. Either post a question at our Stack Exchange or chat with us on Keybase in #dev_discussion to ask for help.","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/monitoring","title":"Monitoring","contentLength":600}},{"pageContent":"ScalingAs alluded to in the discussion on Prerequisites, Horizon encompasses different logical tiers that can be scaled independently for high throughput, isolation, and high availability. The following components can be independently scaled:Web service API (serving)Captive Core (ingestion and transaction submission)Database (storage)As always, scaling encompasses a spectrum. A few common scaling architectures follow.Single VM​As a starting point, for development purposes or low load environments with limited history retention (e.g. a few ledger entries), a single VM would suffice.Low to Medium Load​For low to medium load environments with up to 30-90 days of data history retention and modest API request traffic, this configuration isolates the database instance from the API service and ingestion process.Extension: Isolating Captive Core​Additionally, Captive Core can be further isolated into its own VM, especially for isolating high throughput historical catch-up with parallel workers, leaving it unaffected by API request servicing load.Enterprise n-Tier​This architecture services high request and data processing throughput with isolation and redundancy for each component. Scale the API service horizontally by adding a load balancer in front of multiple API service instances, each only limited by the database I/O limit. If necessary, use ALB routing to direct specific endpoints to specific request-serving instances, which are tied to a specific, dedicated DB. Now, if an intense endpoint gets clobbered, all other endpoints are unaffected.Database instances can be scaled when the I/O limit is reached by using read-only replicated copies that stay in sync and a read/write instance connected to Captive Core. Each DB replica can support a set of request servers to support additional horizontal scaling.Additionally, a second Captive Core instance shares ingestion load and serves as a backup in case of an instance failure.Extension: Redundant Hot Backup​The entire architecture can be replicated to a second cluster. The backup cluster can be upgraded independently or fail-overed to with no downtime. Additionally, capacity can be doubled in an emergency if needed.","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/scaling","title":"Scaling","contentLength":339}},{"pageContent":"Ingestion FilteringThe Ingestion Filtering feature is now released for public beta testing available from Horizon version 2.18.0 and up.Overview​Ingestion Filtering enables Horizon operators to drastically reduce storage footprint of their Horizon DB by whitelisting Assets and/or Accounts that are relevant to their operations. This feature is ideally suited for private Horizon operators who do not need full history for all assets and accounts on the Stellar network.Why is it useful:​Previously, the only way to limit data storage is by limiting the amount of history Horizon ingests, either by configuring the starting ledger to be later than genesis block or via rolling retention (ie: last 30 days). This feature allows users to store the full history of assets and accounts (and related entities) that they care about.For further context, running a full history Horizon instance currently takes ~ 15TB of disk space (as of June 2022) with storage growing at a rate of ~ 1TB / month. As a benchmark, filtering by even 100 of the most active accounts and assets reduces storage by over 90%. For the majority of users who care about an even more limited set of assets and accounts, storage savings should be well over 99%. Other benefits are reducing operating costs for maintaining storage, improved DB health metrics and query performance.How does it work:​This feature provides an ability to select which ledger transactions are accepted at ingestion time to be stored in Horizon’s historical database. Filter whitelists are maintained via an admin REST API (and persisted in the DB). The ingestion process checks the list and persists transactions related to Accounts and Assets that are whitelisted. Note that the feature does not filter the current state of the ledger and related DB tables, only history tables.Whitelisting can include the following supported entities:Account idAsset id (canonical)Given that all transactions related to the white listed entities are included, all historical time series data related to those transactions are saved in horizon's history db as well. For example, whitelisting an Asset will also persist all Accounts that interact with that Asset and vice versa, if an Account is whitelisted, all assets that are held by that Account will also be included.Configuration:​The filters and their configuration are optional features and must be enabled with horizon command line or environmental parameters:andAs Environment properties:andThese should be included in addition to the standard ingestion parameters that must be set also to enable the ingestion engine to be running, such as ingest=true, etc. Once these flags are included at horizon runtime, filter configurations and their rules are initially empty and the filters are disabled by default. To enable filters, update the configuration settings, refer to the Admin API Docs which are published as Open API 3.0 doc on the Admin Port at http://localhost:<admin_port>/. You can paste the contents from that url into any OAPI tool such as Swagger which will render a visual explorer of the API endpoints. Follow details and examples for endpoints:Operation:​Adding and Removing Entities can be done by submitting PUT requests to the http://localhost:<admin_port>/ endpoint.To add new filtered entities, submit an HTTP PUT request to the admin API endpoints for either Asset or Account filters. The PUT request body will be JSON that expresses the filter rules, currently the rules model is a whitelist format and expressed as JSON string array. To remove entities, submit an HTTP PUT request to update the list accordingly. To retrieve what is currently configured, submit an HTTP GET request.The OAPI doc published by the Admin Server can be pulled directly from the Github repo here.Reverting Options:​Disable both Asset and Account Filter config rules via the Admin API by setting enabled=false in each filter rule, or set --exp-enable_ingestion_filtering=false, this will open up forward ingestion to include all data again. It is then your choice whether to run a Re-ingestion to capture older data from past that would have been dropped by filters but could now be re-imported with filters off, e.g. horizon db reingest <from_ledger> <to_ledger>If you have a DB backup:restore the DBrun a Reingestion Gap Fill command to fill in the gaps to current tip of the chainresume Ingestion SyncStart over with a fresh DB (or see Patching Historical Data below)Patching Historical Data:​If new Assets or Accounts are added to the whitelist and you would like to patch in its missing historical data, Reingestion can be run. The Reingestion process is idempotent and will re-ingest the data from the designated ledger range and overwrite or insert new data if not already on current DB.Sample Use Case:​As an Asset Issuer, I have issued 4 assets and am interested in all transaction data related to those assets including customer Accounts that interact with those assets and the following:OperationsEffectsPaymentsClaimable balancesTradesI would like to store the full history of all transactions related from the genesis of those assets.Pre-requisites:​You have an existing Horizon installed, configured and has forward ingestion enabled at a minimum to be able to successfully sync to the current state of the Stellar network. Bonus if you are familiar with running re-ingestion.Steps:Configure 4 whitelisted Assets via the Admin API. Also check the HISTORY_RETENTION_COUNT and set it to 0 if you don’t want any history purged anymore now that you are filtering, otherwise it will continue to reap all data older than the retention.Decide if you want to wipe existing history data on the DB first before the filtering starts running, you can effectively clear the history by runningor drop/create the db and run stellar-horizon db init.Alternatively, if you do not need to free up old history tables, you can effectively stop here, anytime changes or enablement of filter rules are done, the history tables will immediately reflect filtered data per those latest rules from the time the filter config is updated and forward.If starting with a fresh DB, decide if you want to re-run ingestion from the earliest ledger # related to the whitelisted entities to populate history for just the allowed data from filters.Tip: To find this ledger number, you can check for the earliest transaction of the Account issuing that asset.Also consider running parallel workers to speed up the process.Optional: When re-ingestion is finished, run an ingestion gap fill stellar-horizon db fill-gaps to fill any gaps that may have been missed.Verify that your data is thereDo a spot check of Accounts that should be automatically be ingested against a full history Horizon instance such as SDF Horizon","metadata":{"source":"https://developers.stellar.org/docs/run-api-server/ingestion-filtering","title":"Ingestion Filtering","contentLength":1123}},{"pageContent":"OverviewWhat is Hubble?​Hubble is an open-source, publicly available dataset that provides a complete historical record of the Stellar network. Similar to Horizon, it ingests and presents the data produced by the Stellar network in a format that is easier to consume than the performance-oriented data representations used by Stellar Core. The dataset is hosted on BigQuery–meaning it is suitable for large, analytic workloads, historical data retrieval and complex data aggregation. Hubble should not be used for real-time data retrieval and cannot submit transactions to the network. For real time use cases, we recommend running an API server.This guide describes when to use Hubble and how to connect. To view the underlying data structures, queries and examples, use the Viewing Metadata and Optimizing Queries tutorials.Why Use Hubble?​Some questions are hard to answer with the Horizon API and its underlying PostgreSQL database. This is because its infrastructure is optimized for quick database reads and writes so that it can process online transactions. Horizon can accurately store the results of these smaller transactions, however it sacrifices the ability to execute complex queries easily. The Stellar Network’s data footprint has also increased exponentially, which is creating space constraints and performance issues for Horizon instances that store the full historical record.This is where Hubble comes in. It is optimized to execute complex queries and scan large amounts of data. Hubble can store orders of magnitude more data than Horizon and will not run into the same storage constraints. Queries that require pagination in Horizon or timeout can be returned in a single query. Hubble empowers users to explore, analyze, and derive meaningful conclusions from the data without the burden of maintaining a database.Users should be aware of the following limitations:Hubble is read-only; it cannot interact with the Stellar Network.The database is updated in intraday batches. There is no guarantee for same-day data availability.The SDF hosts a public instance of Hubble, and end users incur the cost to execute queries. Visit the BigQuery Pricing Page to learn more.Why We Chose BigQuery​BigQuery is Google Cloud’s data warehouse that comes with some key features that fulfill Stellar’s analytic needs.First, BigQuery allows anyone to make a dataset publicly available. This means that the SDF can contribute open source repositories to build and maintain a data warehouse and also host a public instance.BigQuery also separates storage from compute, which makes it sustainable to host a public instance. The maintainer only has to pay the cost of storage without incurring the cost of the analytics running on the dataset.Most importantly, BigQuery is the de facto platform for blockchain datasets. By selecting BigQuery, Stellar Network data is located with other blockchain data, which allows for cross-chain analytics.","metadata":{"source":"https://developers.stellar.org/docs/accessing-data/overview","title":"Overview","contentLength":469}},{"pageContent":"ConnectingBigQuery offers multiple connection methods to Hubble. This guide details three common methods:BigQuery UI - analysts that need to perform ad hoc analysis using SQLBigQuery SDK - developers that need to integrate data into applicationsLooker Studio - business people that need to visualize dataPrerequisites​To access Hubble, you will need a Google Cloud Project with billing and the BigQuery API enabled. For more information, please follow the instructions provided by Google Cloud.Google does provide a BigQuery Sandbox for free that allows users to explore datasets in a limited capacity.BigQuery UI​From a browser, open the crypto-stellar.crypto_stellar dataset.This will open the public dataset crypto_stellar, where you can browse its contents in the Explorer pane.Click the star icon in the Explorer pane. This will favorite the dataset for you. More detailed information about starring resources can be found here.Copy and paste the following example query in the Editor:This query will return the XLM balances for all Stellar wallet addresses, ordered from largest to smallest amounts.BigQuery SDK​There are multiple BigQuery API Client Libraries available.The following example uses Python to access the Hubble dataset. Use this guide for help setting up a python development environment.Install the client library locally, and configure your environment to use your Google Cloud Project:Use the Python Interpreter to run the example below to list the tables available in Hubble:Run the example below to run a query and print the results:There are various ways to extract and load data using BigQuery. See the BigQuery Client Documentation for more information.Looker Studio​Looker Studio is a business intelligence tool that can be used to connect to and visualize data from the Hubble dataset.To connect Hubble as a data source:Open Looker StudioClick on Create > Data SourceSearch for the BigQuery connector(Optional) Change the name of the data source at the top of the webpageClick Shared Projects > Select your Google Cloud ProjectEnter crypto-stellar as the Shared Project nameClick on the Dataset crypto_stellarSelect the desired table to connectClick CONNECT on the top right of the webpage.And you're connected!General information about Looker Studio can be found here.General information about connecting data sources can be found here.","metadata":{"source":"https://developers.stellar.org/docs/accessing-data/connecting","title":"Connecting","contentLength":371}},{"pageContent":"Viewing MetadataHubble publishes metadata which can help users determine which tables to query, how frequently the dataset updates, and general information about the dataset.There are two ways to access this information:BigQuery Explorer​When accessing Hubble from its starred link, the Explorer pane will load metadata about the crypto-stellar.crypto_stellar dataset.Use the Toggle to view the contents of the Dataset. Clicking a table name will load the following:Schema - detailed information about the table schema, including column definitions and data types. Viewing the schema helps write a SQL queryDetails - general information about the table itself, including partitioning, clustering and table size. Viewing details helps with query optimizationPreview - raw sample data from the table. The data presented is the equivalent of running a SELECT * statementINFORMATION_SCHEMA​BigQuery supports read-only, system-defined views that provide metadata information about BigQuery objects. The views can be queried via SQL from the BigQuery UI or Client Libraries.From the BigQuery Editor, the following query will list all tables in Hubble:If you want details on a particular table, you can return the table schema:More on the INFORMATION_SCHEMA can be found here.","metadata":{"source":"https://developers.stellar.org/docs/accessing-data/viewing-metadata","title":"Viewing Metadata","contentLength":190}},{"pageContent":"Optimizing QueriesHubble has terabytes of data to explore—that’s a lot of data! With access to so much data at your fingertips, it is crucial to performance-tune your queries.One of the strengths of BigQuery is also its pitfall: you have access to tremendous compute capabilities, but you pay for what you use. If you fine-tune your queries, you will have access to powerful insights at the fraction of the cost of maintaining a data warehouse yourself. It is, however, easy to incur burdensome costs if you are not careful.Best Practices​Pay attention to table structure.​Large tables are partitioned and clustered according to common access patterns. Prune only the partitions you need, and filter or aggregate by clustered fields when possible.Joining tables on strings is expensive. Refrain from joining on string keys if you can utilize integer keys instead.Read the docs on Viewing Metadata to learn more about table metadata.Example - Profiling Operation Types​Let’s say you wanted to profile the types of operations submitted to the Stellar Network monthly.The history_operations table is partitioned by batch_run_date and clustered by transaction_id, source_account and type. Query costs are greatly reduced by pruning unused partitions. In this case, you could filter out operations submitted before 2023. This reduces the query cost by 4x.Switching the aggregation field to type, which is a clustered field, will cut costs by a third:Performance SummaryBy pruning partitions and aggregating on a clustered field, the query processing costs reduce by a factor of 8.Bytes ProcessedCostOriginal Query408.1 GB$2.041Improved Query 183.06 GB$0.415Improved Query 254.8 GB$0.274Be as specific as possible.​Do not write SELECT * statements unless you need every column returned in the query response. Since BigQuery is a columnar database, it can skip reading data entirely if the columns are not included in the select statement. The wider the table is, the more crucial it is to select only what you need.Example - Transaction Fees​Let’s say you needed to view the fees for all transactions submitted in May 2023. What happens if you write a SELECT *?This query is estimated to cost almost $4!If you only need fee information, you can filter down the data, reducing the query costs by a factor of 50x:Performance SummaryHubble stores wide tables. Query performance is greatly improved by selecting only the data you need. This principle is critical when exploring the operations and transactions tables, which are the largest tables in Hubble.Bytes ProcessedCostOriginal Query769.45 GB$3.847Improved Query16.6 GB$0.083Filter early.​When writing complex queries, filter the data as early as possible. Push WHERE and GROUP BY clauses up in the query to reduce the amount of data scanned.Push transformations and mathematical functions to the end of the query when possible. Functions like TRIM(), CAST(), SUM(), and REGEXP_* are resource intensive and should only be applied to final table results.Estimating Costs​If you need to estimate costs before running a query, there are several options available to you:BigQuery Console​The BigQuery Console comes with a built-in query validator. It verifies query syntax and provides an estimate of the number of bytes processed. The validator can be found in the upper right hand corner of the Query Editor, next to the green checkmark.To calculate the query cost, convert the number of bytes processed into terabytes, and multiply the result by $5:(estimated bytes read / 1TB) * $5Paste the following query into the Editor to view the estimated bytes processed.The validator estimates that 51.95MB of data will be read.0.00005195 TB * $5 = $0.000259. That’s a cheap query!dryRun Config Parameter​If you are submitting a query through a BigQuery client library, you can perform a dry run to estimate the total bytes processed before submitting the query job.There are also IDE plugins that can approximate cost.For more information regarding query costs, read the BigQuery documentation.","metadata":{"source":"https://developers.stellar.org/docs/accessing-data/optimizing-queries","title":"Optimizing Queries","contentLength":668}},{"pageContent":"OverviewThe Stellar Disbursement Platform (SDP) is a tool built for organizations to make bulk payments to a group of recipients over the Stellar network. The full step-by-step process usually looks something like the following after the SDP is deployed and organizational users have been set up:The organization funds the SDP’s distribution account with a Stellar-based asset (e.g. USDC)An administrator logs in to the SDP’s dashboard and uploads a CSV file containing the payment information to initiate a new disbursementThe SDP sends a text message to every first-time recipient in the CSV inviting them to download a Stellar-enabled wallet applicationMeanwhile, the SDP immediately begins making payments to each recipient that has already registered a wallet through a prior paymentEach first-time recipient clicks a deep link to download the Stellar-enabled wallet application chosen by the organization for this disbursement, downloads the app, and goes through the wallet sign-up processOnce the recipient has signed up and their Stellar account has been created, the wallet immediately authenticates with the SDP using parameters from the deep link and opens the SDP registration web view for the recipient to complete verificationThe user confirms their identity by providing an OTP code sent to their phone number and an additional piece of verification information for security purposes. The SDP supports three different types of verification information: Date of Birth, Personal PIN, and National ID. This information is input by the recipient in a web flow and passes directly to the SDP, meaning the wallet does not need to process or store this information.The SDP verifies the recipient’s information. If it matches the information from the CSV, the SDP automatically makes the payment to the recipient’s Stellar accountGraphic representation of flow of funds:","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/overview","title":"Overview","contentLength":300}},{"pageContent":"Design and ArchitectureThe Stellar Disbursement Platform consists of four services deployed together:Dashboard: the user interface administrators use to initiate and track the progress of disbursementsSDP Core Service: the core backend service that performs several functions:Dashboard API: the API used by the front-end UI for all disbursement requests. The API is documented hereMessaging Service: a recurring process that sends text messages to users prompting them to download the wallet selected for a particular disbursement and verify their phone with an OTPWallet Registration UI: a web application that collects and verifies the recipient’s OTP code and verification information via Stellar’s SEP-24: Hosted Deposit and Withdrawal protocolAnchor Platform Service: the API server that the wallet uses to authenticate and initiate the recipient’s registration process through the SEP-24 deposit flowTransaction Submission Service: the service that submits all payment transactions to the Stellar network. This service is designed to maximize payment throughput, handle queuing, and graceful resubmission/error handlingDependencies​Container Orchestration: the SDP is packaged as Docker containers and can be deployed to Kubernetes or AWS Fargate. SDF provides a Helm Chart for KubernetesPostgres: the SDP uses a Postgres database server for all of its servicesTwilio or AWS SNS and SES: the SDP’s messaging service uses SMS messages via Twilio or AWS SNS and administrative emails for organization account setup and recovery via AWS SESStellar Accounts:Distribution Account: the SDP requires access to a funded Stellar account to make payments to the recipientSEP-10 Auth Account: the SDP requires a Stellar account for the mutual authentication protocol SEP-10: Stellar Web Authentication used to connect to wallet applicationsArchitecture Diagram​","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/design-and-architecture","title":"Design and Architecture","contentLength":273}},{"pageContent":"Getting StartedIn this guide, you will learn to:create and fund a distribution account for making paymentsset up an instance of the Stellar Disbursement Platform (SDP) locallycreate login credentials for users of the SDPset up a Stellar account to accept funds as a receivermake your first disbursementregister your receiver account with the SDPcheck your account balance after receiving paymentBy the end of this guide, you'll have a clear understanding of the Stellar Disbursement Platform's functionality and a working local setup ready for development or testing.Note that while we'll be using USDC and the Demo Wallet in this guide, other Stellar assets and wallets can be used in development or production.Create and Fund a Distribution Account​You'll need a minimum of two accounts when using the Stellar Disbursement Platform, a distribution and receiver account. We'll create the distribution account now and will create the receiver account while making our first disbursment.Go to the Stellar Demo Wallet and select \"Generate keypair for new account\"Select the \"Create account\" button next to the public key to fund your account with XLMSelect the \"Select from preset assets\" button, and select USDCFinally, select \"Add trustline\" to enable payments of USDCNow that we have an account that can send & receive USDC, lets fund it with enough USDC for our first disbursement. You can fund your distribution account from any liquidity source of Stellar USDC but here's how do it through the Circle Sandbox and Stellar Laboratory.Create a Circle Sandbox accountOnce you're at the dashboard, Select \"Get API Key\", and copy it to your clipboardGo to the Circle Sample App and enter your API key after selecting the settings icon in the top right cornerSelect \"Charge Flow\", then \"Prefill Form\", and select a card to use (it doesn't matter which)Enter the amount you'd like to purchase, then select \"Make Payment\"This will fund your Circle Sandbox Account with USDC. You can repeat the process above when you run out or the test network resets, which happens quarterly.Your USDC should appear in your account within a few minutes, which you can check using the balances endpoint. Once funded, you can send it to your distribution account created earlier.Select the icon in the top left, then \"Payouts API\", and finally \"POST /transfers\"Select \"Get Master Wallet ID\" to load the wallet funded with USDCEnter the amount you'd like to sendSelect the \"blockchain\" destination type and then \"XLM\"Paste the public key of the account you created with the demo wallet earlierSelect \"Make API Call\"Circle will submit payment of USDC to the Stellar test network and you should receive funds in your demo wallet account almost immediately!You can also acquire USDC through the Stellar Laboratory if you prefer. Before starting, make sure your demo wallet account is funded with XLM and has a trustline to USDC. Build a transaction in the Laboratory with your demo wallet account as the source account. Create a Path Payment Strict Send operation with the same account as the destination account. Use XLM (native) as the sending asset and USDC issued by GBBD47IF6LWK7P7MDEVSCWR7DPUWV3NY3DTQEVFL4NAT4AQH3ZLLFLA5 as the destination asset. You can set your preferred minimum destination amount based on how much XLM you send but the amount isn't important in testnet. A very low minimum will ensure the trade. Sign the transaction and submit to the network.USDC will arrive in your demo wallet account within seconds! Refresh the account on the demo wallet page to see the new balance.Run the SDP Locally​First you'll need to clone the project.Before we run the SDP, lets replace the private key configured for the distribution account with the one we created with the demo wallet earlier.Copy the secret key from the demo wallet, and replace the following value in docker-compose-tss.ymlCopy the public key from the demo wallet, and replace the following value in docker-compose-sdp-anchor.ymlThen build it using the pre-defined docker compose files.You should now have the Stellar Disbursement Platform running locally on port 3000. However, you won't be able to log in until you create a user.Create an Organization Owner​We need to create an organization owner account with privileges (or role) to use the SDP. We will use the SDP CLI to add the user. Connect to the sdp-api container and create an owner account.The command will ask you to define a password and then create the user.Log In​Now that you have created an owner account, navigate to the dashboard by opening a browser to localhost:3000 and login with the account you just created.Click the Sign in button and the SDP Dashboard will open. You will have no disbursements data at this point.Create Your First Disbursement​Create your first disbursement by clicking the New Disbursement button. Use Demo Wallet as your wallet and USDC as your asset. You can choose whatever values you like for Country and Name. Then upload your disbursement file with receiver information. You can download the template and update the values within it.phone: E164-formatted phone number of the receiverid: a unique identifier for the receiver, ensuring the receiver is only listed once per fileamount: the amount to sendverification: the data to verify. Currently built to verify date of birth.Review and confirm the disbursement.Verify Your Identity​When a disbursement is created, the SDP attempts to send SMS messages to receivers using either Twilio or AWS SNS. This message includes a link to the wallet application selected when creating the disbursement, and should direct the receiver to install the wallet app, go through the wallet's onboarding flow, and finally register with the SDP. However, neither service is configured by default, so the SDP will not send an SMS message to the phone numbers listed in the CSV uploaded in the previous step. You can still see the message in the sdp-api container logs.Check out the Email and SMS Messages section to learn how to configure messaging in the SDP. When you do, and another disbursement is created, you should get a message like the following.Create a Receiver Account​Clicking on the link within the SMS message will bring you back to the Stellar Demo Wallet, where you'll need to create another account to receive the USDC. Follow the same process described earlier to create the account and add a USDC trustline.Initiate SEP-24 Webflow​Now we'll need to connect the demo wallet to the SDP instance running locally. To do that, select the pencil icon next to \"centre.io\" below your USDC balance and enter \"localhost:8080\".In the \"Select Action\" dropdown, select \"SEP-24 Deposit\" to initiate a SEP-24 webflow, which triggers the User Registration process to link the new wallet to the phone number in the SDP.A SEP-24 interactive window will appear. This simulates the wallet application popup you would see on your mobile phone. Enter the phone number from the disbursement CSV.Next, enter the passcode and birthday that you used in the payment file. Note: use 000000 for this example (or 999999 if you want to see an error response).The webflow provides a message indicating your successful registration, which is the trigger for the SDP to send the payment. You should receive your payment from the SDP shortly.Check Your Balance​Refresh your account. The Demo Wallet should now show a balance of 2 USDC sent from the SDP (or however much was defined in the CSV file).Keep an eye on the dashboard until the payment status reaches Success. If everything was set up correctly, your money should be disbursed successfully.Next Up: Updating Application Secrets​Now that you've been able to make a disbursement, lets go back to our docker compose files and update some values. This is an important step before going to production. We'll be updating encryption keys and application secrets.Email and SMS Messages​The Stellar Disbursement Platform sends SMS messages and emails to receivers and users, respectively. For SMS messages, the Stellar Disbursement Platform supports Twilio, AWS SNS, and a dry run mode that just logs the messages. For emails, it supports AWS SES and dry run.These services can be selected through the SMS_SENDER_TYPE and EMAIL_SENDER_TYPE configurations. When selecting Twilio or AWS services, you'll need to fill their service-specific configuration as well. Here's an example of what the setup might look like if you're using both Twilio and AWS:Authentication​Wallets authenticate with the Stellar Disbursement Platform using a mutual authentication protocol, where both the SDP and wallet prove they are in possession of their Stellar accounts by signing a payload exchanged between themselves. Once this process is complete, a JWT is provided to the wallet to use in future requests. Additionally, the SDP's microservices uses authentication tokens to communicate between themselves, and to encrypt user passwords. We need to provide updated values for all these use cases.In docker-compose-sdp-anchor.yml, update the following:There are many other configuration values to update when moving to a production environment, such as database credentials, URLs, and more.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/getting-started","title":"Getting Started","contentLength":1547}},{"pageContent":"Dashboard HomeThe main page of the dashboard contains a summary of recent disbursement activity and key performance metrics.This includes:Successful payment rate: The percentage of payments completed successfully (pending payments are not counted as successful).Successful payments: The total number of payments that have been successfully made.Failed payments: The total number of payments that failed to process.Remaining payments: The total number of payments that are scheduled but haven't been processed yet.Total disbursed: The total amount of funds successfully sent to receivers by an organization over time.Individuals: The total number of individuals who are set to receive disbursements.Wallets: The total number of wallets used within the SDP. This usually equals the number of individuals but it is possible for each person to have more than one wallet.On the left side of the Stellar Disbursement Platform dashboard is the organization logo and tabs to help you navigate through the platform.They include:Home: This is the main dashboard that provides an overview of your organization’s activities.Disbursements: This section shows you the history and details of all disbursements.Receivers: Lists of individuals who are set to receive disbursements.Payments: Here you can find the history and granular details of all payments.Wallets: Information related to your organization’s wallet, the source of funds for your disbursements.Analytics: Data visualization tools to help you analyze your disbursements and payments.Profile: Manage your personal and organizational information.Settings: Adjust the settings of the SDP according to your preference.The dashboard also shows a Recent Disbursements list, providing a quick snapshot of your most recent disbursements.Each entry shows:Disbursement Name: The unique name given by your organization to the disbursement operation.Total payments: Total number of payments within the specific disbursement.Successful: Number of payments that have been successfully sent from the SDP Distribution Wallet to receiver wallets so far.Failed: Number of payments that failed to process.Remaining: Number of payments that are scheduled but haven't been processed yet, usually because the receiver has not yet set up a wallet.Created at: The time and date the disbursement was created, displayed in your local timezone.Total amount: The total value of the disbursement in the appropriate asset.Amount disbursed: The amount of the disbursement that has been successfully paid out so far.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/user-interface/dashboard-home","title":"Dashboard Home","contentLength":389}},{"pageContent":"DisbursementsThe Disbursements page provides a paginated list of all disbursements, detailing each disbursement's status and related payment information.The page contains the following:Drafts: Click the Drafts button at the top right to go to a list of disbursements that have been created but not yet submitted.New disbursement: Click the New Disbursement button to start the process of creating a new disbursement.Search by disbursement name: Input the name of a disbursement to quickly find specific details.Filter: Allows you to narrow down the disbursement list based on specific criteria like status or creation date.Export: Use this option to download the disbursement data in CSV format.Disbursement detail: Each disbursement is displayed with the following details:Disbursement name: The unique name assigned to the disbursement by your organization.Total payments: The total number of payments within the disbursement.Successful: The number of payments within the disbursement that have been processed successfully from the distribution account to registered wallets.Failed: The number of payments that failed during processing.Remaining: The number of payments that are yet to be processed.Created at: The date and time when the disbursement was created.Total amount: The total value of the disbursement in the appropriate asset.Amount disbursed: The amount of the disbursement that has already been paid out.You can click into an individual disbursement to see its details, including a full list of receivers and payments.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/user-interface/disbursements","title":"Disbursements","contentLength":236}},{"pageContent":"ReceiversThe Receivers page displays a list of individuals set to receive payments, with wallet information and payment history. This information allows you to track and manage the payments made to each receiver, and provides a snapshot of each receiver's interaction with a disbursement.The Receivers page includes the following:Search and Filter - At the top of the Receivers page, there are several tools available to help you find specific information:Search by phone number: Enter the phone number of a receiver to quickly find their information.Filter: Use this tool to narrow down the list of receivers based on specific criteria.Export: This allows you to download the receiver data in CSV format.Receiver Details: Each receiver is listed with the following details:Phone number: The receiver's phone number, which serves as a unique identifier within the SDP.Wallet provider(s): The provider of the receiver's digital wallet (usually a non-custodial app on a person’s phone).Wallets registered: The number of wallets registered and successfully linked to the SDP per receiver. A dash (\"-\") indicates no wallet has been registered.Total payments: The total number of payments intended for the receiver.Successful: The number of payments that have been successfully sent to the receiver’s wallet.Created at: The time and date the receiver was created in the system, displayed in your local timezone.Amount(s) received: The total amount the receiver has successfully received in the appropriate asset(s).You can click into an individual receiver to see their details, including their linked wallets and full payments history.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/user-interface/receivers","title":"Receivers","contentLength":263}},{"pageContent":"PaymentsThe Payments page provides a list of all payments, detailing each payment's status and related information.The Payments page includes:Search by payment ID: Enter a payment ID to find specific payment details quickly.Filter: This tool allows you to narrow down the payment list based on specific criteria.Export: This option lets you download payments data in CSV format.Payment Details: Each payment is listed with the following details:Payment ID: A unique identifier assigned to each payment.Wallet address: The digital wallet address where the payment is sent. A dash (\"-\") signifies that the wallet address is not yet set. The payment cannot be made until the receiver wallet is created and linked in the SDP.Disbursement name: The name of the disbursement associated with the payment.Completed at: The date and time when the payment was completed. A dash (\"-\") signifies that the payment has not yet been completed.Amount: The value of the payment in the appropriate asset.Status: The current status of the payment. This can be \"Success\" if the payment has been completed, “Pending” if the payment is currently processing on the Stellar network, or \"Ready\" if the payment is yet to be processed.You can click into an individual payment to see its details, including a granular status history and Stellar blockchain details.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/user-interface/payments","title":"Payments","contentLength":219}},{"pageContent":"WalletsThe Wallets page provides detailed information about your distribution account, which is the primary Stellar account from which your disbursements are made.The Wallets page includes the following:Distribution account public key: This is your unique identifier for your distribution account on the Stellar network. You use this public key to receive funds in your distribution account.Balance: This section displays the current balance of different digital assets in your distribution account:USDC, EUROC, etc: This is the current balance available for making payments within a disbursement.XLM: This is the balance of Stellar Lumens. This is used to fund the distribution account (base reserve) and transaction fees associated with making payments. This is for informational purposes and is not the source of funds for disbursements. In general, you do not need to worry about maintaining this, as Stellar network fees are very low.Adding Funds​Add funds to your distribution account: You can deposit Stellar-based digital assets into your distribution account by sending them to the provided public key. Make sure your account has a trustline to the asset before you send funds. As a general principle, do not use your distribution account as a long-term holding place for money. It is meant to be a pass-through wallet to fund disbursements.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/user-interface/wallets","title":"Wallets","contentLength":215}},{"pageContent":"AnalyticsThe Analytics page provides comprehensive insights into various aspects of financial transactions, enabling the user to track and understand key payment-related metrics. As more metrics and statistics become available, additional tiles will be added to this screen. The page displays information such as the successful payment rate, the total number of successful payments, the number of failed payments, and the number of remaining payments. Additionally, it shows the total amount disbursed, the average amount per transaction, the total amount in USDC, and the number of individuals and wallets involved in the transactions.In more detail:The \"Successful payment rate\" indicates the percentage of payments processed successfully out of total attempted payments.\"Successful payments\" shows the count of all transactions that have been completed successfully.\"Failed payments\" reveals the number of transactions that didn't go through, which can help identify issues with the payment process.\"Remaining payments\" provides the number of transactions that are yet to be processed.\"Total disbursed\" offers information on the total amount of funds that have been sent out.The \"Average amount\" offers an average value of all the transactions that have taken place in USDC.\"USDC\" reveals the total amount of funds in the system, denominated in USDC.\"Individuals\" represents the number of people involved in these transactions.\"Wallets\" indicates the number of unique digital wallets involved in the transactions.","metadata":{"source":"https://developers.stellar.org/docs/stellar-disbursement-platform/user-interface/analytics","title":"Analytics","contentLength":226}},{"pageContent":"Channel AccountsChannel accounts provide a method for submitting transactions to the network at a high rate.An account’s transactions always need to be submitted to the network in increments of one sequence number (unless minimum sequence number preconditions are set). This can cause problems if you are submitting transactions at a high rate, as they can potentially reach Stellar Core out of order and will then bounce with a bad sequence error.To avoid this, you can create separate channel accounts that can be used as the source account for the transaction and use the account holding the assets as the base account or the source account for the individual operations in the transaction. In this scenario, the assets will come out of the base account, and the sequence number and fees will be consumed by the channel account.Channels take advantage of the fact that the source account of a transaction can be different than the source account of the operations inside the transaction. With this setup, you can make as many channels as you need to maintain your desired transaction rate.You will, of course, have to sign the transaction with both the base account key and the channel account key.For example:","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/channel-accounts","title":"Channel Accounts","contentLength":206}},{"pageContent":"Claimable BalancesClaimable balances were introduced in CAP-0023 and are used to split a payment into two parts.Part 1: sending account creates a payment, or ClaimableBalanceEntry, using the Create Claimable Balance operationPart 2: destination account(s), or claimant(s), accepts the ClaimableBalanceEntry using the Claim Claimable Balance operationClaimable balances allow an account to send a payment to another account that is not necessarily prepared to receive the payment. They can be used when you send a non-native asset to an account that has not yet established a trustline, which can be useful for anchors onboarding new users. A trustline must be established by the claimant to the asset before it can claim the claimable balance, otherwise, the claim will result in an op_no_trust error.It is important to note that if a claimable balance isn’t claimed, it sits on the ledger forever, taking up space and ultimately making the network less efficient. For this reason, it is a good idea to put one of your own accounts as a claimant for a claimable balance. Then you can accept your own claimable balance if needed, freeing up space on the network.Each ClaimableBalanceEntry is a ledger entry, and each claimant in that entry increases the source account’s minimum balance by one base reserve.Once a ClaimableBalanceEntry has been claimed, it is deleted.Operations​Create Claimable Balance​For basic parameters, see the Create Claimable Balance entry in our List of Operations section.Additional parameters​Claim_Predicate_ Claimant — an object that holds both the destination account that can claim the ClaimableBalanceEntry and a ClaimPredicate that must evaluate to true for the claim to succeed.A ClaimPredicate is a recursive data structure that can be used to construct complex conditionals using different ClaimPredicateTypes. Below are some examples with the Claim_Predicate_ prefix removed for readability. Note that the SDKs expect the Unix timestamps to be expressed in seconds.Can claim at any time - UNCONDITIONALCan claim if the close time of the ledger, including the claim is before X seconds + the ledger close time in which the ClaimableBalanceEntry was created - BEFORE_RELATIVE_TIME(X)Can claim if the close time of the ledger including the claim is before X (Unix timestamp) - BEFORE_ABSOLUTE_TIME(X)Can claim if the close time of the ledger, including the claim is at or after X seconds + the ledger close time in which the ClaimableBalanceEntry was created - NOT(BEFORE_RELATIVE_TIME(X))Can claim if the close time of the ledger, including the claim is at or after X (Unix timestamp) - NOT(BEFORE_ABSOLUTE_TIME(X))Can claim between X and Y Unix timestamps (given X < Y) - AND(NOT(BEFORE_ABSOLUTE_TIME(X)), BEFORE_ABSOLUTE_TIME(Y))Can claim outside X and Y Unix timestamps (given X < Y) - OR(BEFORE_ABSOLUTE_TIME(X), NOT(BEFORE_ABSOLUTE_TIME(Y))ClaimableBalanceID ClaimableBalanceID is a union with one possible type (CLAIMABLE_BALANCE_ID_TYPE_V0). It contains an SHA-256 hash of the OperationID for Claimable Balances.A successful Create Claimable Balance operation will return a Balance ID, which is required when claiming the ClaimableBalanceEntry with the Claim Claimable Balance operation.Claim Claimable Balance​For basic parameters, see the Claim Claimable Balance entry in our List of Operations section.This operation will load the ClaimableBalanceEntry that corresponds to the Balance ID and then search for the source account of this operation in the list of claimants on the entry. If a match on the claimant is found, and the ClaimPredicate evaluates to true, then the ClaimableBalanceEntry can be claimed. The balance on the entry will be moved to the source account if there are no limit or trustline issues (for non-native assets), meaning the claimant must establish a trustline to the asset before claiming it.Clawback Claimable Balance​This operation claws back a claimable balance, returning the asset to the issuer account, burning it. You must claw back the entire claimable balance, not just part of it. Once a claimable balance has been claimed, use the regular clawback operation to claw it back.Clawback claimable balances require the claimable balance ID.Learn more about clawbacks in our Clawback Encyclopedia Entry.Example​The below code demonstrates via both the JavaScript and Go SDKs how an account (Account A) creates a ClaimableBalanceEntry with two claimants: Account A (itself) and Account B (another recipient).Each of these accounts can only claim the balance under unique conditions. Account B has a full minute to claim the balance before Account A can reclaim the balance back for itself.Note: there is no recovery mechanism for a claimable balance in general — if none of the predicates can be fulfilled, the balance cannot be recovered. The reclaim example below acts as a safety net for this situation.At this point, the ClaimableBalanceEntry exists in the ledger, but we’ll need its Balance ID to claim it, which can be done in several ways:The submitter of the entry (Account A in this case) can retrieve the Balance ID before submitting the transaction;The submitter parses the XDR of the transaction result’s operations; orSomeone queries the list of claimable balances.Either party could also check the /effects of the transaction, query /claimable_balances with different filters, etc. Note that while (1) may be unavailable in some SDKs as it's just a helper, the other methods are universal.With the Claimable Balance ID acquired, either Account B or A can actually submit a claim, depending on which predicate is fulfilled. We’ll assume here that a minute has passed, so Account A just reclaims the balance entry.And that’s it! Since we opted for the reclaim path, Account A should have the same balance as what it started with (minus fees), and Account B should be unchanged.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/claimable-balances","title":"Claimable Balances","contentLength":941}},{"pageContent":"ClawbacksClawbacks were introduced in CAP-0035 and allow an asset issuer to burn a specific amount of a clawback-enabled asset from a trustline or claimable balance, effectively destroying it and removing it from a recipient’s balance.They were designed to allow asset issuers to meet securities regulations, which in many jurisdictions require asset issuers (or designated transfer agents) to have the ability to revoke assets in the event of a mistaken or fraudulent transaction or other regulatory action regarding a specific person or asset.Clawbacks are useful for:Recovering assets that have been fraudulently obtainedResponding to regulatory actionsEnabling identity-proofed persons to recover an enabled asset in the event of loss of key custody or theftOperations​Set Options​The issuer sets up their account to enable clawbacks using the AUTH_CLAWBACK_ENABLED flag. This causes every subsequent trustline established from the account to have the TRUSTLINE_CLAWBACK_ENABLED_FLAG set automatically.If an issuing account wants to set the AUTH_CLAWBACK_ENABLED_FLAG, it must have the AUTH_REVOCABLE_FLAG set. This allows an asset issuer to claw back balances locked up in offers by first revoking authorization from a trustline, which pulls all offers that involve that trustline. The issuer can then perform the clawback.Clawback​The issuing account uses this operation to claw back some or all of an asset. Once an account holds a particular asset for which clawbacks have been enabled, the issuing account can claw it back, burning it. You need to provide the asset, a quantity, and the account from which you’re clawing back the asset.Clawback Claimable Balance​This operation claws back a claimable balance, returning the asset to the issuer account, burning it. You must claw back the entire claimable balance, not just part of it. Once a claimable balance has been claimed, use the regular clawback operation to claw it back.Clawback claimable balances require the claimable balance ID.Set Trust Line Flag​Remove clawback capabilities on a specific trustline by removing the TRUSTLINE_CLAWBACK_ENABLED_FLAG via the SetTrustLineFlags operation.You can only clear a flag, not set it. So clearing a clawback flag on a trustline is irreversible. This is done so that you don’t retroactively change the rules on your asset holders. If you’d like to enable clawbacks again, holders must reissue their trustlines.Examples​Here we’ll cover the following approaches to clawing back an asset.Example 1: Issuing account (Account A) creates a clawback-enabled asset and sends it to Account B. Account B sends that asset to Account C. Account A will then clawback the asset from C. Example 2: Account B creates a claimable balance for Account C, and Account A claws back the claimable balance. Example 3: Account A issues a clawback-enabled asset to Account B. A claws back some of the asset from B, then removes the clawback enabled flag from the trustline and can no longer clawback the asset.Preamble: Issuing a Clawback-able Asset​First, we’ll set up an account to enable clawbacks and issue an asset accordingly.Properly issuing an asset (with separate issuing and distribution accounts) is a little more involved, but we’ll use a simpler method here.Also, note that we first need to enable clawbacks and then establish trustlines since you cannot retroactively enable clawback on existing trustlines.Example 1: Payments​With the shared setup code out of the way, we can now demonstrate how clawback works for payments. This example will highlight how the asset issuer holds control over their asset regardless of how it gets distributed to the world.In our scenario, Account A will pay Account B with 1000 tokens of its custom asset; then, B will pay Account C 500 tokens in turn. Finally, A will claw back half of C’s balance, burning 250 tokens forever. Let’s dive into the helper functions:These snippets will help us with the final composition: making some payments to distribute the asset to the world and clawing some of it back.After running our example, we should see the balances reflect the example flow:Notice that GCIHA (Account A, the issuer) holds none of the asset despite clawing back 250 from Account C. This should drive home the fact that clawed-back assets are burned, not transferred.(It may be strange that A never holds any tokens of its custom asset, but that’s exactly how issuing works: you create value where there used to be none. Sending an asset to its issuing account is equivalent to burning it, and auditing the total amount of an asset in existence is one of the benefits of properly distributing an asset via a distribution account, which we avoid doing here for example brevity.)Example 2: Claimable Balances​Direct payments aren’t the only way to transfer assets between accounts: claimable balances also do this. Since they are a separate payment mechanism, they need a separate clawback mechanism.We need some additional helper methods to get started working efficiently with claimable balances:Now, we can fulfill the flow: A pays B, who sends a claimable balance to C, who gets it clawed back by A. (Note that we rely on the makePayment helper from the earlier example.)After running preamble().then(examplePaymentClawback), we should see the balances reflect our flow:Example 3: Selectively Enabling Clawback​When you enable the AUTH_CLAWBACK_ENABLED_FLAG on your account, it will make all future trustlines have clawback enabled for any of your issued assets. This may not always be desirable as you may want certain assets to behave as they did before. Though you could work around this by reissuing assets from a “dedicated clawback” account, you can also simply disable clawbacks for certain trustlines by clearing the TRUST_LINE_CLAWBACK_ENABLED_FLAG on a trustline.In the following example, we’ll have an account (Account A, as before) issue a new asset and distribute it to a second account (Account B). Then, we’ll demonstrate how A claws back some of the assets from B, then clears the trustline and can no longer claw back the asset.First, let’s prepare the accounts (note that we are relying here on helper functions defined in the earlier examples):Now, let’s distribute some of our asset to Account B, just to claw it back. Then, we’ll clear the flag from the trustline and show that another clawback isn’t possible:Run the example (e.g. via preambleRedux().then(exampleSelectiveClawback)) and observe its result:","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/clawbacks","title":"Clawbacks","contentLength":1072}},{"pageContent":"Error HandlingIt’s important to anticipate errors your users may encounter as you develop on Stellar. In many tutorials throughout our developer documentation, we leave out error handling code to focus on the example. In this section, we will do the opposite and talk specifically about the errors.By the end of this section, you should be able to categorize errors and understand the best way to handle them in your application.There are two main parts to this section:Resolution strategies — recommended resolution strategies that apply to most error scenarios you may encounterManaging specific errors — a deeper dive into the errors themselves. Refer to this section if you have encountered a specific error and want a better understanding of its cause.For a fuller list of errors, see the Error section in our API documentation.Part 1: resolution strategies​Many actions interact with the Stellar network through the Horizon API, and these possible actions fall into two main categories: 1. Queries (any GET request, like to /accounts) and 2. Transaction submissions (a POST /transactions).There are many possible error codes when executing these actions, and you can typically handle these error codes using the following strategies:Request adjustments: adjusting the request to resolve structural errors with queries or transaction submissions. Suppose you’ve included a bad parameter, malformed your XDR, or otherwise didn’t follow the endpoint’s specification. In these cases, resolve the error by referencing the details or result codes of the error response.Retrying until success: this is the recommended way to work around latency or congestion issues encountered along the pipeline between your computer and the Stellar network, which can sometimes happen due to the nature of the distributed system.Adjusting the transaction: this can also resolve issues but must be done with extreme care. If one of the above scenarios is in effect, it can trigger destructive duplicate actions (like sending a payment twice).Let’s get into these strategies in more detail. We will mainly focus on the transaction submission category for each strategy since queries only return a read-only request.Request adjustments strategy​Queries​Many GET requests have specific parameter requirements, and while the SDKs can help enforce them, you can still pass invalid arguments (for example, an asset string that isn’t SEP-11 compatible) that error out every time. In this scenario, there’s nothing you can do aside from following the API specification. The extras field of the error response will often clue you in on where to look and what to look for.Note that the SDKs make it a point to distinguish an invalid request (as above) versus a missing resource (a 404 Not Found) (for example, the generic NetworkError versus a NotFoundError in the JavaScript SDK), where the latter might not be considered an error depending on your situation.Transaction submissions​Certain transaction submission failures also need adjustments to succeed. If the XDR is malformed, or the transaction is otherwise invalid, you’ll encounter a 400 Bad Request (for example, see excluding a source account). Both transactions and their operations can be easily malformed: look at the extras.result_codes field for details and cross-reference them with the appropriate result codes documentation to determine specifics.Transaction fees are also a safe adjustment. If you get a tx_insufficient_fee error, refer to the Insufficient Fees and Surge Pricing section later in this document.Retrying until success strategy​Transaction submissions​There are many possible scenarios (504 Timeouts, transient outages, congestion on the network) in which retrying your transaction submission is the only reasonable solution. However, only use this method after trying to make safe modifications to the transaction.There is no way to cancel a transaction after submitting it. So, successfully resubmitting your transaction has two considerations. 1. Time bounds. Time bounds are optional but recommended, as they put a time limit on the transaction- so either the transaction makes it onto the ledger or it times out depending on your time parameters. 2. If the transaction has already successfully made it to the ledger, Horizon will return any attempted resubmission. Only in cases where a transaction’s status is unknown (and thus will have a chance to make it on the ledger) will a resubmission to the network occur.If a transaction successfully makes it into the ledger, any attempted resubmitted transactions will be returned to you.Example scenario:You submit a transaction, and it enters the queue of the Stellar network, but Horizon crashes while giving you a response. Uncertain about the transaction status, you resubmit the transaction (with no changes!) until either a. Horizon comes back up to give you a reply or b. your time bounds are exceeded.There are only two possible results to this scenario: either the transaction makes it into the ledger (exactly once) and Horizon gives you the response, or the transaction never makes it out of the queue, and you receive the corresponding tx_too_late response.Example implementation:We assume the existence of a sleep implementation similar to the one here Be sure to integrate backoff into your retry mechanism. In our example error-handling code above, we implement a simple linear backoff, but there are plenty of recommendations for various other strategies. Backoff is important both for maintaining performance and avoiding rate-limiting issues.Adjusting the transaction- unsafe transaction adjustments strategy​Transaction submissions​Resubmitting an unchanged transaction (same operations, signatures, sequence number, etc.) is always safe to do. However, be careful when working around an error that does require changes to the transaction. It can cause duplicate transactions, which can cause problems (double payments, incorrect trustlines, and more).Example scenario: invalid sequence numbersThese errors typically occur when you have an outdated view of an account. This could be because multiple devices are using this account, you have concurrent submissions happening, or other reasons. The solution is relatively simple: retrieve the account details and try again with an updated sequence number.Despite the solution’s simplicity, things can go wrong fast if you don’t understand why the error occurred.Suppose you submit transactions from multiple places in your application simultaneously, and your user spammed the Send Payment button a few times in their impatience. If you send the exact same payment transaction for each tap, naturally, only one will succeed. The others will fail with an invalid sequence number (tx_bad_seq), and if you resubmit blindly with an updated sequence number (as we do above), these payments will also succeed, resulting in more than one payment being made when only one was intended. So, be very careful when resubmitting transactions that have been modified to work around an error.Part 2: managing specific errors​Here, we will cover specific errors commonly encountered during transaction submission and direct you to the appropriate resolution. We’ll start with a table of common errors and their codes and descriptions, then dive deeper into some specific ones.ResultCodeDescriptionFAILED-1One of the operations failed (see List of Operations for errors)TOO_EARLY-2Ledger closeTime before minTime value in the transactionTOO_LATE-3Ledger closeTime after maxTime value in the transactionMISSING_OPERATION-4No operation was specifiedBAD_SEQ-5Sequence number does not match source accountBAD_AUTH-6Too few valid signatures / wrong networkINSUFFICIENT_BALANCE-7Fee would bring account below minimum balance; see our section on Lumens for more infoNO_ACCOUNT-8Source account not foundINSUFFICIENT_FEE-9Fee is too small; see our section on Fees for more infoBAD_AUTH_EXTRA-10Unused signatures attached to transactionINTERNAL_ERROR-11An unknown error occurredNOT_SUPPORTED-12The transaction type is not supportedFEE_BUMP_INNER_FAILED-13The fee bump inner transaction failedBAD_SPONSORSHIP-14The sponsorship is not confirmedWe’ll do a deeper dive into the following errors:Timeouts: 504 TimeoutInsufficient fees and surge pricing: INSUFFICIENT_FEERate limiting: 429 Too Many RequestsInsufficient XLM balance: INSUFFICIENT_BALANCETimeouts​Horizon may send a 504 Timeout after transaction submission. Timeouts are not errors but warnings that your request hasn’t been fulfilled yet. This can happen because of the relationship between Horizon and Stellar Core- the network may take some time (5-10 mins during congestion) to accept the transaction. At the same time, Horizon needs to provide developers with a response within 30 seconds.Receiving a 504 for your transaction submission does not mean the transaction didn’t make it to the network. Continue with retries until you get a definitive response. If you continue to face timeouts on retries, consider using a fee-bump transaction to get into the ledger (after the time bounds expire) or increasing the maximum fee you’re willing to pay. Read up on Surge Pricing and Fee Strategies for more details.Insufficient fees and surge pricing​See the Surge Pricing and Fee Strategies Encyclopedia EntryRate limiting​If you’re using SDF’s public Horizon instance, you may get a 429 Too Many Requests error when exceeding the rate limits. If you’re encountering this frequently, it may be time to deploy your own Horizon instance!Insufficient XLM balance​Any transaction that would reduce an account’s balance to less than the minimum will be rejected with an INSUFFICIENT_BALANCE error. Likewise, lumen selling liabilities that would reduce an account’s balance to less than the minimum plus lumen selling liabilities will be rejected with an INSUFFICIENT_BALANCE error.For more on minimum balances, see our Lumens section.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/error-handling","title":"Error Handling","contentLength":1533}},{"pageContent":"FederationThe Stellar federation protocol maps Stellar addresses to an email-like identifier that provides more information about a given user. It’s a way for Stellar client software to resolve email-like addresses such as name*yourdomain.com into account IDs like: GCCVPYFOHY7ZB7557JKENAX62LUAPLMGIWNZJAFV2MITK6T32V37KEJU. Federated addresses provide an easy way for users to share payment details by using a syntax that interoperates across different domains and providers.Federated addresses​Stellar federated addresses are divided into two parts separated by the asterisk character (*): the username and the domain. For example: jed*stellar.org:jed is the usernamestellar.org is the domainThe domain can be any valid RFC 1035 domain name. The username is limited to printable UTF-8 with whitespace and the following characters excluded: <*,>.Note that the @ symbol is allowed in the username. This means you can use email addresses in the username of a federated address. For example: [email protected]*stellar.org.Supporting federation​To support federation, first, create a stellar.toml file, and publish it at https://YOUR_DOMAIN/.well-known/stellar.toml. Complete instructions for doing that can be found in the stellar.toml specification (aka SEP-1).In general, you will want to include any and all information about your Stellar integration in your stellar.toml. To support federation specifically, you need to add a FEDERATION_SERVER section to your stellar.toml file that tells other people the URL of your federation endpoint.For example: FEDERATION_SERVER=\"https://api.yourdomain.com/federation\"Note: your federation server must use https protocolOnce you’ve published the location of your federation server, implement federation url HTTP endpoint that accepts an HTTP GET request and issues responses of the form detailed below:To make it easier to set up a federation server, you can use the reference implementation designed to be dropped into your existing infrastructure.Federation requests​You can use the federation endpoint to look up an account ID if you have a Stellar address. You can also do reverse federation and look up a Stellar address from an account ID or a transaction ID. This is useful to see who has sent you a payment.Federation requests are http GET requests with the following form:?q=<string to look up>&type=<name,forward,id,txid>Supported types:Name Example: https://YOUR_FEDERATION_SERVER/federation?q=jed*stellar.org&type=nameForward Used for forwarding the payment to a different network or different financial institution. The other parameters of the query will vary depending on what kind of institution is the ultimate destination of the payment and what you as the forwarding anchor supports. Your stellar.toml file should specify what parameters you expect in a forward federation request. If you are unable to forward or the other parameters in the request are incorrect you should return an error to this effect. Example request: https://YOUR_FEDERATION_SERVER/federation?type=forward&forward_type=bank_account&swift=BOPBPHMM&acct=2382376Id Not supported by all federation servers. Reverse federation will return the federation record of the Stellar address associated with the given account ID. In some cases, this is ambiguous. For instance, if an anchor sends transactions on behalf of its users, the account id will be of the anchor, and the federation server won’t be able to resolve the particular user that sent the transaction. In cases like that, you may need to use txid instead. Example: https://YOUR_FEDERATION_SERVER/federation?q=GD6WU64OEP5C4LRBH6NK3MHYIA2ADN6K6II6EXPNVUR3ERBXT4AN4ACD&type=idTxid Not supported by all federation servers. Will return the federation record of the sender of the transaction if known by the server. Example: https://YOUR_FEDERATION_SERVER/federation?q=c1b368c00e9852351361e07cc58c54277e7a6366580044ab152b8db9cd8ec52a&type=txidFederation Response​The federation server should respond with an appropriate HTTP status code, headers, and a JSON response.You must enable CORS on the federation server so clients can send requests from other sites. The following HTTP header must be set for all federation server responses.Access-Control-Allow-Origin: *When a record has been found, the response should return 200 OK http status code and the following JSON body:If a redirect is needed, the federation server should return 3xx http status code and immediately redirect the user to the correct URL using the Location header.When a record has not been found 404 Not Found http status code should be returned. Every other http status code will be considered an error. The body should contain error details:Looking up federation provider via a home domain entry​Accounts may optionally have a home domain specified. This allows an account to programmatically specify the main federation provider for that account.Caching​You shouldn’t cache responses from federation servers. Some organizations may generate random IDs to protect their users’ privacy. Those IDs may change over time.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/federation","title":"Federation","contentLength":779}},{"pageContent":"Fee-bump TransactionsFee-bump transactions were introduced in CAP-0015 and enable an account to pay the transaction fees for an existing transaction without having to re-sign the transaction or manage sequence numbers.A fee-bump transaction is made of two parts:An inner transaction envelope with its signature(s)An outer transaction envelope with the fee-bump transaction and fee account signatureCommon use cases​You may want to consider using fee bumps when:You’re building a service where you want to cover user feesYou want to increase the fee on an existing transaction so it has a better chance of making it to the ledger during surge pricingYou need to adjust the fee on a pre-authorized transaction so it can make it to the ledger if minimum network fees have increasedAttributes​Existing transaction envelope (inner transaction)​Before creating a fee-bump transaction, you must first have a transaction wrapped with its signatures in a transaction envelope. We’ll call this transaction the inner transaction.Fee account​The account that will pay the fee for the fee-bump transaction. This account will incur the fee instead of the source account specified in the inner transaction. The sequence number is still taken from the source account, however.Fee​The maximum per-operation fee you’re willing to pay for the fee-bump transaction. The fee-bump transaction is one operation. Therefore, the total number of operations is equal to the number of operations in the inner transaction plus one.Read more about transaction fees in our Fees section.Replace-by-fee​You can apply a fee-bump transaction to increase a fee originating from your own account. However, if you submit two distinct transactions with the same source account and sequence number with the second transaction being a fee-bump transaction, the second transaction will replace the first transaction in the queue if and only if the fee bid of the second transaction is 10x the fee bid of the first transaction. This number may seem random, it is a deliberate design decision to limit DOS attacks without introducing too much complexity to the protocol.Fee-bump transaction envelope​When a fee-bump transaction is ready to be signed, it’s wrapped in a transaction envelope. This envelope contains the fee-bump transaction and the signature of the specified fee account.Validity of a fee-bump transaction​A fee-bump transaction goes through a series of checks in its lifecycle to determine validity. The following conditions must be met:Fee account — the fee account for the fee-bump transaction must exist on the ledger.FeeThe fee must be greater than or equal to the network minimum fee for the number of operations in the inner transaction, plus one for the fee bump.The fee must also be greater than or equal to the fee specified in the inner transaction.If the fee-bump transaction is taking advantage of the replace-by-fee, the fee must be 10x higher than the first transactionFee account signature — the fee-bump transaction envelope must contain a valid signature for the fee account. Additionally, the weight of that signature must meet the low threshold for the fee account, and the appropriate network passphrase must be part of the transaction hash signed by the fee account.Fee account balance — the fee account must have a sufficient XLM balance to cover the feeInner transaction — the inner transaction must be valid, which means it must meet the requirements described in the Validity of a Transaction section. If validation of the inner transaction is successful, then the result is FEE_BUMP_INNER_SUCCESS, and the validation results from the validation of the inner transaction appear in the inner result. If the inner transaction is invalid, the result is FEE_BUMP_INNER_FAILED, and the fee-bump transaction is invalid because the inner transaction is invalid.Application​The sole purpose of a fee-bump transaction is to get an inner transaction included in a transaction set. Since the fee-bump transaction has no side effects other than paying a fee — and at the time the fee is paid the outer transaction must have been valid (otherwise nodes would not have voted for it) — there is no reason to check the validity of the fee-bump transaction at apply time. Therefore, the sequence number of the inner transaction is always consumed at apply time. The inner transaction, however, will still have its validity checked at apply time.Every fee-bump transaction result contains a complete inner transaction result. This inner-transaction result is exactly what would have been produced had there been no fee-bump transaction, except that the inner fee will always be 0.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/fee-bump-transactions","title":"Fee-bump Transactions","contentLength":780}},{"pageContent":"Fees, Surge Pricing, and Fee StrategiesStellar requires a small fee for all transactions to prevent ledger spam and prioritize transactions during surge pricing. All fees are paid in lumens (XLM).Network fees on Stellar​The fee for a given transaction equals the number of operations in the transaction multiplied by the effective base fee for the given ledger (transaction fee = # of operations * effective base fee).Effective base fee: the fee required per operation for a transaction to make it to the ledger. This cannot be lower than 100 stroops per operation (the network minimum).Stroop: the smallest unit of a lumen, one ten-millionth of a lumen (.0000001 XLM).When you decide on a base fee for a transaction, you specify the maximum amount that you’re willing to pay per operation in that transaction. That does not necessarily mean that you’ll pay that amount, you will only be charged the lowest amount needed for your transaction to make it to the ledger. If network traffic is light and the number of submitted operations is below the network ledger limit (which is configured by validators, currently 1,000 ops per ledger on the pubnet and 100 ops per ledger on the testnet), you will only pay the network minimum (also configured by validators, currently 100 stroops).Alternatively, your transaction may not make it to the ledger if the effective base fee is higher than your base fee bid. When network traffic exceeds the ledger limit, the network enters into surge pricing mode, and your fee becomes a max bid. This amount can vary depending on network activity, but we recommend submitting a base fee of 100,000 stroops for consumer-facing applications. But it's up to you.Fees are deducted from the source account unless there is a fee-bump transaction that states otherwise. To learn about fee-bump transactions, see our Fee-Bump Transaction Encyclopedia EntryThe lumens collected from transaction fees go into a locked account and are not given to or used by anyone.Surge pricing​When the number of operations submitted to a ledger exceeds the network capacity (1,000 ops per ledger on the Pubnet; 100 ops per ledger on the Testnet), the network enters surge pricing mode. During this time, the network uses market dynamics to decide which submissions to include in the ledger — transactions that offer a higher fee per operation make it to the ledger first.If multiple transactions offer the same base fee during surge pricing, the transactions are shuffled randomly and the transactions at the top make the ledger. The rest of the transactions are pushed to the next ledger or discarded if they’ve been waiting for too long. If your transaction is discarded, Horizon will return a timeout error.The goal of the transaction pricing specification, which you can read in full here, is to maximize network throughput while minimizing transaction fees.Fee strategies​There are three primary methods to deal with fee fluctuations and surge pricing:Method 1: Set the highest fee you’re comfortable paying. This does not mean that you’ll pay that amount on every transaction- you will only pay what’s necessary to get you into the ledger. Under normal (non-surge) circumstances, you will only pay the standard fee even if you have a higher maximum fee set. This method is simple, convenient, and efficient but can still potentially fail.Method 2: Track fee fluctuations with the fee_stats endpoint. Use this to make specific, informed choices about the fee you’re comfortable paying. All three of the SDF-maintained SDKs allow you to poll the /fee_stats endpoint: Go, Java, JavaScript. This method provides reliable submissions but is more inefficient.Method 3: Use a fee-bump transactionSet the highest fee you’re comfortable paying​In general, it’s a good idea to choose the highest fee you’re willing to pay per operation for your transaction to make it to the ledger.Wallet developers may want to offer users a chance to specify their own base fee, though it may make more sense to set a persistent global base fee that’s above the market rate since the average user probably doesn’t care if they’re paying 0.8 cents or 0.00008 cents.Track fee fluctuations​In general, it is important to track fee costs. If network fees surge beyond what you’re willing to pay, consider waiting for activity to die down or periodically trying to resubmit the transaction with the same fee.If you want to match a fee error exactly, you may write something like this:There are more streamlined ways to combine errors, which we use below to demonstrate the (very) specific check.Example: suppose we want a fairly conservative fee-paying strategy- we’re only willing to pay a 10% higher fee than the average transaction paid.Fee-bumps on past transactions​Even with a liberal fee-paying policy, your transaction may fail to make it into the ledger due to insufficient funds or untimely surges. Fee-bump transactions can solve this problem. The following snippet shows you how to resubmit a transaction with a higher fee (as long as you have the original transaction envelope):Suppose you submit two distinct transactions with the same source account and sequence number, and the second transaction is a fee-bump transaction. In that case, the second transaction will be included in the transaction queue, replacing the first transaction if and only if the fee bid of the second transaction is at least 10x the fee bid of the first transaction.This value can typically be found in the fee_charged field of the transaction response under the tx_insufficient_fee error case.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/fees-surge-pricing-fee-strategies","title":"Fees, Surge Pricing, and Fee Strategies","contentLength":952}},{"pageContent":"InflationThe inflation operation is deprecated. Here’s why:Before Protocol 12, Stellar had a built-in inflation mechanism designed to allow account holders to collectively direct inflation-generated lumens toward projects built on Stellar.As the network evolved and grew, it became clear that inflation wasn’t working as intended — account holders either didn’t set their inflation destination or joined inflation pools to claim the inflation themselves. The operational costs associated with inflation payments continued to rise, and so CAP-26, a protocol change to disable inflation, was proposed, implemented, voted on by validators, and ultimately adopted as part of a network upgrade.For more information, you can read our blog here: Our Proposal to Disable Inflation","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/inflation","title":"Inflation","contentLength":118}},{"pageContent":"Ledger HeadersEvery ledger has a header that references the data in that ledger and the previous ledger. These references are cryptographic hashes of the content which behave like pointers in typical data structures but with added security guarantees. Think of a historical ledger chain as a linked list of ledger headers:[Genesis] <---- [LedgerHeader_1] <----- … <---- [LedgerHeader_n]The genesis ledger has a sequence number of 1. The ledger directly following a ledger with sequence number n has a sequence number of n+1.Ledger header fields​Version​The protocol version of this ledger.Previous ledger hash​Hash of the previous ledger.SCP value​During consensus, all the validating nodes in the network run SCP and agree on a particular value, which is a transaction set they will apply to a ledger. This value is stored here and in the following three fields (transaction set hash, close time, and upgrades).Transaction set hash​Hash of the transaction set applied to the previous ledger.Close time​When the network closed this ledger; UNIX timestamp.Upgrades​How the network adjusts overall values (like the base fee) and agrees to network-wide changes (like switching to a new protocol version). This field is usually empty. When there is a network-wide upgrade, the SDF will inform and help coordinate participants using the #validators channel on the Dev Discord and the Stellar Validators Google Group.Transaction set result hash​Hash of the results of applying the transaction set. This data is not necessary for validating the results of the transactions. However, it makes it easier for entities to validate the result of a given transaction without having to apply the transaction set to the previous ledger.Bucket list hash​Hash of all the objects in this ledger. The data structure that contains all the objects is called the bucket list.Ledger sequence​The sequence number of this ledger.Total coins​Total number of lumens in existence.Fee pool​Number of lumens that have been paid in fees. Note this is denominated in lumens, even though a transaction’s fee field is in stroops.Inflation sequence​Number of times inflation has been run. Note: the inflation operation was deprecated when validators voted to upgrade the network to Protocol 12 on 10/28/2019. Therefore, inflation no longer runs, so this sequence number no longer changes.ID pool​The last used global ID. These IDs are used for generating objects.Maximum number of transactions​The maximum number of operations validators have agreed to process in a given ledger. If more transactions are submitted than this number, the network will enter into surge pricing mode. For more about surge pricing and fee strategies, see our Fees, Surge Pricing, and Fee Strategies Encyclopedia Entry.Base fee​The fee the network charges per operation in a transaction. Calculated in stroops. See the Fees section for more information.Base reserve​The reserve the network uses when calculating an account’s minimum balance.Skip list​Hashes of ledgers in the past. Allows you to jump back in time in the ledger chain without walking back ledger by ledger. There are four ledger hashes stored in the skip list. Each slot contains the oldest ledger that is mod of either 50 5000 50000 or 500000 depending on index skipList[0] mod(50), skipList[1] mod(5000), etc.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/ledger-headers","title":"Ledger Headers","contentLength":551}},{"pageContent":"Liquidity on Stellar: SDEX and Liquidity PoolsUsers can trade and convert assets on the Stellar network with the use of path payments through Stellar’s decentralized exchange and liquidity pools.In this section, we will talk about the SDEX and liquidity pools. To learn about how these work together to execute transactions, see our Path Payments Encyclopedia Entry.SDEX​The Stellar network acts as a decentralized distributed exchange that allows users to trade and convert assets with the Manage Buy Offer and Manage Sell Offer operations. The Stellar ledger stores both the balances held by user accounts and orders that user accounts make to buy or sell assets.Order books​Stellar uses order books to operate its decentralized exchange.An order book is a record of outstanding orders on a network, and each record sits between two assets (wheat and sheep, for example). The order book for this asset pair records every account wanting to sell wheat for sheep and every account wanting to sell sheep for wheat. In traditional finance, buying is expressed as a “bid” order, and selling is expressed as an “ask” order (ask orders are also called offers).A couple of notes on order books on Stellar:The term “offers” usually refers specifically to ask orders. In Stellar, however, all orders are stored as selling- i.e., the system automatically converts bids to asks. Because of this, the terms “offer” and “order” are used interchangeably in the Stellar ecosystem.Order books contain all orders that are not acceptable to parties on either side to make a trade.Some assets will have a small or nonexistent order book between them. In these cases, Stellar facilitates path payments, which we’ll discuss later.To view an order book chart, see the Order Book Wikipedia Page. In addition, there are also plenty of video tutorials and articles out there that can help you understand how order books work in greater detail.Orders​An account can create orders to buy or sell assets using the Manage Buy Offer, Manage Sell Offer, or Passive Order operations. The account must hold the asset it wants to exchange, and it must trust the issuer of the asset it is trying to buy.Orders in Stellar behave like limit orders in traditional markets. When an account initiates an order, it is checked against the existing orderbook for that asset pair. If the submitted order is a marketable order (for a marketable buy limit order, the limit price is at or above the ask price; for a marketable sell limit order, the limit price is at or below the bid price), it is filled at the existing order price for the available quantity at that price. If the order is not marketable (i.e., does not cross an existing order), the order is saved on the orderbook until it is either consumed by another order, consumed by a path payment, or canceled by the account that created the order.Each order constitutes a selling obligation for the selling asset and buying obligation for the buying asset. These obligations are stored in the account (for lumens) or trustline (for other assets) owned by the account creating the order. Any operation that would cause an account to be unable to satisfy its obligations — such as sending away too much balance — will fail. This guarantees that any order in the orderbook can be executed entirely.Orders are executed on a price-time priority, meaning orders will be executed based first on price; for orders placed at the same price, the order that was entered earlier is given priority and is executed before the newer one.Price and operations​Each order in Stellar is quoted with an associated price and is represented as a ratio of the two assets in the order, one being the “quote asset” and the other being the “base asset”. This is to ensure there is no loss of precision when representing the price of the order (as opposed to storing the fraction as a floating-point number).Prices are specified as a {numerator, denominator} pair with both components of the fraction represented as 32-bit signed integers. The numerator is considered the base asset, and the denominator is considered the quote asset. When expressing a price of “Asset A in terms of Asset B”, the amount of B is the denominator (and therefore the quote asset), and A is the numerator (and therefore the base asset). As a good rule of thumb, it’s generally correct to be thinking about the base asset that is being bought/sold (in terms of the quote asset).Manage Buy Offer​When creating a buy order in Stellar via the Manage Buy Offer operation, the price is specified as 1 unit of the base currency (the asset being bought), in terms of the quote asset (the asset that is being sold). For example, if you’re buying 100 XLM in exchange for 20 USD, you would specify the price as {20, 100}, which would be the equivalent of 5 XLM for 1 USD (or $.20 per XLM).Manage Sell Offer​When creating a sell order in Stellar via the Manage Sell Offer operation, the price is specified as 1 unit of base currency (the asset being sold), in terms of the quote asset (the asset that is being bought). For example, if you’re selling 100 XLM in exchange for 40 USD, you would specify the price as {40, 100}, which would be the equivalent of 2.5 XLM for 1 USD (or $.40 per XLM).Passive Order​Passive orders allow markets to have zero spread. If you want to exchange USD from anchor A for USD from anchor B at a 1:1 price, you can create two passive orders so the two orders don’t fill each other.A passive order is an order that does not execute against a marketable counter order with the same price. It will only fill if the prices are not equal. For example, if the best order to buy BTC for XLM has a price of 100XLM/BTC, and you make a passive offer to sell BTC at 100XLM/BTC, your passive offer does not take that existing offer. If you instead make a passive offer to sell BTC at 99XLM/BTC it would cross the existing offer and fill at 100XLM/BTC.An account can place a passive sell order via the Create Passive Sell Offer operation.Fees​The order price you set is independent of the fee you pay for submitting that order in a transaction. Fees are always paid in XLM, and you specify them as a separate parameter when submitting the order to the network.To learn more about transaction fees, see our section on Fees, Surge Pricing, and Fee Strategies.Liquidity pools​Liquidity pools enable automated market making on the Stellar network. Liquidity refers to how easily and cost-effectively one asset can be converted to another.Automated Market Makers (AMMs)​Instead of relying on the buy and sell orders of decentralized exchanges, AMMs keep assets in an ecosystem liquid 24/7 using liquidity pools.Automated market makers provide liquidity using a mathematical equation. AMMs hold two different assets in a liquidity pool, and the quantities of those assets (or reserves) are inputs for that equation (Asset A * Asset B = k). If an AMM holds more of the reserve assets, the asset prices move less in response to a trade.AMM pricing​AMMs are willing to make some trades and unwilling to make others. For example, if 1 EUR = 1.17 USD, then the AMM might be willing to sell 1 EUR for 1.18 USD and unwilling to sell 1 EUR for 1.16 USD. To determine what trades are acceptable, the AMM enforces an invariant. There are many possible invariants, and Stellar enforces a constant product invariant and so is known as a constant product market maker. This means that AMMs on Stellar must never allow the product of the reserves to decrease.For example, suppose the current reserves in the liquidity pool are 1000 EUR and 1170 USD which implies a product of 1,170,000. Selling 1 EUR for 1.18 USD would be acceptable because that would leave reserves of 999 EUR and 1171.18 USD, which implies a product of 1,170,008.82. But selling 1 EUR for 1.16 USD would not be acceptable because that would leave reserves of 999 EUR and 1171.16 USD, which implies a product of 1,169,988.84.AMMs decide exchange rates based on the ratio of reserves in the liquidity pool. If this ratio is different than the true exchange rate, arbitrageurs will come in and trade with the AMM at a favorable price. This arbitrage trade moves the ratio of the reserves back toward the true exchange rate.AMMs charge fees on every trade, which is a fixed percentage of the amount bought by the AMM. For example, if an automated market maker sells 100 EUR for 118 USD then the fee is charged on the USD. The fee is 30 bps, which is equal to 0.30%. If you actually wanted to make this trade, you would need to pay about 118.355 USD for 100 EUR. The automated market maker factors the fees into the constant product invariant, so in reality, the product of the reserves grows after every trade.Liquidity pool participation​Any eligible participant can deposit assets into a liquidity pool, and in return, receive pool shares representing their ownership of that asset. If there are 150 total pool shares and one user owns 30, they are entitled to withdraw 20% of the liquidity pool asset at any time.Pool shares are similar to other assets on Stellar but they cannot be transferred. You can only increase the number of pool shares you hold by depositing into a liquidity pool with the LiquidityPoolDespositOp and decrease the number of pool shares you hold by withdrawing from a liquidity pool with LiquidityPoolWithdrawOp.A pool share has two representations. The full representation is used with ChangeTrustOp, and the hashed representation is used in all other cases. When constructing the asset representation of a pool share, the assets must be in lexicographical order. For example, A-B is in the correct order but B-A is not. This results in a canonical representation of a pool share.AMMs charge a fee on all trades and the participants in the liquidity pool receive a share of the fee proportional to their share of the assets in the liquidity pool. Participants collect these fees when they withdraw their assets from the pool. The fee rate on Stellar is 30 bps, which is equal to 0.30%. These fees are completely separate from the network fees.Trustlines​Users need to establish trustlines to three different assets to participate in a liquidity pool: both the reserve assets (unless one of them is XLM) and the pool share itself.An account needs a trustline for every pool share it wants to own. It is not possible to deposit into a liquidity pool without a trustline for the corresponding pool share. Pool share trustlines differ from trustlines for other assets in a few ways:A pool share trustline cannot be created unless the account already has trustlines that are authorized or authorized to maintain liabilities for the assets in the liquidity pool. See below for more information about how authorization impacts pool share trustlines.A pool share trustline requires 2 base reserves instead of 1. For example, an account (2 base reserves) with a trustline for asset A (1 base reserve), a trustline for asset B (1 base reserve), and a trustline for the A-B pool share (2 base reserves) would have a reserve requirement of 6 base reserves.Authorization​Pool share trustlines cannot be authorized or de-authorized independently. Instead, the authorization of a pool share trustline is derived from the trustlines for the assets in the liquidity pool. This design is necessary because a liquidity pool may contain assets from two different issuers, and both issuers should have a say in whether the pool share trustline is authorized.There are a few possibilities with regard to authorization. The behavior of the A-B pool share trustline is determined according to the following table:SCENARIOBEHAVIORTrustlines for A and B are fully authorizedNo restrictions on deposit and withdrawalTrustline for A is fully authorized but trustline for B is authorized to maintain liabilitiesTrustlines for A and B are authorized to maintain liabilitiesTrustline for B is fully authorized but trustline for A is authorized to maintain liabilitiesTrustlines for A and B are authorized to maintain liabilitiesTrustlines for A and B are authorized to maintain liabilitiesTrustlines for A and B are authorized to maintain liabilitiesTrustline for A is not authorized or doesn’t existPool share trustline does not existTrustline for B is not authorized or doesn’t existPool share trustline does not existIf the issuer of A or B revokes authorization, then the account will automatically withdraw from every liquidity pool containing that asset and those pool share trustlines will be deleted. We say that these pool shares have been redeemed. For example, if the account participates in the A-B, A-C, and B-C liquidity pools and the issuer of A revokes authorization then the account will redeem from A-B and A-C but not B-C. For each redeemed pool share trustline, a Claimable Balance will be created for each asset contained in the pool if there is a balance being withdrawn and the redeemer is not the issuer of that asset. The claimant of the Claimable Balance will be the owner of the deleted pool share trustline, and the sponsor of the Claimable Balance will be the sponsor of the deleted pool share trustline. The BalanceID of each Claimable Balance is the SHA-256 hash of the revokeID.Operations​There are two operations that facilitate participation in a liquidity pool: LiquidityPoolDeposit and LiquidityPoolWithdraw. Use LiquidityPoolDeposit to start providing liquidity to the market. Use LiquidityPoolWithdraw to stop providing liquidity to the market.However, users don’t need to participate in the pool to take advantage of what it’s offering: an easy way to exchange two assets. For that, just use PathPaymentStrictReceive or PathPaymentStrictSend. If your application is already using path payments, then you don’t need to change anything for users to take advantage of the prices available in liquidity pools.Examples​Here we will cover basic liquidity pool participation and querying.Preamble​For all of the following examples, we’ll be working with three funded Testnet accounts. If you’d like to follow along, generate some keypairs and fund them via the friendbot.The following code sets up the accounts and defines some helper functions. These should be familiar if you’ve played around with other examples like clawbacks.Here, we use distributeAssets() to establish trustlines and set up initial balances of two custom assets (A and B, issued by kp1) for two accounts (kp2 and kp3). For someone to participate in the pool, they must establish trustlines to each of the asset issuers and to the pool share asset (explained below).Note the orderAssets() helper here. Operations related to liquidity pools refer to the asset pair arbitrarily as A and B; however, they must be “ordered” such that A < B. This ordering is defined by the protocol, but its details should not be relevant (if you’re curious, it’s essentially lexicographically ordered by asset type, code, then issuer). We can use the comparison methods built into the SDKs (like Asset.compare) to ensure we pass them in the right order and avoid errors.Participation: Creation​First, let's create a liquidity pool for the asset pair defined in the preamble. This involves establishing a trustline to the pool itself:This lets the participants hold pool shares, which means now they can perform deposits and withdrawals.Participation: Deposits​To work with a liquidity pool, you need to know its ID beforehand. It’s a deterministic value, and only a single liquidity pool can exist for a particular asset pair, so you can calculate it locally from the pool parameters.When depositing assets into a liquidity pool, you need to define your acceptable price bounds. In the above function, we allow for a +/-10% margin of error from the “spot price”. This margin is by no means a recommendation and is chosen just for demonstration.Notice that we also specify the maximum amount of each reserve we’re willing to deposit. This, alongside the minimum and maximum prices, helps define boundaries for the deposit, since there can always be a change in the exchange rate between submitting the operation and it getting accepted by the network.Participation: Withdrawals​If you own shares of a particular pool, you can withdraw reserves from it. The operation structure mirrors the deposit closely:Notice here that we specify the minimum amount. Much like with a strict-receive path payment, we’re specifying that we’re not willing to receive less than this amount of each asset from the pool. This effectively defines a minimum withdrawal price.Putting it all together​Finally, we can combine these pieces together to simulate some participation in a liquidity pool. We’ll have everyone deposit increasing amounts into the pool, then one participant withdraws their shares. Between each step, we’ll retrieve the spot price.Watching Liquidity Pool Activity​You can access the transactions, operations, and effects related to a liquidity pool if you want to track its activity. Let’s see how we can track the latest deposits in a pool (suppose poolId is defined as before):","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/liquidity-on-stellar-sdex-liquidity-pools","title":"Liquidity on Stellar: SDEX and Liquidity Pools","contentLength":2959}},{"pageContent":"Lumen Supply MetricsThis section explains how lumen supply metrics are calculated and made available via API. This information can be useful for products and services that track the distribution of XLM, including market cap aggregators and some exchanges, or to anyone who wants to investigate the distribution of XLM defined by the SDF mandate.Unlike many other blockchains, the native network currency is not created through mining- all XLM that has ever existed and will ever exist was created when the Stellar network went live.SDF’s Dashboard API endpoint will always have the live totals for the essential numbers around lumens. This guide explains important supply metrics like Original Supply, Total Supply, and Circulating Supply entailed in that data.Dashboard API​As of December 12, 2019, the Dashboard API shows:Definitions​originalSupply One hundred billion lumens were created when the Stellar network went live. That’s the Original Supply for the network.inflationLumens For the first five or so years of Stellar’s existence, the supply of lumens increased by 1% annually. This “network inflation” was ended by validator vote on October 28, 2019. The total number of lumens generated by inflation was 5,443,902,087.3472865.Adding this number to the Original Supply, you get the total lumens that have ever existed: 105,443,902,087.3472865. This number is visible on the List All Ledgers Horizon API endpoint as _embedded.records.total_coins.burnedLumens These are all the lumens sent to accounts with no signers, meaning the funds are inaccessible and have been removed forever from Stellar’s lumen supply.While any address with no signers is counted here, the vast majority of the lumens in this sum are in a single locked address. On November 4, 2019, SDF reduced its lumen holdings to better reflect its mission and the growth of the Stellar ecosystem. To do so, the Foundation sent 55,442,095,285.7418 lumens to GALA…LUTO.totalSupply The Total Supply is the number of lumens now in existence: 50,001,803,905.97172. The Total Supply includes four major categories of lumens, which the API treats in detail.upgradeReserve The Upgrade Reserve is a special address that’s neither circulating nor a part of SDF’s mandate. When Stellar changed its consensus algorithm in 2015 and relaunched the network these lumens were set aside, to be claimed, one-for-one, by holders of the old network tokens. The Upgrade Reserve account is essentially an escrow, and we don’t expect many claimants to come and pull those lumens into the circulating supply at this point.feePool The Fee Pool is where network fees collect. The lumens do not belong to any particular account. No one has access to the fee pool, so these lumens are non-circulating. Network validators could theoretically vote for a protocol change that would affect the fee pool, so we include it in the total supply. Stellar’s transaction fees are extremely low so the fee pool grows very slowly. The Fee Pool is tracked by the protocol itself, and the current number is visible on the List All Ledgers Horizon API endpoint as _embedded.records.fee_pool.sdfMandate The SDF Mandate is described in detail here. The Foundation was funded by lumens generated at Stellar’s inception; all of those lumens will eventually be spent or distributed to enhance and promote Stellar. Here is a complete list of the addresses currently associated with the SDF Mandate:Direct Development, Available FundsJan 1 2021 EscrowJan 1 2022 EscrowJan 1 2023 EscrowDirect Development (Hot 1)Direct Development (Hot 2)Direct Development (Hot 3)Developer SupportDeveloper Support (Hot)Currency SupportNew ProductsEnterprise FundMarketing SupportIn-App DistributionIn-App Distribution (Hot)circulatingSupply The Circulating Supply is lumens in the hands of individuals and independent companies. These are lumens out in the world, used to pay network fees and fund Stellar accounts. They are also used as a general medium of exchange. We expect Stellar’s Circulating Supply to grow steadily as SDF spends and distributes lumens according to its mandate. Lumens in the Total Supply, but not in the SDF Mandate, Upgrade Reserve, or Fee Pool are assumed to be circulating.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/lumen-supply-metrics","title":"Lumen Supply Metrics","contentLength":695}},{"pageContent":"MemosMemos are an optional unstructured data field that can be used to embed any additional identifying information about the transaction relevant to the sender or receiver.They were previously used to differentiate between individual accounts in a pooled account- something we used muxed accounts for now.For more information on muxed accounts, see our Pooled Accounts - Muxed Accounts & Memos Encyclopedia EntryMemos can be one of the following types:MEMO_TEXT: A string encoded using either ASCII or UTF-8, up to 28-bytes long. MEMO_ID: A 64-bit unsigned integer. MEMO_HASH: A 32-byte hash. MEMO_RETURN: A 32-byte hash intended to be interpreted as the hash of the transaction the sender is refunding.Memo content examples​Notifying that the transaction is a refund or reimbursementReference to an invoice the transaction is payingAny further internal routing informationLinks to relevant data","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/memos","title":"Memos","contentLength":139}},{"pageContent":"Network PassphrasesStellar’s Pubnet and Testnet each have their own unique passphrase. These are used when validating signatures on a given transaction. If you sign a transaction for one network but submit it to another, it won’t be considered valid. By convention, the format of a passphrase is ‘[Network Name] ; [Month of Creation] [Year of Creation]’.The current passphrases for the Stellar Pubnet and Testnet are:Pubnet: 'Public Global Stellar Network ; September 2015'Testnet: 'Test SDF Network ; September 2015'Passphrases serve two main purposes: (1) used as the seed for the root account (master network key) at genesis and (2) used to build hashes of transactions, which are ultimately what is signed by each signer’s secret key in a transaction envelope; this allows you to verify that a transaction was intended for a specific network by its signers.Most SDKs have the passphrases hardcoded for the Stellar Pubnet and Testnet. If you’re running a private network, you’ll have to manually pass in a passphrase to be used whenever transaction hashes are generated. All of Stellar’s official SDKs allow you to use a network with a custom passphrase.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/network-passphrases","title":"Network Passphrases","contentLength":192}},{"pageContent":"Path PaymentsIn a path payment, the asset received differs from the asset sent. Rather than the operation transferring assets directly from one account to another, path payments cross through the SDEX and/or liquidity pools before arriving at the destination account. For the path payment to succeed, there has to be a DEX offer or liquidity pool exchange path in existence. It can sometimes take several hops of conversion to succeed.For example:Account A sells XLM → [buy XLM / sell ETH → buy ETH / sell BTC → buy BTC / sell USDC] → Account B receives USDCIt is possible for path payments to fail if there are no viable exchange paths.For more information on the Stellar Decentralized Exchange and Liquidity Pools, see our Liquidity on Stellar: SDEX and Liquidity Pools Encyclopedia EntryOperations​Path payments use the Path Payment Strict Send or Path Payment Strict Receive operations.Path Payment Strict Send​Allows a user to specify the amount of the asset to send. The amount received will vary based on offers in the order books and/or liquidity pools.Path Payment Strict Receive​Allows a user to specify the amount of the asset received. The amount sent will vary based on the offers in the order books/liquidity pools.Path payments - more info​Path payments don’t allow intermediate offers to be from the source account as this would yield a worse exchange rate. You’ll need to either split the path payment into two smaller path payments or ensure that the source account’s offers are not at the top of the order book.Balances are settled at the very end of the operation.This is especially important when (Destination, Destination Asset) == (Source, Send Asset) as this provides a functionality equivalent to getting a no-interest loan for the duration of the operation.Destination min is a protective measure, it allows you to specify a lower bound for an acceptable conversion. If offers in the order books are not favorable enough for the operation to deliver that amount, the operation will fail.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/path-payments","title":"Path Payments","contentLength":339}},{"pageContent":"Pooled Accounts: Muxed Accounts and MemosWhen building an application or service on Stellar, one of the first things you have to decide is how to handle user accounts.You can create a Stellar account for each user, but most custodial services, including cryptocurrency exchanges, choose to use a single pooled Stellar account to handle transactions on behalf of their users. In these cases, the muxed account feature can map transactions to individual accounts via an internal customer database.Note that we used memos in the past for this purpose, however, using muxed accounts is better in the long term. At this time, there isn't support for muxed accounts by all wallets, exchanges, and anchors, so you may want to support both memos and muxed accounts, at least for a while.Pooled accounts​A pooled account allows a single Stellar account ID to be shared across many users. Generally, services that use pooled accounts track their customers in a separate, internal database and use the muxed accounts feature to map an incoming and outgoing payment to the corresponding internal customer.The benefits of using a pooled account are lower costs – no base reserves are needed for each account – and lower key complexity – you only need to manage one account keypair. However, with a single pooled account, it is now your responsibility to manage all individual customer balances and payments. You can no longer rely on the Stellar ledger to accumulate value, handle errors and atomicity, or manage transactions on an account-by-account basis.Muxed accounts​Muxed accounts are embedded into the protocol for convenience and standardization. They distinguish individual accounts that all exist under a single, traditional Stellar account. They combine the familiar GABC… address with a 64-bit integer ID.Muxed accounts do not exist on the ledger, but their shared underlying GABC… account does.Muxed accounts are defined in CAP-0027, introduced in Protocol 13, and their string representation is described in SEP-0021.It is safe for all wallets to implement sending to muxed accounts.If you wish to receive deposits to muxed accounts please keep in mind that they are not yet supported by all wallets and exchanges.Address format​Muxed accounts have their own address format that starts with an M prefix. For example, from a traditional Stellar account address: GA7QYNF7SOWQ3GLR2BGMZEHXAVIRZA4KVWLTJJFC7MGXUA74P7UJVSGZ, we can create new muxed accounts with different IDs. The IDs are embedded into the address itself- when you parse the muxed account addresses, you get the G address from above plus another number.MA7QYNF7SOWQ3GLR2BGMZEHXAVIRZA4KVWLTJJFC7MGXUA74P7UJUAAAAAAAAAAAACJUQ has the ID 0, whileMA7QYNF7SOWQ3GLR2BGMZEHXAVIRZA4KVWLTJJFC7MGXUA74P7UJUAAAAAAAAAABUTGI4 has the ID 420.Both of these addresses will act on the underlying GA7Q… address when used with one of the supported operations.Supported operations​Not all operations can be used with muxed accounts. Here is what you can use them for:The source account of any operation or transaction;The fee source of a fee-bump transaction;The destination of all three types of payments:Payment,PathPaymentStrictSend, andPathPaymentStrictReceive;The destination of an AccountMerge; andThe target of a Clawback operation (i.e. the from field).We will demonstrate some of these in the examples section.There’s no validation on IDs and as far as the Stellar network is concerned, all supported operations operate exactly as if you did not use a muxed account. For example, if you make two payments from two muxed accounts that share an underlying Stellar account (same G… address but different M… addresses) this is exactly the same as that single Stellar account sending two payments according to the ledger. Even though only the underlying G… account truly exists on the Stellar ledger, the Horizon API will make an effort to interpret and track the muxed accounts responsible for certain actions.Examples​In this section, we’ll demonstrate how to create muxed accounts and how they interface with their supported operations. Since custodial account workarounds based on transaction memos are unnecessary now, we’ll use that as a skeleton for our example structure.After preparing some supporting code, we’ll demonstrate three examples:Example 1: Normal, “full” Stellar account payments (i.e. G to G) Example 2: Mixed payments (i.e. M to G) Example 3: Fully muxed payments (i.e. M to M)But use a shared function for all of them that does the real work, highlighting the ease of implementing muxed account support.Preamble​First, let’s create two accounts and then a handful of virtual accounts representing “custodial customers” that the parent account manages:We assume that these accounts exist on the testnet; you can replace them with your own keys and use friendbot if you’d like.When we run this function, we’ll see the similarity in muxed account addresses among the customers, highlighting the fact that they share a public key:With the accounts out of the way, let’s look at how we can manage the difference between traditional Stellar accounts (G...) and these virtual muxed accounts (M...).Muxed Operations Model​The introduction of muxed addresses as a higher-level abstraction—and their experimental, opt-in nature—means there are mildly diverging branches of code depending on whether the source is a muxed account or not. We still need to, for example, load accounts by their underlying address, because the muxed versions don’t actually live on the Stellar ledger:For payments—our focus for this set of examples—the divergence only matters because we want to show the balances for the custodian account.Payments​The actual code to build payments is almost exactly the same as it would be without the muxed situation:We can use this block to make a payment between normal Stellar accounts with ease: doPayment(\"GCIHA...\", \"GDS5N...\"). The main divergence from the standard payments code—aside from the stubs to show XLM balances before and after—is the inclusion of the opt-in withMuxing flag.Muxed to Unmuxed​The codeblock above covers all payment operations, abstracting away any need for differentiating between muxed (M...) and unmuxed (G...) addresses. From a high level, then, it’s still trivial to make payments between one of our “customers” and someone outside of the “custodian’s” organization.Notice that we still sign the transaction with the custodian keys, because muxed accounts have no concept of a secret key. Ultimately, everything still goes through the parent account, and so we should see the parent account’s balance decrease by 10 XLM accordingly:Of course, there’s also a fee charged for the transaction itself.Muxed to Muxed​As we’ve mentioned, muxed account actions aren’t represented in the Stellar ledger explicitly. When two muxed accounts sharing an underlying Stellar account communicate, it’s as if the underlying account is talking to itself. A payment between two such accounts, then, is essentially a no-op.The output should be something like the following:Notice that the account’s balance is essentially unchanged, yet it was charged a fee since this transaction is still recorded in the ledger (despite doing next to nothing). You may want to detect these types of transactions in your application to avoid paying unnecessary transaction fees.If we were to make a payment between two muxed accounts that had different underlying Stellar accounts, this would be equivalent to a payment between those two respective G... accounts.More Examples​As is the case for most protocol-level features, you can find more usage examples and inspiration in the relevant test suite for your favorite SDK. For example, here are some of the JavaScript test cases.FAQs​What happens if I pay a muxed address, but the recipient doesn’t support them?In general, you should not send payments to muxed addresses on platforms that do not support them. These platforms will not be able to provide muxed destination addresses in the first place.Even still, if this does occur, parsing a transaction with a muxed parameter without handling them will lead to one of two things occurring:If your SDK is out-of-date, parsing will error out. You should upgrade your SDK. For example, the JavaScript SDK will throw a helpful message:If your SDK is up-to-date, you will see the muxed (M...) address parsed out. What happens next depends on your application.Note, however, that the operation will succeed on the network. In the case of payments, for example, the destination’s parent address will still receive the funds.What happens if I want to pay a muxed account, but my platform does not support them?In this case, do not use a muxed address. The platform will likely fail to create the operation. You probably want to use the legacy method of including a transaction memo, instead.What do I do if I receive a transaction with muxed addresses and a memo ID?In an ideal world, this situation would never happen. You can determine whether or not the underlying IDs are equal; if they aren’t, this is a malformed transaction and we recommend not submitting it to the network.What happens if I get errors when using muxed accounts?In up-to-date versions of Stellar SDKs, muxed accounts are natively supported by default. If you are using an older version of an SDK, however, they may still be hidden behind a feature flag.If you get errors when using muxed addresses on supported operations like: “destination is invalid; did you enable muxing?”We recommend upgrading to the latest version of any and all Stellar SDKs you use. However, if that’s not possible for some reason, you will need to enable the feature flag before interacting with muxed accounts. Consult your SDK’s documentation for details.What happens if I pass a muxed address to an incompatible operation?Only certain operations allow muxed accounts, as described above. Passing a muxed address to an incompatible parameter with an up-to-date SDK should result in a compilation or runtime error at the time of use.For example, when using the JavaScript SDK incorrectly:The runtime result would be:“Error: invalid version byte. expected 48, got 96”This error message indicates that the trustor failed to parse as a Stellar account ID (G...). In other words, your code will fail and the invalid operation will never reach the network.How do I validate Stellar addresses?You should use the validation methods provided by your SDK or carefully adhere to SEP-23. For example, the JavaScript SDK provides the following methods for validating Stellar addresses:There are also abstractions for constructing and managing both muxed and regular accounts; consult your SDK documentation for details.Memo - differentiated accounts​Prior to the introduction of muxed accounts, products and services that relied on pooled accounts often used transaction memos to differentiate between users. Supporting muxed accounts is better in the long term, but for now you may want to support both memos and muxed accounts as all exchanges, anchors, and wallets may not support muxed accounts.To learn about what other purposes memos can be used for, see our Memos Encyclopedia Entry.Why are muxed accounts better in the long term?​Muxed accounts are a better approach to differentiating between individuals in a pooled account because they have better:Shareability — rather than worrying about error-prone things like copy-pasting memo IDs, you can just share your M... address.SDK support — the various SDKs support this abstraction natively, letting you create, manage, and work with muxed accounts easily. This means that you may see muxed addresses appear when parsing any of the fields that support them, so you should be ready to handle them. Refer to your SDK’s documentation for details; for example, v7.0.0 of the JavaScript SDK library stellar-base describes all of the fields and functions that relate to muxed accounts.Efficiency — by combining related virtual accounts under a single account’s umbrella, you can avoid holding reserves and paying fees for all of them to exist in the ledger individually. You can also combine multiple payments to multiple destinations within a single transaction since you do not need the per-transaction memo field anymore.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/pooled-accounts-muxed-accounts-memos","title":"Pooled Accounts: Muxed Accounts and Memos","contentLength":2025}},{"pageContent":"Securing Web-based ProjectsAny application managing cryptocurrency is a frequent target of malicious actors and needs to follow security best practices. The below checklist offers guidance on the most common vulnerabilities. However, even if you follow every piece of advice, security is not guaranteed. Web security and malicious actors are constantly evolving, so it’s good to maintain a healthy amount of paranoia.SSL/TLS​Ensure that TLS is enabled. Redirect HTTP to HTTPS where necessary to ensure that Man in the Middle attacks can’t occur and sensitive data is securely transferred between the client and browser. Enable TLS and get an SSL certificate for free at LetsEncrypt.If you don’t have SSL/TLS enabled, stop everything and do this first.Content security policy (CSP) headers​CSP headers tell the browser where it can download static resources from. For example, if you astralwallet.io and it requests a JavaScript file from myevilsite.com, your browser will block it unless it was whitelisted with CSP headers. You can read about how to implement CSP headers here.Most web frameworks have a configuration file or extensions to specify your CSP policy, and the headers are auto-generated for you. For example, see Helmet for Node.js. This would have prevented the Blackwallet Hack.HTTP strict-transport-security headers​This is an HTTP header that tells the browser that all future connections to a particular site should use HTTPS. To implement this, add the header to your website. Some web frameworks (like Django) have this built-in. This would have prevented the MyEtherWallet DNS Hack.Storing sensitive data​Ideally, you don’t have to store much sensitive data. If you must, be sure to tread carefully. There are many strategies to store sensitive data:Ensure sensitive data is encrypted using a proven cipher like AES-256 and stored separately from application data. Always pick up AEAD mode.Any communication between the application server and secret server should be in a private network and/or authenticated via HMAC. Your cipher strategy will change based on whether you will be sending the ciphertext over the wire multiple times.Back up any encryption keys you may use offline and store them only in-memory in your app.Consult a good cryptographer and read up on best practices. Look into the documentation of your favorite web framework.Rolling your own crypto is a bad idea. Always use tried and tested libraries such as NaCI.Monitoring​Attackers often need to spend time exploring your website for unexpected or overlooked behavior. Examining logs defensively can help you catch onto what they’re trying to achieve. You can at least block their IP or automate blocking based on suspicious behavior.It’s also worth setting up an error reporting (like Sentry). Often, people trigger strange bugs when trying to hack things.Authentication weaknesses​You must build your authentication securely if you have logins for users. The best way to do this is to use something off the shelf. Both Ruby on Rails and Django have robust, built-in authentication schemes.Many JSON web token implementations are poorly done, so ensure the library you use is audited.Hash passwords with a time-tested scheme are good. And Balloon Hashing is also worth looking into.We strongly prefer 2FA and require U2F or TOTP 2FA for sensitive actions. 2FA is important as email accounts are usually not very secure. Having a second factor of authentication ensures that users who accidentally stay logged on or have their password guessed are still protected.Finally, require strong passwords. Common and short passwords can be brute-forced. Dropbox has a great open-source tool that gauges password strength fairly quickly, making it usable for user interactions.Denial of service attacks (DOS)​DOS attacks are usually accomplished by overloading your web servers with traffic. To mitigate this risk, rate limit traffic from IPs and browser fingerprints. Sometimes people will use proxies to bypass IP rate-limiting. In the end, malicious actors can always find ways to spoof their identity, so the surest way to block DOS attacks is to implement proof of work checks in your client or use a managed service like Cloudflare.Lockdown unused ports​Attackers will often scan your ports to see if you were negligent and left any open. Services like Heroku do this for you- read about how to enable this on AWS.Phishing and social engineering​Phishing attacks will thwart any well-formed security infrastructure. Have clear policies published on your website and articulate them to users when they sign up (you will never ask for their password, etc.). Sign messages to your users and prompt users to check the website's domain they are on.Scan your website and libraries for vulnerabilities​Use a tool like Snyk to scan your third-party client libraries for vulnerabilities. Make sure to keep your third-party libraries up to date. Often, upgrades are triggered by security exploits. You can use Mozilla Observatory to check your HTTP security as well.Cross-Site Request Forgery Protection (CSRF), SQL injections​Most modern web and mobile frameworks handle both CSRF protection and SQL injections. Ensure CSRF protection is enabled and that you are using a database ORM instead of running raw SQL based on user input. For example, see what Ruby on Rails documentation says about SQL injections.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/securing-web-based-projects","title":"Securing Web-based Projects","contentLength":893}},{"pageContent":"Signatures and MultisigSignatures are authorization for transactions on the network. Transactions always need authorization from at least one public key to be valid and generally, the signature comes from the source account. Sometimes transactions require more signatures, which we’ll get into in the multisig section.Transaction signatures are created by signing the transaction object contents with a secret key. Stellar uses the ed25519 signature scheme, but there is also a mechanism for adding additional types of public and private key schemes. A transaction with an attached signature is considered to have authorization from that public key.Thresholds​Each operation falls under a specific threshold category: low, medium, or high with a number level between 0-255 (to read more about this see our section on Operations and Transactions). This threshold determines what signature weight is needed to authorize an operation.To view each operation’s threshold, see our List of Operations section.Accounts can set their own signature weight, threshold values, and additional signing keys with the Set Options operation. By default, all operation threshold levels are set to 0, and the master key is set to weight 1. For most cases, it is recommended to set thresholds such that low <= medium <= high.If the master key’s weight is set at 0, it cannot be used to sign transactions, even for operations with a threshold value of 0. Be very careful setting your master key weight to 0. Doing so may permanently lock you out of your account (although if there are other signers listed on the account, they can still continue to sign transactions.)Authorization​To determine if a transaction has the necessary authorization to run, the weights of all the signatures in the transaction envelope are added up. If this sum is equal to or greater than the threshold for that operation type, then the operation is authorized.This scheme is very flexible. You can require many signers to authorize payments from a particular account. You can have an account that any number of people can authorize for. You can have a master key that grants access or revokes access from others. It supports any m of n setup.Multisig​In some cases, a transaction may need more than one signature:If the transaction has operations with multiple source accounts, it requires the source account signature for each operationAdditional signatures are required if the account associated with the transaction has multiple public keysEach additional signer beyond the master key increases the account’s minimum balance by one base reserve. Up to 20 signatures can be attached to one transaction. Once a signature threshold is met, if there are leftover signatures, the transaction will fail. For example, if your transaction requires three signatures, providing more than three signatures, even if they are all valid, will result in a failed transaction error: TX_BAD_AUTH_EXTRA. This design is because unnecessary signature verification has a large effect on performance before accepting transactions in consensus.Alternate signature types​To enable some advanced smart contract features there are a couple of additional signature types. These signature types also have weights and can be added and removed similarly to normal signature types. But rather than check a cryptographic signature for authorization they have a different method of proving validity to the network.Pre-authorized Transaction​It is possible for an account to pre-authorize a particular transaction by adding the hash of the future transaction as a signer on the account. To do that, you need to prepare the transaction beforehand with the proper sequence number. Then you can obtain the hash of this transaction and add it as a signer to the account.Signers of this type are automatically removed from the account when a matching transaction is applied, regardless of whether the transaction succeeds or fails. In case a matching transaction is never submitted, the signer remains, and must be manually removed using the Set Options operation.This type of signer is especially useful in escrow accounts. You can pre-authorize two different transactions. Both could have the same sequence number but different destinations. This means that only one of them can be executed.Hash(x)​Adding a signature of type hash(x) allows anyone who knows x to sign the transaction. This type of signer is especially useful in atomic cross-chain swaps which are needed for inter-blockchain protocols like lightning networks.First, create a random 256-bit value, which we call x. The SHA256 hash of that value can be added as a signer of type hash(x). Then in order to authorize a transaction, x is added as one of the signatures of the transaction. Keep in mind that x will be known to the world as soon as a transaction is submitted to the network with x as a signature. This means anyone will be able to sign for that account with the hash(x) signer at that point. Often you want there to be additional signers so someone must have a particular secret key and know x in order to reach the weight threshold required to authorize transactions on the account.Examples​Example 1: AnchorsExample 2: Joint accountsExample 3: Expense accountsExample 4: Company accountsExample 1: Anchors​You run an anchor that would like to keep its issuing key offline. That way, it's less likely a bad actor can get ahold of the anchor's key and start issuing credit improperly. However, your anchor needs to authorize people holding credit by running the Set Trust Line Flags operation. Before you issue credit to an account, you need to verify that account is OK.Multisig allows you to do all of this without exposing the master key of your anchor. You can add another signing key to your account with the operation Set Options. This additional key should have a weight below your anchor account's medium threshold. Since Set Trust Line Flags is a low-threshold operation, this extra key authorizes users to hold your anchor's credit. But, since Payment is a medium-threshold operation, this key does not allow anyone who compromises your anchor to issue credit.Your account setup:Example 2: Joint accounts​You want to set up a joint account with Bilal and Carina such that any of you can authorize a payment. You also want to set up the account so that, if you choose to change signers (e.g., remove or add someone), a high-threshold operation, all 3 of you must agree. You add Bilal and Carina as signers to the joint account. You also ensure that it takes all of your key weights to clear the high threshold but only one to clear the medium threshold.Joint account setup:Example 3: Expense accounts​You fully control an expense account, but you want your two coworkers Diyuan and Emil to be able to authorize transactions from this account. You add Diyuan and Emil’s signing keys to the expense account. If either Diyuan or Emil leave the company, you can remove their signing key, a high-threshold operation.Expense account setup:Example 4: Company accounts​Warning: this example involves setting the master key weight of an account to 0. Be very careful if you decide to do that: that key will no longer be able to sign any kind of transaction, so you are in danger of permanently locking yourself out of your account. Make sure you’ve thought carefully about what you’re doing, that you understand the implications, and that you change weights in the correct order.Your company wants to set up an account that requires 3 of 6 employees to agree to any transaction from that account.Company account setup:","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/signatures-multisig","title":"Signatures and Multisig","contentLength":1285}},{"pageContent":"Sponsored ReservesSponsored reserves were introduced in CAP-0033 and allow an account (sponsoring account) to pay the base reserves for another account (sponsored account). While this relationship exists, base reserve requirements that would normally accumulate on the sponsored account now accumulate on the sponsoring account.Both the Begin Sponsoring Future Reserves and the End Sponsoring Future Reserves operations must appear in the sponsorship transaction, guaranteeing that both accounts agree to the sponsorship.Anything that increases the minimum balance can be sponsored (account creation, offers, trustlines, data entries, signers, claimable balances).To learn about base reserves, see our section on Lumens.Sponsored reserves operations​Begin and end sponsorships​To create a sponsored reserve, you have to use a sandwich transaction that includes three operations.The first operation: Begin Sponsoring Future Reserves initiates the sponsorship and requires the sponsoring account's signature.The second operation: specifies what is being sponsored.The third operation: End Sponsoring Future Reserves, allows the sponsored account to accept the sponsorship and requires the sponsored account’s signature.Begin Sponsoring Future Reserves establishes the is-sponsoring-future-reserves-for relationship where the sponsoring account is the source account of the operation. The account specified in the operation is the sponsored account.End Sponsoring Future Reserves ends the current is-sponsoring-future-reserves-for relationship for the source account of the operation.At the end of any transaction, there must be no ongoing is-sponsoring-future-reserves-for relationships, which is why these two operations must be used together in a single transaction.View operation details in our List of Operations section.Revoke sponsorship​Allows the sponsoring account to remove or transfer sponsorships of existing ledgerEntries and signers. If the ledgerEntry or signer is not sponsored, the owner of the ledgerEntry or signer can establish a sponsorship if it is the beneficiary of an is-sponsoring-future-reserves-for relationship.Operation logicEntry/signer is sponsoredSource account is currently the beneficiary of a is-sponsoring-future-reserves-for relationshipTransfer sponsorship of entry/signer from source account to the account that is-sponsoring-future-reserves-for source accountSource account is not the beneficiary of a is-sponsoring-future-reserves-for relationshipRemove the sponsorship from the entry/signerEntry/signer is not sponsoredSource account is currently the beneficiary of a is-sponsoring-future-reserves-for relationshipEstablish sponsorship between entry/signer and the account that is-sponsoring-future-reserves-for source accountSource account is not the beneficiary of a is-sponsoring-future-reserves-for relationshipNo-OpView operation details in our List of Operations section.Effect on minimum balance​Once sponsorships are introduced, the minimum balance calculation is: (2 base reserves + numSubEntries + numSponsoring - numSponsored) * baseReserve + liabilities.selling.When account A is sponsoring future reserves for account B, any reserve requirements that would normally accumulate on B will instead accumulate on A, shown in numSponsoring. The fact that these reserves are being provided by another account will be reflected on B in numSponsored, which cancels out the increase in numSubEntries, keeping the minimum balance unchanged for B.When a sponsored entry or subentry is removed, numSponsoring is decreased on the sponsoring account and numSponsored is decreased on the sponsored account.To learn more about minimum balance requirements, see our section on Lumens.Effect on claimable balances​All claimable balances are sponsored through built-in logic in the claimable balance operations. The account that creates the claimable balance pays the base reserve to get the claimable balance on the ledger. When the claimable balance is claimed by the claimant(s), the claimable balance is removed from the ledger, and the account that created it gets the base reserve back.Read more about claimable balances in our Claimable Balances Encyclopedia Entry.Examples​Each of the following examples builds on itself, referencing variables from previous snippets. The following examples will demonstrate:Sponsor creation of a trustline for another accountSponsor two trustlines for an account via two different sponsorsTransfer the sponsorship responsibility from one account to anotherRevoke the sponsorship by an account entirelyFor brevity in the Golang examples, we’ll assume the existence of a SignAndSend(...) method (defined below) which creates and submits a transaction with the proper parameters and basic error-checking.Preamble​We’ll start by including the boilerplate of account and asset creation.1. Sponsoring trustlines​Now, let’s sponsor trustlines for Account A. Notice how the CHANGE_TRUST operation is sandwiched between the begin and end sponsoring operations and that all relevant accounts need to sign the transaction.2. Transferring sponsorship​Suppose that now Signer 1 wants to transfer the responsibility of sponsoring reserves for the trustline to Sponsor 2. This is accomplished by sandwiching the transfer between the BEGIN/END_SPONSORING_FUTURE_RESERVES operations. Both of the participants must sign the transaction, though either can submit it.An intuitive way to think of a sponsorship transfer is that the very act of sponsorship is being sponsored by a new account. That is, the new sponsor takes over the responsibilities of the old sponsor by sponsoring a revocation.At this point, Signer 1 is only sponsoring the first asset (arbitrarily coded as ABCD), while Signer 2 is sponsoring the other two assets. (Recall that initially Signer 1 was also sponsoring EFGH.)3. Sponsorship revocation​Finally, we can demonstrate complete revocation of sponsorships. Below, Signer 2 removes themselves from all responsibility over the two asset trustlines. Notice that Account A is not involved at all, since revocation should be performable purely at the sponsor’s discretion.Sponsorship Source Accounts​When it comes to the SourceAccount fields of the sponsorship sandwich, it's important to refer to the wisdom of CAP-33:This relation is initiated by BeginSponsoringFutureReservesOp, where the sponsoring account is the source account, and is terminated by EndSponsoringFutureReserveOp, where the sponsored account is the source account.Since the source account defaults to the transaction submitter when omitted, this field needs always needs to be set for either the Begin or the End.For example, the following is an identical expression of the earlier Golang example of sponsoring a trustline, just submitted by the sponsor (Sponsor 1) rather than the sponsored account (Account A). Notice the differences in where SourceAccount is set:Other examples​If you’d like other examples or want to view a more-generic pseudo-code breakdown of these sponsorship scenarios, you can refer to CAP-0033 directly.Footnote​For the above examples, an implementation of SignAndSend (Golang) and some (very) rudimentary error checking code (all languages) might look something like this:","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/sponsored-reserves","title":"Sponsored Reserves","contentLength":1075}},{"pageContent":"XDRStellar stores and communicates ledger data, transactions, results, history, and messages in a binary format called External Data Representation (XDR). XDR is optimized for network performance but not human readable. Horizon and the Stellar SDKs convert XDRs into friendlier formats.XDR is specified in RFC 4506 and is similar to tools like Protocol Buffers or Thrift. XDR provides a few important features:It is very compact, so it can be transmitted quickly and stored with minimal disk space.Data encoded in XDR is reliably and predictably stored. Fields are always in the same order, which makes cryptographically signing and verifying XDR messages simple.XDR definitions include rich descriptions of data types and structures, which is not possible in simpler formats like JSON, TOML, or YAML.Parsing XDR​Since XDR is a binary format and not as widely known as simpler formats like JSON, the Stellar SDKs all include tools for parsing XDR and will do so automatically when retrieving data.In addition, the Horizon API server generally exposes the most important parts of the XDR data in JSON, so they are easier to parse if you are not using an SDK. The XDR data is still included (encoded as a base64 string) inside the JSON in case you need direct access to it..X files​Data structures in XDR are specified in an interface definition file (IDL). The IDL files used for the Stellar Network are available on GitHub.","metadata":{"source":"https://developers.stellar.org/docs/encyclopedia/xdr","title":"XDR","contentLength":239}},{"pageContent":"GlossaryAccount​A central Stellar data structure to hold balances, sign transactions, and issue assets.See the Accounts section to learn more.Account ID​The public key used to create an account. This key persists across different key assignments.Anchor​The on and off-ramps on the Stellar network that facilitate one-to-one conversion of off-chain representations to and from tokenized assets, for example, digital tokens representing bank deposits.Application (app)​A software program designed for users to carry out a specific task (other than operating the computer itself).Asset​Fiat, physical, or other tokens of value that are tracked, held, or transferred by the Stellar distributed network.See the Assets section to learn more.Balance​The amount of a given asset an account holds. Each asset has its own balance and these balances are stored in trustlines for every asset except XLM, which is held directly by the account.BalanceID​Parameter required when claiming a newly created entry via the Claim claimable balance operation. See ClaimableBalanceID.Base fee​The fee you’re willing to pay per operation in a transaction.This differs from the Effective Base Fee which is the actual fee paid per operation for a transaction to make it to the ledger. When the network is in surge pricing mode, the effective base fee varies based on an auction mechanism. When it's not, the effective base fee defaults to the network minimum currently at 100 stroops per operation.Learn more in our Fees, Surge Pricing, and Fee Strategies Encyclopedia EntryBase reserve​A unit of measurement used to calculate an account’s minimum balance. One base reserve is currently 0.5 XLM.Learn more in our Lumens section.Burn​Remove an asset from circulation, which can happen in two ways: 1) a holder sends the asset back to the issuing account 2) an issuer claws back a clawback-enabled asset from a holder's account.Claim Predicate​A recursive data structure used to construct complex conditionals with different values of ClaimPredicateType.ClaimableBalanceID​A SHA-256 hash of the OperationID for claimable balances.Claimant​An object that holds both the destination account that can claim the ClaimableBalanceEntry and a ClaimPredicate that must evaluate to true for the claim to succeed.Clawback​An amount of asset from a trustline or claimable balance removed (clawed back) from a recipient’s balance sheet.See the Clawback Encyclopedia Entry for more information.Core Advancement Proposals (CAPs)​Proposals of standards to improve the Stellar protocol- CAPs deal with changes to the core protocol of the Stellar network.Create account operation​Makes a payment to a 0-balance public key (Stellar address), thereby creating the account. You must use this operation to initialize an account rather than a standard payment operation.Cross-asset payments​A payment that automatically handles the conversion of dissimilar assets.Decentralized exchange​A distributed exchange that allows the trading and conversion of assets on the network.Learn more in our Liquidity on Stellar Encyclopedia Entry.External Data Representation (XDR)​The type of encoding used operations and data running on stellar-core.Flags​Flags control access to an asset on the account level. Learn more about flags in our Controlling Access to an Asset section.GitHub​An online repository for documents that can be accessed and shared among multiple users; host for the Stellar platform’s source code, documentation, and other open-source repos.Home domain​A fully qualified domain name (FQDN) linked to a Stellar account, used to generate an on-chain link to a Stellar Info File, which holds off-chain metadata. See the Set Options operation. Can be up to 32 characters.Horizon​The Stellar API, provides an HTTP interface to data in the Stellar network.JSON​A standardized human-readable and machine-readable format for the exchange of structured data.Keypair​A combined public and private key used to secure transactions. You can use any Stellar wallet, SDK, or the Stellar Laboratory to generate a valid keypair.Keystore​An encrypted store or file that serves as a repository of private keys, certificates, and public keys.Ledger​A representation of the state of the Stellar universe at a given point in time, shared across all network nodes.Learn more in the Ledgers section.LedgerKey​LedgerKey holds information to identify a specific ledgerEntry. It is a union that can be any one of the LedgerEntryTypes (ACCOUNT, TRUSTLINE, OFFER, DATA, or CLAIMABLE_BALANCE).Liability​A buying or selling obligation, required to satisfy (selling) or accommodate (buying) transactions.Lumen (XLM)​The native, built-in token on the Stellar network.Learn more about lumens in our Lumens section.Master key​The private key used in initial account creation.Minimum balance​The smallest permissible balance in lumens for a Stellar account, currently 1 lumen.Learn more in our Lumens section.Network capacity​The maximum number of operations per ledger, as determined by validator vote. Currently 1,000 operations for the pubnet and 100 operations for the testnet.Number of subentries​The number of entries owned by an account, used to calculate the account’s minimum balance.Operation​An individual command that modifies the ledger.Learn more in our Operations and Transactions section.OperationID​Contains the transaction source account, sequence number, and the operation index of the CreateClaimableBalance operation in a transaction.Order​An offer to buy or sell an asset.Learn more in our Liquidity on Stellar: SDEX and Liquidity Pools Encyclopedia Entry.Orderbook​A record of outstanding orders on the Stellar network.Learn more in our Liquidity on Stellar: SDEX and Liquidity Pools Encyclopedia Entry.Passive order​An order that does not execute against a marketable counter order with the same price; filled only if the prices are not equal.Passphrase​The Pubnet and Testnet each have their own unique passphrase, which are used to validate signatures on a given transaction.Learn more about network passphrases in the Network Passphrases Encyclopedia Entry.Pathfinding​The process of determining the best path of a payment, evaluating the current orderbooks, and finding the series of conversions to achieve the best rate.Payment channel​Allows two parties who frequently transact with one another to move the bulk of their activity off-chain, while still recording opening balances and final settlement on-chain.Precondition​Optional requirements you can add to control a transaction’s validity.See the Operation and Transaction Validity section for more information.Price​The ratio of the quote asset and the base asset in an order.Public key​The public part of a keypair that identifies a Stellar account. The public key is public- it is visible on the ledger, anyone can look it up, and it is used when sending payments to the account, identifying the issuer of an asset, and verifying that a transaction is authorized.Pubnet​The Stellar Public Network, aka mainnet, the main network used by applications in production.Read more in our Testnet & Pubnet section.Rate-limiting​Horizon rate limits on a per-IP-address basis. By default, a client is limited to 3,600 requests per hour, or one request per second on average.Sequence number​Used to identify and verify the order of transactions with the source account.A transaction’s sequence number must always increase by one (unless minimum sequence number preconditions are set, or a bump sequence operation is used). SDKs and the Laboratory automatically increment the account’s sequence number by one when you build a transaction.Secret (private) key​The private key is part of a keypair, which is associated with an account. Do not share your secret key with anyone.SEPs (Stellar Ecosystem Proposals)​Standards and protocols to allow the Stellar ecosystem to interoperate.Learn more in our SEPs section.Signer​Refers to the master key or to any other signing keys added later. A signer is defined as the pair: public key + weight. Signers can be set with the Set Options operation.See our Signature and Multisignature Encyclopedia Entry for more information.Source account​The account that originates a transaction. This account also provides the fee and sequence number for the transaction.Starlight​Stellar’s layer 2 protocol that allows for bi-directional payment channels.Stellar​A decentralized, federated peer-to-peer network that allows people to send payments in any asset anywhere in the world instantaneously, and with minimal fees.Stellar Consensus Protocol (SCP)​Provides a way to reach consensus without relying on a closed system to accurately record financial transactions.See our SCP section to learn more.Stellar Core​A replicated state machine that maintains a local copy of a cryptographic ledger and processes transactions against it, in consensus with a set of peers; also, the reference implementation for the peer-to-peer agent that manages the Stellar network.Stellar Development Foundation (SDF)​A non-profit organization founded to support the development and growth of the Stellar network.Stellar.toml​A formatted configuration file containing published information about a node and an organization. For more, see the Stellar Info File spec (SEP-0001`)Stroop​As cents are to dollars, stroops are to assets: the smallest unit of an asset, one ten-millionth.Testnet​The Stellar Test Network is maintained by the Stellar Development Foundation, which developers can use to test applications. Testnet is free to use and provides the same functionality as the main (public) network.Read more in our Testnet & Pubnet section.Threshold​The level of access for an operation.Also used to describe the ratio of validator nodes in a quorum set that must agree in order to reach consensus as part of the Stellar Consensus Protocol.Read more about operation thresholds in the Operations and Transactions section.Learn more about quorum set validators in our Stellar Consensus Protocol section.Time bounds​An optional feature you can apply to a transaction to enforce a time limit on the transaction; either the transaction makes it to the ledger or times out (fails) depending on your time parameters.Read more about time bounds in our Operation and Transaction Validity section.Transaction​A group of 1 to 100 operations that modify the ledger state.Read more in the Operations and Transactions section.Transaction envelope​A wrapper for a transaction that carries signatures.Transaction fee​Stellar requires a small fee for all transactions to prevent ledger spam and prioritize transactions during surge pricing.Learn more in our Lumens section.Trustline​An explicit opt-in for an account to hold a particular asset that tracks liabilities, the balance of the asset, and can also limit the amount of an asset that an account can hold.Learn more in our Accounts section.UNIX timestamp​An integer representing a given date and time, as used on UNIX and Linux computers.Validator​A basic validator keeps track of the ledger and submits transactions for possible inclusion. It ensures reliable access to the network and sign-off on transactions. A full validator performs the functions of a basic validator, but also publishes a history archive containing snapshots of the ledger, including all network transactions and their results.XLM (lumens)​The native currency of the Stellar network.Wallet​An interface that gives a user access to an account stored on the ledger; that access is controlled by the account’s secret key. The wallet allows users to store and manage their assets.","metadata":{"source":"https://developers.stellar.org/docs/glossary","title":"Glossary","contentLength":1875}}]